<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[suse11sp1 编译 apache 2.4.34]]></title>
    <url>%2F2019%2F09%2F26%2F2019%2F20190418%20suse11sp1%20%E7%BC%96%E8%AF%91%20apache%202.4.34%2F</url>
    <content type="text"><![CDATA[背景：suse 11 sp1 机器编译安装带有指定模块的 apache 2.4.34. 暂时没有bicp代码访问权限，先放这里 == 第一步 安装openssl cd /data/bicpinstall/ tar zxvf openssl-1.1.0i.tar.gz cd openssl-1.1.0i export LDFLAGS=-ldl export LIBPATH="/data/bicpinstall/ssl" export LIBS="-L/data/bicpinstall/ssl" export SSL_LIBS="-L/data/bicpinstall/ssl" export CPPFLAGS="-I/data/bicpinstall/ssl/include/openssl" ./config --prefix=/data/bicpinstall/ssl shared make &amp;&amp; make install rm -rf /data/bicpinstall/ssl/ssl/man 第二步 生成证书 cd /data/bicpinstall/ssl/bin openssl genrsa -passout pass:cHpxHUm+v5teANoYurlMvA2+Gdg+ifm -des3 -out server.key 1024 openssl req -new -out server.csr -key server.key -passin pass:cHpxHUm+v5teANoYurlMvA2+Gdg+ifm -passout pass:cHpxHUm+v5teANoYurlMvA2+Gdg+ifm -subj /C=CN/O=huawei/CN=10.139.200.36 -config ../ssl/openssl.cnf openssl x509 -req -days 3650 -in server.csr -signkey server.key -out server.crt -passin pass:cHpxHUm+v5teANoYurlMvA2+Gdg+ifm openssl pkcs12 -export -out server.pfx -inkey server.key -in server.crt -passin pass:cHpxHUm+v5teANoYurlMvA2+Gdg+ifm -passout pass:cHpxHUm+v5teANoYurlMvA2+Gdg+ifm 第三步 安装 httpd 2.4.34 依赖的 apr 和 apr-util 该部分不再捆绑发布，需要自行安装，版本需要 1.5 以上，部分功能需要 1.6 以上，版本要求见https://www.apache.org/dist/httpd/Announcement2.4.html cd /data/bicpinstall/ tar zxvf apr-1.6.3.tar.gz tar zxvf apr-util-1.6.1.tar.gz apr cd /data/bicpinstall/apr-1.6.3/ ./configure --prefix=/data/bicpinstall/httpd-2.4.34/srclib/apr make &amp; make install apr-utils expat （apr-utils依赖 libexpat，https://www.apache.org/dist/apr/CHANGES-APR-UTIL-1.6） cd /data/bicpinstall/ tar xvjf expat-2.2.5.tar.bz2 cd expat-2.2.5 ./configure --prefix=/data/bicpinstall/httpd-2.4.34/srclib/expat make &amp; make install cd /data/bicpinstall/apr-util-1.6.1 ./configure --prefix=/data/bicpinstall/httpd-2.4.34/srclib/apr-util --with-apr=/data/bicpinstall/httpd-2.4.34/srclib/apr --with-expat=/data/bicpinstall/httpd-2.4.34/srclib/expat make &amp; make install 第四步 安装 pcre，下载地址(https://ftp.pcre.org/pub/pcre/) tar zxvf pcre-8.42.tar.gz cd /data/bicpinstall/pcre-8.42 ./configure --prefix=/data/bicpinstall/httpd-2.4.34/srclib/pcre make &amp;&amp; make install 安装 zlib，下载地址(https://zlib.net/zlib-1.2.11.tar.gz) 直接 ./configure &amp;&amp; make &amp;&amp; make install 第五步 编译安装 httpd cd /data/bicpinstall/httpd-2.4.34 ./configure --prefix=/data/bicpinstall/apache --with-ssl=/data/bicpinstall/ssl --with-apr=/data/bicpinstall/httpd-2.4.34/srclib/apr --with-apr-util=/data/bicpinstall/httpd-2.4.34/srclib/apr-util --with-pcre=/data/bicpinstall/httpd-2.4.34/srclib/pcre --enable-headers=shared --enable-rewrite=shared --enable-proxy=shared --enable-proxy-connect=shared --enable-proxy-ftp=shared --enable-proxy-http=shared --enable-proxy-scgi=shared --enable-proxy-ajp=shared --enable-proxy-balancer=shared --enable-ssl=shared --enable-deflate=shared make &amp;&amp; make install 第六步 压缩包 cd /data/bicpinstall/ mkdir apache/lib cp -P /data/bicpinstall/httpd-2.4.34/srclib/apr/lib/libapr-1.so* data/bicpinstall/apache/lib/ cp -P /data/bicpinstall/httpd-2.4.34/srclib/apr-util/lib/libaprutil-1.so* data/bicpinstall/apache/lib/ cp -P /data/bicpinstall/httpd-2.4.34/srclib/expat/lib/libexpat.so* data/bicpinstall/apache/lib/ cp -r /data/bicpinstall/ssl /data/bicpinstall/apache/lib cd /data/bicpinstall/apache/manual/mod; rm -rf index.html* cd /data/bicpinstall/apache/manual/rewrite; rm -rf index.html* cd /data/bicpinstall/apache/manual; rm -rf index.html* cd /data/bicpinstall/apache/manual/ssl; rm -rf index.html* cd /data/bicpinstall/apache/manual/programs; rm -rf index.html* cd /data/bicpinstall/apache/manual/developer;rm -rf index.html* cd /data/bicpinstall/apache/manual/misc; rm -rf index.html* cd /data/bicpinstall/apache/manual/howto; rm -rf index.html* cd /data/bicpinstall/apache/manual/platform; rm -rf index.html* cd /data/bicpinstall/apache/manual/faq; rm -rf index.html* cd /data/bicpinstall/apache/manual/vhosts; rm -rf index.html* cd /data/bicpinstall/apache/htdocs; rm -rf index.html* cd /data/bicpinstall/apache/cgi-bin;rm -rf * zip -r apache.zip apache 附录一 部分软件 apr-1.6.3.tar.gz apr-util-1.6.1.tar.gz expat-2.2.5.tar.bz2.remove.asc httpd-2.4.34.tar.gz openssl-1.1.0i.tar.gz pcre-8.42.tar.gz zlib-1.2.11.tar.gz 附录二 部分编译工具版本或环境 cat /etc/SuSE-release SUSE Linux Enterprise Server 11 (x86_64) VERSION = 11 PATCHLEVEL = 1 gcc --version gcc (SUSE Linux) 4.3.4 [gcc-4_3-branch revision 152973] Copyright (C) 2008 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. gunzip --version gzip 1.3.12 Copyright (C) 2007 Free Software Foundation, Inc. Copyright (C) 1993 Jean-loup Gailly. This is free software. You may redistribute copies of it under the terms of the GNU General Public License &lt;http://www.gnu.org/licenses/gpl.html&gt;. There is NO WARRANTY, to the extent permitted by law. Written by Jean-loup Gailly. make --version GNU Make 3.81 Copyright (C) 2006 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. This program built for x86_64-unknown-linux-gnu 附录三 错误解决 报错： /bin/sh: gcc: command not found make[1]: *** [crypto/aes/aes-x86_64.o] Error 127 make[1]: Leaving directory `/data/bicpinstall/openssl-1.1.0i' make: *** [all] Error 2 解决：安装gcc 报错： checking for APR... no configure: error: APR not found. Please read the documentation. 报错： pcre-config for libpcre not found. PCRE is required and available from http://pcre.org/ 解决：见编译指导.md 报错： checking dirent.h presence... yes checking for dirent.h... yes checking windows.h usability... no checking windows.h presence... no checking for windows.h... no configure: error: Invalid C++ compiler or C++ compiler flags 解决： zypper in gcc-c++ 报错： checking for zlib location... not found checking whether to enable mod_deflate... configure: error: mod_deflate has been requested but can not be built due to prerequisite failures 解决：编译安装zlib 报错： checking whether to enable mod_deflate... checking dependencies adding "-I/lib64/include" to INCLUDES setting MOD_INCLUDES to "-I/lib64/include" adding "-L/lib64/lib" to LDFLAGS setting ap_zlib_ldflags to "-L/lib64/lib" adding "-lz" to LIBS checking for zlib library... not found configure: error: ... Error, zlib was missing or unusable 解决：安装 zlib 报错： od_proxy_balancer.c &amp;&amp; touch mod_proxy_balancer.slo mod_proxy_balancer.c:25:24: error: apr_escape.h: No such file or directory mod_proxy_balancer.c: In function 'make_server_id': mod_proxy_balancer.c:779: warning: implicit declaration of function 'apr_pescape_hex' mod_proxy_balancer.c:779: warning: return makes pointer from integer without a cast make[4]: *** [mod_proxy_balancer.slo] Error 1 make[4]: Leaving directory `/data/bicpinstall/httpd-2.4.34/modules/proxy' make[3]: *** [shared-build-recursive] Error 1 make[3]: Leaving directory `/data/bicpinstall/httpd-2.4.34/modules/proxy' make[2]: *** [shared-build-recursive] Error 1 make[2]: Leaving directory `/data/bicpinstall/httpd-2.4.34/modules' make[1]: *** [shared-build-recursive] Error 1 make[1]: Leaving directory `/data/bicpinstall/httpd-2.4.34' make: *** [all-recursive] Error 1 解决：安装 apr-util 报错： xml/apr_xml.c:35:19: error: expat.h: No such file or directory xml/apr_xml.c:66: error: expected specifier-qualifier-list before ‘XML_Parser’ xml/apr_xml.c: In function ‘cleanup_parser’: xml/apr_xml.c:364: error: ‘apr_xml_parser’ has no member named ‘xp’ xml/apr_xml.c:365: error: ‘apr_xml_parser’ has no member named ‘xp’ xml/apr_xml.c: At top level: xml/apr_xml.c:384: error: expected ‘;’, ‘,’ or ‘)’ before ‘*’ token xml/apr_xml.c: In function ‘apr_xml_parser_create’: xml/apr_xml.c:401: error: ‘apr_xml_parser’ has no member named ‘xp’ xml/apr_xml.c:402: error: ‘apr_xml_parser’ has no member named ‘xp’ xml/apr_xml.c:410: error: ‘apr_xml_parser’ has no member named ‘xp’ xml/apr_xml.c:411: error: ‘apr_xml_parser’ has no member named ‘xp’ xml/apr_xml.c:412: error: ‘apr_xml_parser’ has no member named ‘xp’ xml/apr_xml.c:424: error: ‘apr_xml_parser’ has no member named ‘xp’ xml/apr_xml.c:424: error: ‘default_handler’ undeclared (first use in this function) xml/apr_xml.c:424: error: (Each undeclared identifier is reported only once 解决：安装 expat，方法见上 报错： aclocal: couldn't open directory `m4': No such file or directory 解决 直接在当前目录 mkdir m4]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>[object Object]</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自研数据库主备切换的一个bug记录]]></title>
    <url>%2F2019%2F09%2F26%2F20190810_%E8%87%AA%E7%A0%94%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2%E7%9A%84%E4%B8%80%E4%B8%AAbug%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[自研数据库主备切换的一个bug记录 还是要给自研数据库的人点个赞，以前可能有人要问，业界有mysql，有oracle，有postgresql，大量的收费免费数据库，你们为什么要自己开发数据库？ 相信过了今年，不会再有人问这个问题了。 自研数据库虽然具体细节不能透露，但是其只有6m的安装包大小，完美支持与oracle对接并同步的特性，兼容sql标准，支持python，c，java， 支持多个主备，简单如mysql的配置，简单的容灾能力，支持方便的升级等等，还是很有竞争力。 主备同步的bug 那么bug是什么呢？ 该数据库在一主一备的情况下，有两种手段可以进行主备倒换： 1. switchover 2. failover switchover的场景是，如果主机和备机都正常，想手动触发主备倒换； failover的场景是，如果主机宕机了，备机需要容灾，提升为主机。 这个bug出现在failover的情况。在failover的场景，备机已经升为主机，但是如果主机又恢复，这个时候会出现双主的现象，就需要将其降为备（demote）。 问题是，在demote后，数据库必然出现主备不一致的情况，导致发生该数据库一个著名的异常情况needrepair，而且恢复方案需要删除数据重建，因此没人愿意写自动脚本处理，需要手工干预。 问题定位 我们首先快速排查自己触发切换代码，在排查后将问题范围指向该数据库本身； 首先，主备不一致的情况，是可以在日志中查询到的。该数据库，在主机降备成功后的十秒钟左右，会打印一行类似如下的信息： standby redo point(1/1422) is faster than primary(2/1421)，need repair&#8230;&#8203; 很清晰，说新的备机redo日志比主机要快。那么就是要找出，多出来的这个操作，到底是什么？ 路线分为两路： 1. 通过解析redo日志，查看操作内容 2. 通过其它日志手段，继续确认及排查 由于环境与我们开发环境的网络较为复杂，速度也比较慢，而该redo日志有1个G，传输要1个小时。因此在等待传输的间隙，我们走路线2. 通过类似以下命令开启audit日志以及debug日志。 alter system set audit_level=15; alter system set _log_level=255; 最终搜索通过debug日志，查到有insert语句在执行： cat debug.log|grep -i insert -C 2 通过查询数据库的job，发现开启了wsr性能收集job： select * from dba_jobs; 关闭该任务后，问题消失。自研数据库部门的人虽然确认问题，但是始终想不通，明明在停止和切换数据库的时间节点，已经停止wsr收集，为何还会导致该问题出现，该问题虽然不属于我们的范畴， 但是以往写并发以及过程控制要求比较严格的场景的经验告诉我，自研数据库这块的job，包括wsr以及用户自定义的job的逻辑，都需要再仔细审视一下。]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F22%2Ftest%2F</url>
    <content type="text"><![CDATA[#!/usr/bin/env node var arguments = process.argv.splice(2); var file = arguments[0] var showdown = require('showdown'), converter = new showdown.Converter(), fs = require('fs'), text = fs.readFileSync(file, "utf8"), html = converter.makeHtml(text); console.log(html)]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hive 2.3.3 安装常见问题]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181013%20Hive%202.3.3%20%E5%AE%89%E8%A3%85%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[remote 模式最小配置&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt; &lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://192.168.47.128:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;km717070&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 安装问题 remote 模式报错 Java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient解决：hive 需要先 hive --service metastore 先启动 thrift server，才能访问 mysql参考：官方手册：Hive Metastore 配置理解：mysql 为 metastore 的 database， Thrift Server 为 metastore 的服务器 hive –service metastore 启动报错 Unable to open a test connection to the given database解决：mysql 的配置有问题场景1：mysql 只允许本地访问场景2：mysql 白名单未添加相应机器参考： 如何确定 mysql 使用的配置文件mysql 访问常见问题Unable to open a test connection to the given database 报错 Version infomation not found in metastore原因：hive 0.12 以后版本会验证 metastore version，metastore 中无该信息，因此无法访问解决：schematool -dbType mysql -initSchema 刷库 警告 ssl 连接 mysql 的信息jdbc 连接串添加 &amp;useSSL=false 即可，注意在 xml 中的转义（写成 &amp;amp;useSSL=false）。 hive on mr is deprecated in hive 2, consider using a different execution engine like spark. or using a hive 1.x versionhive spark tez 对比]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何对 centos 7 分区进行扩容]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181013%20%E5%A6%82%E4%BD%95%E5%AF%B9%20centos%207%20%E5%88%86%E5%8C%BA%E8%BF%9B%E8%A1%8C%E6%89%A9%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[识别分区类型1fdisk -l 在 Id 一列可以看到分区类型为8e 83等十进制数值，8e代表该分区由 Linux LVM 管理，适用本文的扩容方法，如果你的分区类型为83，代表其是 Linux Native Partion，可以参考另一篇博文（尚未书写）。 虚拟机管理软件增加物理磁盘大小我使用的是 Vmware Workstation pro，在编辑虚拟机设置里可以轻松增加磁盘大小（磁盘为单个文件，而不是分割文件，如果你的硬盘是分割的多个文件，参考另一篇博文 Vmware 分割磁盘如何扩容(尚未编写) 查看新增加的磁盘位置12fdisk -l## 在 fdisk 输出信息中，可以看到 Disk /dev/sda： 30 GB 类似的信息，证明磁盘增加成功，位置确认。 分区12345678910111213141516171819## 以下命令为交互式命令fdisk /dev/sda# 输入 n 以创建新分区n# 输入 p 以设置为主分区p# 根据 fdisk -l 的信息，决定分区的编号，由于我的机器 fdisk -l 已经有 /dev/sda1 /dev/sda2 两个，所以此处输入 33# 此处输入两次回车，以决定分区的开始和结束位置，默认使用剩余全部未分配空间First cylinder.... 回车Last cylinder.... 回车# 此处输入 t，并输入 3 以选择我们上面步骤刚刚创建的分区t3# 在 Hex code 的输入步骤，输入我们希望使用的 LVM 代码符号：8e8e# 最后，输入 w 以使上述所有更改生效w 查看分区结果在我的机器上，不需要重启已经可以使用 fdisk -l 查看到新创建的 /dev/sda3，但是推荐你在此处先重启一次，然后执行后续操作 扩容关键步骤来了。此处使用到了 pv，vg，lv 等名词，请自行搜索了解，如果不了解，也不影响操作执行。123456789101112# 在 /dev/sda3 创建 pvpvcreate /dev/sda3 # 如果提示 Device /dev/sda3 not found, 请先重启。# 查看 vg 信息，获取到 vg 的 name，一般是你的机器名称，我的机器为 centosvgdisplay# 添加 pv 到 vgvgextend centos /dev/sda3 # 这里的 centos 是上一步查询出的 vg name# 查看 lv 的 path 信息lvdisplay # 此处我的 path 信息为 /dev/centos/root# 将新分区扩容到 lv lvextend /dev/centos/root /dev/sda3 # 此处 /dev/centos/root 为上一步查询出的 path# 最后一步xfs_growfs /dev/centos/root # centos 7/RedHat 默认使用 xfs 文件系统，如果是 ext 文件系统，可以使用 resize2fs /dev/Mega/root 命令 结束使用 df -h 查看扩容的结果吧~]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>centos7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BTrace 使用教程]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181019%20BTrace%20%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[BTrace 是 Java 的一个诊断工具，可以在不重启应用的情况下，对应用进行时间耗费、参数及结果跟踪、方法调用跟踪等分析。 BTrace 术语 Probe Point 位置 Trace Actions or Actions 追踪语句 Action Methods 追踪语句所在的静态方法 BTrace 程序结构 一个 BTrace 程序 是一个 Java 类，包含数个由 BTrace 注解 注释的 public static void 方法。这些注解被用来指定被追踪程序的 Probe Point. Tracing Actions 在这些静态方法内定义。这些静态方法也即上文提到的 Action Methods。 BTrace 的限制 不能 创建对象，数组。 不能 抛出、捕获异常。 不能 调用任意实例或静态方法，只能调用 BTraceUtils 中的方法。 不能 修改目标程序的静态或实例变量，不过 BTrace 程序自己不做限制。 不能 有实例变量或方法，方法不能有返回值类型，BTrace 程序的所有方法必须是 public static 1. oid 的，所有的字段都必须是 static 的。 不能 有 outer, inner, nested 或 local 类。 不能 用 synchronized 关键字。 不能 有循环 (for, while, do..while)。 不能 继承任何类 (即父类只能是 java.lang.Object)。 不能 实现接口。 不能 包含 assert 语句. 不能 使用 class literals. Warning 虽然不需要重启就可以使用 BTrace, 但是使用不当仍然会导致应用终止，比如目标程序可能会发生下面这种错误: Exception in thread "main" java.lang.NoSuchMethodError: com.foo.btraceDemo.Target.$btrace$com$foo$btraceDemo$Tracer$func(Ljava/lang/Object;IJII)V 一个简单的 BTrace 程序 演示 Tracer.java&#8201;&#8212;&#8201;BTrace 要执行的程序（脚本） // 导入所有 BTrace 注解。 import com.sun.btrace.annotations.*; // 导入 BTraceUtils 的静态方法。 import static com.sun.btrace.BTraceUtils.*; // @BTrace annotation tells that this is a BTrace program @BTrace (3) public class HelloWorld &#123; // @OnMethod 注解表明 Probe Point(位置)。 // 在这个例子中，我们对进入 Thread.start() 方法感兴趣。 @OnMethod( clazz="java.lang.Thread", method="start" ) public static void func() &#123; // println 是 BTraceUtils 的静态方法 println("about to start a thread!"); // System.out.println("123"); (1) // new Tracer(); : (2) &#125; &#125; 错误: Tracer.java:21:method calls are not allowed - only calls to BTraceUtils are allowed 错误: Tracer.java:22:object creation is not allowed 不要忘记 @BTrace 注解 Target.java&#8201;&#8212;&#8201;模拟的线上应用 import java.util.concurrent.TimeUnit; public class Target &#123; public static void main(String[] args) throws InterruptedException &#123; try &#123; TimeUnit.SECONDS.sleep(15); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("start main method..."); while(true) &#123; System.out.println("starting new thread..."); new Thread(() -&gt; &#123; while (true) &#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); TimeUnit.SECONDS.sleep(5); &#125; &#125; &#125; 运行 Target.java 后，使用 jps -v 查看该程序 pid 号。 &gt; jps -v 21952 Target -javaagent:D:\program\JetBrains\IntelliJ IDEA017.2.2\lib\idea_rt.jar=55132:D:\program\JetBrains\IntelliJ IDEA 2017.2.2\bin -Dfile.encoding=UTF-8 使用 btrace 启用 Tracer.java。 ## 首先切换到 Tracer.java 所在目录，然后执行 &gt; btrace -v 21952 Tracer.java (1) -v 打印出 DEBUG 信息，无 -v 只输出你自己想要输出的信息 可以看到在 Target.java 和 BTrace 的窗口都输出了调试信息。在 Target 中一旦一个新线程被创建，BTrace 便可以打印出相关信息。 继续&#8201;&#8212;&#8201;BTrace 注解 假设我们想诊断这样一个 add 方法： Target.java package com.foo.btraceDemo; import java.lang.management.ManagementFactory; import java.util.concurrent.TimeUnit; public class Target &#123; private static final String pid = ManagementFactory.getRuntimeMXBean().getName().split("@")[0]; public static void main(String[] args) throws InterruptedException &#123; System.out.println("pid: " + pid); while(true) &#123; System.out.println("准备调用 add 方法..."); add(3, 5); System.out.println("调用 add 方法结束..."); &#125; &#125; public static int add(int a, int b) throws InterruptedException &#123; TimeUnit.SECONDS.sleep(5); a = a + a; System.out.println("dododo"); a = a / 2; return a + b; &#125; &#125; Method Annotations 方法注释 @OnMethod Tracer.java:func @OnMethod(clazz="com.foo.btraceDemo.Target", method="add", location = @Location(Kind.RETURN)) public static void func(@Return int result, @Duration long time, int paramA, int paramB) &#123; println("param:" + paramA + ", " + paramB); println("result:" + result); println("costs(ms):" + time/1000/1000); &#125; 输出结果 param:3, 5 result:8 costs(ms):5020 param:3, 5 result:8 costs(ms):5013 如何通过 clazz/method 指定要诊断的方法 全限定名 clazz="com.foo.btraceDemo.Target", method="add" 正则表达式 clazz = "+java.sql.Statement", method = "/execute($|Update|Query|Batch)/" 接口/父类，注解 clazz = "+java.sql.Statement" // 匹配所有实现该接口或父类的类 clazz = "@org.springframework.stereotype.Controller" // 匹配所有 @Controller 注解的类 构造函数 clazz="java.lang.Throwable",method="&lt;init&gt;", location=@Location(Kind.RETURN) // 匹配任何异常被构造完成准备抛出 静态内部类 clazz="com.foo.bar$YourInnerClass", method="mName") 重载方法区别方法见下文 如何通过 @Location 指定诊断方法的时机 Kind.Entry Kind.Return Kind.Entry 方法进入时，为默认值。 Kind.Return 方法完成时, 指定此 Kind 可以使用 @Duration 获取方法耗时, @Return 获取方法返回结果 @OnMethod(clazz="com.foo.btraceDemo.Target", method="add", ocation = @Location(Kind.RETURN)) public static void func(@Return int result, @Duration long me, int paramA, int paramB) &#123; println("param:" + paramA + ", " + paramB); println("result:" + result); println("costs(ms):" + time/1000/1000); &#125; Kind.Error, Kind.Throw和 Kind.Catch Kind.Error: 异常抛出方法之外 Kind.Throw: 异常被 throw 之处 Kind.Catch: 异常被 catch 之处 @OnMethod(clazz = "java.net.ServerSocket", method = "bind", ocation = @Location(Kind.ERROR)) public static void onBind(Throwable exception, @Duration long uration) // 这种写法待验证 Kind.Call与Kind.Line Kind.ENTRY （默认值）只关注目标方法（OnMethod 的clazz/method），Kind.CALL 关注目标方法中，调用的其它哪些类哪些方法（Location的class，method）。注意，一般网上的教程，在描述 Kind.ENTRY 和 Kind.CALL 时，会将 CALL 描述为“还关注目标方法中其它方法的调用”，但是经过验证，此处不是“还”的关系，而是过滤的逻辑。也就是说，指定了这里的 clazz 和 method（例如 MethodB），将忽略目标方法（MethodA）的其它逻辑的时间。示例代码如下： Target.java&#8201;&#8212;&#8201;add public int add(int a, int b) throws InterruptedException &#123; TimeUnit.SECONDS.sleep(5); a = a + a; System.out.println("dododo"); a = a / 2; return a + b; &#125; Kind.ENTRY @OnMethod(clazz = "com.foo.btraceDemo.Target", method = "add", location = @Location(value = Kind.RETURN)) public static void add1(@Duration long time, int a, int b) &#123; print("add1 costs1(ns):" + time); totalTime += time; counter ++; println(", average(ns): " + (totalTime/counter)); &#125; add1 costs1(ns):5053722750, average(ns): 5053722750 add1 costs1(ns):5050729632, average(ns): 5052226191 add1 costs1(ns):5036155712, average(ns): 5046869364 KIND.CALL 匹配 println @OnMethod(clazz = "com.foo.btraceDemo.Target", method = "add", location = @Location(value = Kind.CALL, clazz = "java.io.PrintStream", method = "println", where = Where.AFTER)) public static void add2(@Duration long time) &#123; print("add2 costs(ns):" + time); totalTime += time; counter ++; println(", average(ns): " + (totalTime/counter)); &#125; add2 costs(ns):148064, average(ns): 148064 add2 costs(ns):91911, average(ns): 119987 add2 costs(ns):143314, average(ns): 127763 KIND.CALL 匹配 * @OnMethod(clazz = "com.foo.btraceDemo.Target", method = "add", location = @Location(value = Kind.CALL, clazz = "/.*/", method = "/.*/", where = Where.AFTER)) public static void add3(@Duration long time) &#123; print("add3 costs(ns):" + time); totalTime += time; counter ++; println(", average(ns): " + (totalTime/counter)); &#125; add3 costs(ns):5166920098, average(ns): 5166920098 (1) add3 costs(ns):81295, average(ns): 2583500696 add3 costs(ns):5160914306, average(ns): 3442638566 add3 costs(ns):68445, average(ns): 2581996036 add3 costs(ns):5075955184, average(ns): 3080787865 add3 costs(ns):67048, average(ns): 2567334396 add3 costs(ns):5060307945, average(ns): 2923473474 add3 costs(ns):115098, average(ns): 2558053677 add3 costs(ns):5276136213, average(ns): 2860062848 add3 costs(ns):93308, average(ns): 2574065894 注意这种写法打印的时间，你看出什么规律了吗? @OnTimer 定时任务，单位 ms, 没有什么好解释的。 @OnTimer(5000) public static void run()&#123; println(counter); &#125; @OnEvent @OnEvent public static void defalutEvent()&#123; println("default event sent..."); &#125; @OnEvent("speak") public static void namedEvent()&#123; println("speak something..."); &#125; 输出结果 Please enter your option: 1. exit 2. send an event 3. send a named event 4. flush console output &gt;3 Please enter the event name: &gt;speak speak something... &gt;1 default event sent... @OnError Arguments Annotations 参数注释 jstat -J-Djstat.showUnsupported=true -name btrace.com.sun.btrace.samples.ThreadCounter.count &lt;pid&gt; 更多解释请参考 BTrace 本地安装路径下的帮助文档，或者 wiki wiki 页面 Btrace使用小结 btrace记忆]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>btrace</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scala sbt 使用自定义的 maven 仓库]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181013%20%5BScala%5D%20%5Bsbt%5D%20%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%20maven%20%E4%BB%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[1.编辑或新建 ${HOME}/.sbt/repositories，添加如下123[repositories]localany-name-you-want: 你的仓库地址 2.编辑 ${sbt_安装目录}/conf/sbtconfig.txt，如果你使用的 idea，在 settings-&gt;SBT-&gt; jvm parameters 添加1-Dsbt.override.build.repos=true ## 忽略工程自定义的 resolvers，采用全局配置 参考 sbt 代理仓库 设置]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Scala</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 如何...]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181013%20CentOS%207%20%E5%A6%82%E4%BD%95...%2F</url>
    <content type="text"><![CDATA[如何更改为静态 IP 地址一. vi /etc/sysconfig/network-scripts/ifcfg-&lt;你的网卡名，如果不知道，直接 tab 自动补全&gt;123456789## 更改并添加以下数行# BOOTPROTO=dfcpBOOTPROTO=static# ONBOOT=noONBOOT=yesIPADDR=192.168.47.190 # IP 地址，先在虚拟机或路由里查看你的 IP 网段，然后在设置为你想要的值GATEWAY=192.168.47.2 # 网关信息，同上NETMASK=255.255.255.0 # 子网掩码信息，同上DNS1=8.8.8.8 # DNS 信息，同上 二. service network restart 重启网络服务 如何更改主机名hostnamectl set-hostname &lt;你想要的主机名&gt; 如何关闭防火墙和SELinux123456789systemctl disable firewalld.servicesystemctl stop firewalld.service# 编辑以下文件vi /etc/sysconfig/selinuxSELINUX=disabled# 编辑完成后，执行setenforce 0# 重启后执行 getenforce 变成 disabled 说明更改永久生效 如何设置 NTP 时间同步12yum install -y ntpsystemctl enable ntpd]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>centos7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm, yarn 代理或国内镜像设置]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181013%20npm%2C%20yarn%20%E4%BB%A3%E7%90%86%E6%88%96%E5%9B%BD%E5%86%85%E9%95%9C%E5%83%8F%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[使用家目录下的默认rc文件配置，不使用 npm config set.. npm 代理123456vi ~/.npmrc## add these lines to .npmrc## privoxy and shadowsocks [如何配置 privoxy 详见另一篇博文]()proxy=http://localhost:8118https_proxy=https://localhost:8118strict-ssl=false npm 国内镜像-淘宝1234registry=https://registry.npm.taobao.org## proxy=http://localhost:8118## https_proxy=https://localhost:8118## strict-ssl=false yarn 代理123456vi ~/.yarnrc## add these lines to .yarnrcenv: proxy &apos;http://localhost:8118&apos; https_proxy &apos;https://localhost:8118&apos; strict-ssl false yarn 使用国内镜像12yarn config set registry https://registry.npm.taobao.orgyarn config list]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>npm</tag>
        <tag>yarn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos 7 安装 apache-ambari]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181013%20centos%207%20%E5%AE%89%E8%A3%85%20apache-ambari%2F</url>
    <content type="text"><![CDATA[版本说明 部件 版本号 Ambari 2.6.2.2 CentOS 7 HDP 2.6 时间 20180814 背景对于 Ambari 能做什么，对于搜索到此文的同学来说应该毋庸赘述。目前 Ambari 安装的官方手册主要是 Apache 和 Hortonworks，我首先是参考 Apache 的说明，通过 maven 编译源码的方式，在 安装 linux-mint 的机器上尝试安装 Ambari 2.7.0，遇到过以下问题： 由于系统不符合 Ambari 的要求，因此通过更改其中的 ambari-commons/OSCheck.py:is_ubuntu_family() 函数强制安装 server 和 agent. 由于采用的国内 maven 仓库，ambari web legacy 始终编译不过，通过更改其依赖编译通过. maven compiler plugin 报错 json-simple 的相关依赖问题，最后删除该 legacy 模块. 其它 node, yarn, npm 的代理设置问题.最终在安装 agent 的时候遇到 ssl 连接错误，时间已晚，选择放弃这种安装方式。转而使用文档支持较好的 CentOS 和 yum 仓库安装的方式。虽然如此，Hortonworks 的文档逻辑也稍显混乱，过于简单，本文对安装过程做详细记录，以备查询。本文所有操作均使用 root 用户完成。 准备几台虚拟机我使用的是 Vmware WorkStation，CentOS 7 下载路径为 点我，安装步骤略过，建议安装 4 台机器(网络方式选择NAT模式)，其中安装 Ambari 服务器的机器硬盘大小不得小于 30 GB，如果不小心硬盘大小分配过小，参见另一篇博文如何对 centos 7 分区进行扩容。其余 3 台机器作为集群机器以备后续使用。 静态 IP ，hostname 设置，关闭防火墙，设置NTP时间同步服务参见另一篇博文 CentOS 7 如何… 设置 hosts 文件以便识别自定义的 hostname12345# vi /etc/hostsx.x.x.x linux-1x.x.x.x linux-2x.x.x.x linux-3x.x.x.x linux-4 然后 scp /etc/hosts 其它机器主机名:/etc/hosts 到其它机器。 设置无密码访问 ssh参见另一篇博文 免密码 ssh 到其它机器 umask 文件默认权限设置12## 默认权限更改为 755umask 0022 关闭 ssl 检查（注意，后面安装 HDP 还会有一次 openssl 相关的报错）123vi /etc/python/cert-verification.cfg # verify=platformxxx 改为verify=disable 安装 httpd 服务器作为后续离线安装包服务器123yum install httpdchkconfig httpd onservice httpd start 关于 JDK如果环境中没有 JDK，ambari 在安装设置阶段可以自动在线安装 JDK。但是如果已经安装了 JDK（要求1.8 版本），设置阶段指定 JDK_HOME 所在的路径即可，参见后续 ambari-server setup 阶段。 关于 python 和其它如果你使用的是我上面提供的官方 CentOS 7 镜像，python 的版本应该为 2.7，不需要任何修改。后续安装需要使用 wget 工具，请使用 yum install wget 安装。后续安装需要使用其它软件源管理工具，请使用 yum install yum-utils createrepo yum-plugin-priorities -y 安装。执行以下修改，以关闭 gpg 校验（否则后面安装会报错）。123vi /etc/yum/pluginconf.d/priorities.conf## 添加或更改为以下内容gpgcheck = 0 安装包获取CentOS 7 采用 yum 安装 ambari-server，该软件可以通过在线和离线两种方式下载到本地，出于国情，很明显我们应该选择离线安装的方式。 步骤1 下载离线包到本地由于我们使用的是 Ambari 2.6.2.2 ，配套的 HDP 版本为 2.[4|5|6]，本文选用 HDP 2.6，附上需要下载的所有包路径(以下 tar 包都需要下载)： 包名 路径 ambari 点我 HDP 点我 HDP-UTILS 点我 步骤2 上传到需要安装 Ambari 的机器上，解压到 httpd 的服务器目录中12345cd /var/www/htmlmkdir hdp ambaritar zxvf &lt;你上传的路径&gt;/ambari-2.6.2.2-centos7.tar.gz -C /var/www/html/ambaritar zxvf &lt;你上传的路径&gt;/HDP-2.6.5.0-centos7-rpm.tar.gz -C /var/www/html/hdptar zxvf &lt;你上传的路径&gt;/HDP-UTILS-1.1.0.22-centos7.tar.gz -C /var/www/html/hdp 步骤3 使用 createrepo 工具配置生成源描述文件(可省略，会影响后续 repo 文件的路径配置)1234cd /var/www/html/ambaricreaterepo ./cd /var/www/html/hdpcreaterepo ./ 步骤4 下载 HDP 和 Ambari 的 yum repo 文件123cd /etc/yum.repos.dwget -nv http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.5.0/hdp.repowget -nv http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.6.2.2/ambari.repo 步骤5 配置 yum repo 文件指向本地的软件源123456789vi /etc/yum.repos.d/ambari.repo## 更改 baseurl 和 gpgcheck 两项baseurl=http:///&lt;你的主机名&gt;/ambarigpgcheck=0vi /etc/yum.repos.d/hdp.repo ## 根据步骤3，HDP 和 HDP-UTILS 可以使用同一个 baseurl## 更改 baseurl 和 gpgcheck 两项baseurl=http:///&lt;你的主机名&gt;/hdpgpgcheck=0 步骤6 刷新软件源123yum clean allyum makecache## 如果此过程出现 404 错误，检查 httpd 服务是否正常，或者步骤3 安装、配置、启动与登录此过程较为简单。 安装1yum install ambari-server 配置12ambari-server setup其中可以配置是否创建用户、JDK、Ambari 自用元数据库（默认 Postgre）等，可以选择一路回车。 启动1service ambari-server start 登录访问 http://&lt;你的主机 IP 地址&gt;:8080/，使用默认的 admin/admin 账户登录即可。 使用 Ambari 安装 hadoop 集群可以参考另外一篇博文使用 Ambari 安装 hadoop 集群。]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>centos7</tag>
        <tag>ambari</tag>
        <tag>BigData</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vmware clone 机器地址重复_ubuntu18.04地址配置]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181013%20vmware%20clone%20%E6%9C%BA%E5%99%A8%E5%9C%B0%E5%9D%80%E9%87%8D%E5%A4%8D_ubuntu18.04%E5%9C%B0%E5%9D%80%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;在使用 VMware Workstation 克隆 Ubuntu Server 18.04 版本后，发现克隆前后的机器 ip地址 重复，且无论如何更改虚拟网络设置（编辑-虚拟网络编辑器）都无效。由于 Ubuntu 18.04 采用 netplan (/etc/netplan) 而不是先前版本的 /etc/network/interfaces 管理网卡设置，因此通过如下方法，将机器 ip 地址更改为静态获取，可以解决此问题。 1. vi /etc/netplan/50-cloud-init.yaml (此文件名可能会变化) network: ethernets: ens33: dhcp4: no dhcp6: no addresses: [192.168.44.129/24,] gateway4: 192.168.44.1 nameservers: addresses: [8.8.8.8, 8.8.4.4] 2. 更改后，执行 &gt;netplan apply &gt;reboot]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Ubuntu 18.04</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu 18.04 更改 hostname]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181013%20ubuntu%2018.04%20%E6%9B%B4%E6%94%B9%20hostname%2F</url>
    <content type="text"><![CDATA[1234vi /etc/cloud/cloud.cfg#preserve_hostname: false ---&gt; 改成 truevi /etc/hostnamereboot]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Ubuntu 18.04</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop 2.9.1 学习笔记]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181013%20hadoop%202.9.1%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[hadoop 学习笔记HDFS读写流程HDFS文件权限安全模式注意事项JDK 版本应该使用 1.8，JDK 10 遇到启动过程中 warning 并且 datanode 无法启动的问题。 集群安装最小配置文件（hadoop 2.9.1）core-site.xml12345678910111213&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://linux-1:8020/&lt;/value&gt; &lt;description&gt;NameNode URI&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;io.file.buffer.size&lt;/name&gt; &lt;value&gt;131072&lt;/value&gt; &lt;description&gt;Buffer size&lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.secondary.http.address&lt;/name&gt; &lt;value&gt;linux-2:50090&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.http.address&lt;/name&gt; &lt;value&gt;linux-1:50070&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:///opt/hdfs/namenode&lt;/value&gt; &lt;description&gt;NameNode directory for namespace and transaction logs storage.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.edits.dir&lt;/name&gt; &lt;value&gt;file:///opt/hdfs/namenode&lt;/value&gt; &lt;description&gt;DFS name node should store the transaction (edits) file.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:///opt/hdfs/datanode&lt;/value&gt; &lt;description&gt;DataNode directory&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.checkpoint.dir&lt;/name&gt; &lt;value&gt;file:///opt/hdfs/secondarynamenode&lt;/value&gt; &lt;description&gt;Secondary Namenode directory&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.edits.dir&lt;/name&gt; &lt;value&gt;file:///opt/hdfs/namenode&lt;/value&gt; &lt;description&gt;DFS name node should store the transaction (edits) file.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:///opt/hdfs/datanode&lt;/value&gt; &lt;description&gt;DataNode directory&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.checkpoint.dir&lt;/name&gt; &lt;value&gt;file:///opt/hdfs/secondarynamenode&lt;/value&gt; &lt;description&gt;Secondary Namenode directory&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.checkpoint.edits.dir&lt;/name&gt; &lt;value&gt;file:///opt/hdfs/secondarynamenode&lt;/value&gt; &lt;description&gt;DFS secondary name node should store the temporary edits to merge.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.checkpoint.period&lt;/name&gt; &lt;value&gt;7200&lt;/value&gt; &lt;description&gt;The number of seconds between two periodic checkpoints.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.checkpoint.txns&lt;/name&gt; &lt;value&gt;1000000&lt;/value&gt; &lt;description&gt;SecondaryNode or CheckpointNode will create a checkpoint of namespace every 1000000 transactions&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.use.datanode.hostname&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; mapred-site.xml12345678910111213141516171819202122232425262728293031&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;description&gt;MapReduce framework name&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;linux-1:10020&lt;/value&gt; &lt;description&gt;Default port is 10020.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;linux-1:19888&lt;/value&gt; &lt;description&gt;Default port is 19888.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.intermediate-done-dir&lt;/name&gt; &lt;value&gt;/mr-history/tmp&lt;/value&gt; &lt;description&gt;Directory where history files are written by MapReduce jobs.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.done-dir&lt;/name&gt; &lt;value&gt;/mr-history/done&lt;/value&gt; &lt;description&gt;Directory where history files are managed by the MR JobHistory Server.&lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; yarn-site.xml12345678910111213141516171819202122232425&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;description&gt;Yarn Node Manager Aux Service&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.local-dirs&lt;/name&gt; &lt;value&gt;file:///opt/yarn/local&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.log-dirs&lt;/name&gt; &lt;value&gt;file:///opt/yarn/logs&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hadoop-env.sh123456##update this lineexport JAVA_HOME=/opt/jdk1.8.0_181##add this to lastexport HADOOP_HOME=/opt/hadoop-2.9.1export HADOOP_CONF_DIR=/opt/hadoop-2.9.1/etc/hadoopexport HADOOP_LOG_DIR=$&#123;HADOOP_HOME&#125;/logs /etc/profile123456789export HADOOP_INSTALL=/opt/hadoop-2.9.1 export PATH=$PATH:$HADOOP_INSTALL/bin export PATH=$PATH:$HADOOP_INSTALL/sbin export HADOOP_MAPRED_HOME=$HADOOP_INSTALL export HADOOP_COMMON_HOME=$HADOOP_INSTALL export HADOOP_HDFS_HOME=$HADOOP_INSTALL export YARN_HOME=$HADOOP_INSTALLexport HADOOP_CONF_DIR=$HADOOP_INSTALL/etc/hadoopexport HADOOP_PREFIX=$HADOOP_INSTALL 启动命令start-all.sh (废弃) NameNodestart-dfs.shhttp://192.168.44.128:50070/dfshealth.html#tab-overview ResourceManagerstart-yarn.shhttp://192.168.44.128:8088/cluster JobHistoryServermr-jobhistory-daemon.sh --config /opt/hadoop-2.9.1/etc/hadoop start historyserverhttp://192.168.44.128:19888/jobhistory 参考 http://gaurav3ansal.blogspot.com/2018/06/install-hadoop-291-pseudo-distributed.html]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[免密码 ssh 到其它机器]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181013%20%E5%85%8D%E5%AF%86%E7%A0%81%20ssh%20%E5%88%B0%E5%85%B6%E5%AE%83%E6%9C%BA%E5%99%A8%2F</url>
    <content type="text"><![CDATA[背景：在配置 hadoop 的时候这样设置会比较方便。目标：A 机器上输入 ssh root@B 可以直接访问，不需要输入密码 步骤： 首先在 A 机器上生成密钥对，一路回车 1ssh-keygen -t rsa 在 A 机器上输入，输入 B 机器的密码一次即可 1ssh-copy-id -i ~/.ssh/id_rsa.pub root@B 所以同样的操作，B机器上可能还要再操作一遍，如果机器多了，也是很烦，因此，更懒人的做法是： 准备 xshell 5 打开多个机器的 ssh 会话窗口 配置好各个机器的 hostname 在 xshell 底部，“发送命令到所有窗口”这一行，依次输入 ssh-copy-id -i ~/.ssh/id_rsa.pub root@&lt;主机名&gt; 即可。]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[更换 python pip 软件源]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181013%20%E6%9B%B4%E6%8D%A2%20Python%20pip%20%E8%BD%AF%E4%BB%B6%E6%BA%90%2F</url>
    <content type="text"><![CDATA[12345678910mkdir ~/.pipcd ~/.piptouch pip.conf## add these lines[global] timeout = 6000 index-url = https://pypi.doubanio.com/simple/ [install] use-mirrors = true mirrors = https://pypi.doubanio.com/simple/ pip install --upgrade pip]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos 7 安装 apache-ambari]]></title>
    <url>%2F2019%2F09%2F22%2F20181013%20centos%207%20%E5%AE%89%E8%A3%85%20apache-ambari%2F</url>
    <content type="text"><![CDATA[版本说明 部件 版本号 Ambari 2.6.2.2 CentOS 7 HDP 2.6 时间 20180814 背景对于 Ambari 能做什么，对于搜索到此文的同学来说应该毋庸赘述。目前 Ambari 安装的官方手册主要是 Apache 和 Hortonworks，我首先是参考 Apache 的说明，通过 maven 编译源码的方式，在 安装 linux-mint 的机器上尝试安装 Ambari 2.7.0，遇到过以下问题： 由于系统不符合 Ambari 的要求，因此通过更改其中的 ambari-commons/OSCheck.py:is_ubuntu_family() 函数强制安装 server 和 agent. 由于采用的国内 maven 仓库，ambari web legacy 始终编译不过，通过更改其依赖编译通过. maven compiler plugin 报错 json-simple 的相关依赖问题，最后删除该 legacy 模块. 其它 node, yarn, npm 的代理设置问题.最终在安装 agent 的时候遇到 ssl 连接错误，时间已晚，选择放弃这种安装方式。转而使用文档支持较好的 CentOS 和 yum 仓库安装的方式。虽然如此，Hortonworks 的文档逻辑也稍显混乱，过于简单，本文对安装过程做详细记录，以备查询。本文所有操作均使用 root 用户完成。 准备几台虚拟机我使用的是 Vmware WorkStation，CentOS 7 下载路径为 点我，安装步骤略过，建议安装 4 台机器(网络方式选择NAT模式)，其中安装 Ambari 服务器的机器硬盘大小不得小于 30 GB，如果不小心硬盘大小分配过小，参见另一篇博文如何对 centos 7 分区进行扩容。其余 3 台机器作为集群机器以备后续使用。 静态 IP ，hostname 设置，关闭防火墙，设置NTP时间同步服务参见另一篇博文 CentOS 7 如何… 设置 hosts 文件以便识别自定义的 hostname12345# vi /etc/hostsx.x.x.x linux-1x.x.x.x linux-2x.x.x.x linux-3x.x.x.x linux-4 然后 scp /etc/hosts 其它机器主机名:/etc/hosts 到其它机器。 设置无密码访问 ssh参见另一篇博文 免密码 ssh 到其它机器 umask 文件默认权限设置12## 默认权限更改为 755umask 0022 关闭 ssl 检查（注意，后面安装 HDP 还会有一次 openssl 相关的报错）123vi /etc/python/cert-verification.cfg # verify=platformxxx 改为verify=disable 安装 httpd 服务器作为后续离线安装包服务器123yum install httpdchkconfig httpd onservice httpd start 关于 JDK如果环境中没有 JDK，ambari 在安装设置阶段可以自动在线安装 JDK。但是如果已经安装了 JDK（要求1.8 版本），设置阶段指定 JDK_HOME 所在的路径即可，参见后续 ambari-server setup 阶段。 关于 python 和其它如果你使用的是我上面提供的官方 CentOS 7 镜像，python 的版本应该为 2.7，不需要任何修改。后续安装需要使用 wget 工具，请使用 yum install wget 安装。后续安装需要使用其它软件源管理工具，请使用 yum install yum-utils createrepo yum-plugin-priorities -y 安装。执行以下修改，以关闭 gpg 校验（否则后面安装会报错）。123vi /etc/yum/pluginconf.d/priorities.conf## 添加或更改为以下内容gpgcheck = 0 安装包获取CentOS 7 采用 yum 安装 ambari-server，该软件可以通过在线和离线两种方式下载到本地，出于国情，很明显我们应该选择离线安装的方式。 步骤1 下载离线包到本地由于我们使用的是 Ambari 2.6.2.2 ，配套的 HDP 版本为 2.[4|5|6]，本文选用 HDP 2.6，附上需要下载的所有包路径(以下 tar 包都需要下载)： 包名 路径 ambari 点我 HDP 点我 HDP-UTILS 点我 步骤2 上传到需要安装 Ambari 的机器上，解压到 httpd 的服务器目录中12345cd /var/www/htmlmkdir hdp ambaritar zxvf &lt;你上传的路径&gt;/ambari-2.6.2.2-centos7.tar.gz -C /var/www/html/ambaritar zxvf &lt;你上传的路径&gt;/HDP-2.6.5.0-centos7-rpm.tar.gz -C /var/www/html/hdptar zxvf &lt;你上传的路径&gt;/HDP-UTILS-1.1.0.22-centos7.tar.gz -C /var/www/html/hdp 步骤3 使用 createrepo 工具配置生成源描述文件(可省略，会影响后续 repo 文件的路径配置)1234cd /var/www/html/ambaricreaterepo ./cd /var/www/html/hdpcreaterepo ./ 步骤4 下载 HDP 和 Ambari 的 yum repo 文件123cd /etc/yum.repos.dwget -nv http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.5.0/hdp.repowget -nv http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.6.2.2/ambari.repo 步骤5 配置 yum repo 文件指向本地的软件源123456789vi /etc/yum.repos.d/ambari.repo## 更改 baseurl 和 gpgcheck 两项baseurl=http:///&lt;你的主机名&gt;/ambarigpgcheck=0vi /etc/yum.repos.d/hdp.repo ## 根据步骤3，HDP 和 HDP-UTILS 可以使用同一个 baseurl## 更改 baseurl 和 gpgcheck 两项baseurl=http:///&lt;你的主机名&gt;/hdpgpgcheck=0 步骤6 刷新软件源123yum clean allyum makecache## 如果此过程出现 404 错误，检查 httpd 服务是否正常，或者步骤3 安装、配置、启动与登录此过程较为简单。 安装1yum install ambari-server 配置12ambari-server setup其中可以配置是否创建用户、JDK、Ambari 自用元数据库（默认 Postgre）等，可以选择一路回车。 启动1service ambari-server start 登录访问 http://&lt;你的主机 IP 地址&gt;:8080/，使用默认的 admin/admin 账户登录即可。 使用 Ambari 安装 hadoop 集群可以参考另外一篇博文使用 Ambari 安装 hadoop 集群。]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>centos7</tag>
        <tag>ambari</tag>
        <tag>BigData</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 Asciidoc 文档中使用 latex]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181106%20%E5%9C%A8%20Asciidoc%20%E6%96%87%E6%A1%A3%E4%B8%AD%E4%BD%BF%E7%94%A8%20latex%2F</url>
    <content type="text"><![CDATA[本文基于 asciidoctor 1.5.7.13，其通过 mathjax 实现 LaTex 字体的显示，方法和 markdown 差不多，区别是 markdown（不同差距实现方法不同）使用 $$ 或者 $``$ 包围 LaTex 语法，而 asciidoctor 使用 stem:[] 包围 LaTex 语法。 Table 1. 单个符号对照表 渲染后 源码 \(\cdot\) stem:[\cdot] \(\times\) stem:[\times] \(a^&#123;\prime&#125; a\) stem:[a^&#123;\prime&#125; a] \(a’’\) stem:[a’’] \(\hat&#123;a&#125;\) stem:[\hat&#123;a&#125;] \(\bar&#123;a&#125;\) stem:[\bar&#123;a&#125;] \(\grave&#123;a&#125;\) stem:[\grave&#123;a&#125;] \(\acute&#123;a&#125;\) stem:[\acute&#123;a&#125;] \(\dot&#123;a&#125;\) stem:[\dot&#123;a&#125;] \(\ddot&#123;a&#125;\) stem:[\ddot&#123;a&#125;] \(\not&#123;a&#125;\) stem:[\not&#123;a&#125;] \(\mathring&#123;a&#125;\) stem:[\mathring&#123;a&#125;] \(\overrightarrow&#123;AB&#125;\) stem:[\overrightarrow&#123;AB&#125;] \(\overleftarrow&#123;AB&#125;\) stem:[\overleftarrow&#123;AB&#125;] \(a’’’\) stem:[a’’’] \(\overline&#123;aaa&#125;\) stem:[\overline&#123;aaa&#125;] \(\check&#123;a&#125;\) stem:[\check&#123;a&#125;] \(\vec&#123;a&#125;\) stem:[\vec&#123;a&#125;] \(\underline&#123;a&#125;\) stem:[\underline&#123;a&#125;] \(\color&#123;red&#125;x\) stem:[\color&#123;red&#125;x] \(\pm\) stem:[\pm] \(\mp\) stem:[\mp] \(\int y \mathrm&#123;d&#125;x\) stem:[\int y \mathrm&#123;d&#125;x] \(!\) stem:[!] \(\int y\, \mathrm&#123;d&#125;x\) stem:[\int y\, \mathrm&#123;d&#125;x] \(\dots\) stem:[\dots] \(\ldots\) stem:[\ldots] \(\cdots\) stem:[\cdots] \(\vdots\) stem:[\vdots] \(\ddots\) stem:[\ddots] Table 2. 行列式 渲染后 源码 \[\vec&#123;a&#125; = \left[\begin&#123;array&#125;&#123;rrrr&#125; 15\\ 7 \end&#123;array&#125;\right)\] \vec&#123;a&#125; = \left[\begin&#123;array&#125;&#123;rrrr&#125; (1) 15\\ 7 \end&#123;array&#125;\right) (2) \[\begin&#123;cases&#125; \ u_&#123;tt&#125;(x,t)= b(t)\triangle u(x,t-4)&amp;\\ \ \hspace&#123;42pt&#125;- q(x,t)f[u(x,t-3)]+te^&#123;-t&#125;\sin^2 x, &amp; t \neq t_k; \\ \ u(x,t_k^+) - u(x,t_k^-) = c_k u(x,t_k), &amp; k=1,2,3\ldots ;\\ \ u_&#123;t&#125;(x,t_k^+) - u_&#123;t&#125;(x,t_k^-) =c_k u_&#123;t&#125;(x,t_k), &amp; k=1,2,3\ldots\ . \end&#123;cases&#125; ]\] [latexmath] ++++ \begin&#123;cases&#125; \ u_&#123;tt&#125;(x,t)= b(t)\triangle u(x,t-4)&amp;\\ \ \hspace&#123;42pt&#125;- q(x,t)f[u(x,t-3)]+te^&#123;-t&#125;\sin^2 x, &amp; t \neq t_k; \\ \ u(x,t_k^+) - u(x,t_k^-) = c_k u(x,t_k), &amp; k=1,2,3\ldots ;\\ \ u_&#123;t&#125;(x,t_k^+) - u_&#123;t&#125;(x,t_k^-) =c_k u_&#123;t&#125;(x,t_k), &amp; k=1,2,3\ldots\ . \end&#123;cases&#125; ] ++++ \[q(x,t)= \begin&#123;cases&#125;(t-k+1)x^2,\quad \ \ &amp; t\in\big(k-1,k-\dfrac&#123;1&#125;&#123;2&#125;\big],\\ (k-t)x^2, \quad \ \ &amp; t\in\big(k-\dfrac&#123;1&#125;&#123;2&#125;,k\big], \end&#123;cases&#125;\] q(x,t)= \begin&#123;cases&#125;(t-k+1)x^2,\quad \ \ &amp; t\in\big(k-1,k-\dfrac&#123;1&#125;&#123;2&#125;\big],\\ (k-t)x^2, \quad \ \ &amp; t\in\big(k-\dfrac&#123;1&#125;&#123;2&#125;,k\big], \end&#123;cases&#125; hexo中集成asciidoctor后渲染latex的bug hexo, asciidoctor, latex 三者在一起组成了一个很小众的东西。实际上使用 ruby 安装的 asciidoctor 在使用起来完全没有问题，但是 hexo 中因为使用的是 nodejs 中的一个 hexo-renderer-asciidoc 插件对 hexo 增强了 asciidoctor 的功能，并且该插件会对 &#123; &#125; 进行 转义，因此会导致莫名其妙的 问题出现。 另外 hexo 的 theme\next 主题中有 mathjax 的配置，将其设置为 true 后所有的页面都会引用 mathjax 的 js。 themes/next/_config.yml mathjax: enable: true per_page: false cdn: //cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML 因此开启此项配置后，结合插件，页面上的 LaTex 公式就可以正常显示了。]]></content>
      <categories>
        <category>备忘</category>
        <category>Asciidoctor</category>
      </categories>
      <tags>
        <tag>Asciidoctor</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181010%20hello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql 访问常见问题]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181229%20mysql%20%E8%AE%BF%E9%97%AE%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[配置文件参见[如何确定 mysql 的配置文件](待补充) 只能从本机访问 lsof -i:3306 查看发现，mysql 只监听本机。 解决：以我本机为例，在 /etc/mysql/mysql.conf.d/mysqld.cnf 中，将以下行注释掉 bind-address:127.0.0.1 无法从外部机器使用某一用户访问 登陆 mysql，创建远程访问用户，以 root 为例。 mysql&gt; `grant all privileges on *.* to 'root'@'%' identified by 'password' with grant option;`]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性代数快速复习[双语]]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181216%20%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%BF%AB%E9%80%9F%E5%A4%8D%E4%B9%A0%5B%E5%8F%8C%E8%AF%AD%5D%2F</url>
    <content type="text"><![CDATA[向量加法与数乘 Addition and Scalar Multiplication \[\vec&#123;a&#125; = \left[\begin&#123;array&#125;&#123;rrrr&#125; x\\ y \end&#123;array&#125;\right] , \vec&#123;b&#125; = \left[\begin&#123;array&#125;&#123;rrrr&#125; m\\ n \end&#123;array&#125;\right] \\ \vec&#123;a&#125;+\vec&#123;b&#125;= \left[\begin&#123;array&#125;&#123;rrrr&#125; x+m\\ y+n \end&#123;array&#125;\right] \\ 2\vec&#123;a&#125;= \left[\begin&#123;array&#125;&#123;rrrr&#125; 2x\\ 2y \end&#123;array&#125;\right]\] 向量的线性组合，向量张成的空间，基向量 Linear Combination, Span, bases \(a\vec&#123;i&#125; + b\vec&#123;j&#125; \quad a,b 取所有实数\) 线性相关 Linear Dependent \(\vec&#123;v&#125; = b\vec&#123;w&#125; \quad 增加一个线性相关的向量，不会增加张成的空间\) 所以向量空间的基，是可以张成该空间的一组线性无关的向量(的集合) A basis of a vector space is a set of linear independent vectors that span the full space. 线性变换 Linear Transformation 把\( \left(\begin&#123;array&#125;&#123;rrrr&#125; x_1 &amp; x_2\\ y_1 &amp; y_2 \end&#123;array&#125;\right) \)看作是经过线性变换后的基向量组成的矩阵，其中 \( \vec&#123;i&#125;= \left(\begin&#123;array&#125;&#123;rrrr&#125; x_1\\ y_1 \end&#123;array&#125;\right) \) , \( \vec&#123;j&#125;= \left(\begin&#123;array&#125;&#123;rrrr&#125; x_2\\ y_2 \end&#123;array&#125;\right) \)，而 \( a_&#123;input&#125;\left(\begin&#123;array&#125;&#123;rrrr&#125; x_1\\ y_1 \end&#123;array&#125;\right) +b_&#123;input&#125;\left(\begin&#123;array&#125;&#123;rrrr&#125; x_2\\ y_2 \end&#123;array&#125;\right) \)就可以看作用矩阵对 \( \left(\begin&#123;array&#125;&#123;rrrr&#125; a_&#123;input&#125;\\ b_&#123;input&#125; \end&#123;array&#125;\right) \)做变换。 更形象的表示，就是 \[\left[\begin&#123;array&#125;&#123;llll&#125; a_&#123;input&#125;\\ b_&#123;input&#125; \end&#123;array&#125;\right] \to a_&#123;input&#125;\left[\begin&#123;array&#125;&#123;rrrr&#125; x_1\\ y_1 \end&#123;array&#125;\right] +b_&#123;input&#125;\left[\begin&#123;array&#125;&#123;rrrr&#125; x_2\\ y_2 \end&#123;array&#125;\right] = \left[\begin&#123;array&#125;&#123;llll&#125; a_&#123;input&#125;x_1+b_&#123;input&#125;x_2\\ a_&#123;input&#125;y_1+b_&#123;input&#125;y_2 \end&#123;array&#125;\right] = \left[\begin&#123;array&#125;&#123;llll&#125; a_&#123;output&#125;\\ a_&#123;output&#125; \end&#123;array&#125;\right]\] 举例，如何描述将一个坐标轴逆时针旋转\(90^&#123;\circ&#125;\)呢？ 假设原空间的基础向量为 \( \vec&#123;i&#125;= \left(\begin&#123;array&#125;&#123;llll&#125; 1\\ 0 \end&#123;array&#125;\right) \) , \( \vec&#123;j&#125;= \left(\begin&#123;array&#125;&#123;llll&#125; 0\\ 1 \end&#123;array&#125;\right) \)。 那么旋转90\(\circ\)后，\(\vec&#123;i&#125;\)和\(\vec&#123;j&#125;\)变成了 \( \vec&#123;i_&#123;new&#125;&#125;= \left(\begin&#123;array&#125;&#123;llll&#125; 0\\ 1 \end&#123;array&#125;\right) \) , \( \vec&#123;j_&#123;new&#125;&#125;= \left(\begin&#123;array&#125;&#123;llll&#125; -1\\ 0 \end&#123;array&#125;\right) \)。可以画一张图来帮助理解。 那么对于任意一个向量\(\vec&#123;v&#125;=a\vec&#123;i&#125;+b\vec&#123;j&#125;\)，其变换后的向量就可以用 \( \left(\begin&#123;array&#125;&#123;llll&#125; \vec&#123;i_&#123;new&#125;&#125;&amp;\vec&#123;j_&#123;new&#125;&#125; \end&#123;array&#125;\right)\cdot\vec&#123;v&#125; \)即 \( a\cdot\vec&#123;i_&#123;new&#125;&#125;+b\cdot\vec&#123;j_&#123;new&#125;&#125; \)表示。 这种思想，也可以理解为，将变换后的基向量重新数乘后相加。 矩阵与向量相乘 由上得出，矩阵与向量相乘计算公式为 \[\left[\begin&#123;array&#125;&#123;llll&#125; x_1 &amp; x_2\\ y_1 &amp; y_2 \end&#123;array&#125;\right] \left(\begin&#123;array&#125;&#123;llll&#125; a\\ b \end&#123;array&#125;\right) = a\cdot\left(\begin&#123;array&#125;&#123;llll&#125; x_1\\ y_1 \end&#123;array&#125;\right) + b\cdot\left(\begin&#123;array&#125;&#123;llll&#125; x_2\\ y_2 \end&#123;array&#125;\right) = \left(\begin&#123;array&#125;&#123;llll&#125; ax_1+bx_2\\ ay_1+by_2 \end&#123;array&#125;\right)\] 矩阵与矩阵相乘 矩阵和矩阵相乘的几何意义，就是描述两个（或以上）线性变换的组合效果，并且最先变换的矩阵在最右边。 对于\( \left(\begin&#123;array&#125;&#123;llll&#125; \vec&#123;i_&#123;second&#125;&#125; &amp; \vec&#123;j_&#123;second&#125;&#125; \end&#123;array&#125;\right) \left(\begin&#123;array&#125;&#123;llll&#125; \vec&#123;i_&#123;first&#125;&#125; &amp; \vec&#123;j_&#123;first&#125;&#125; \end&#123;array&#125;\right) \)，可以考察最左侧变换，分别对\(\vec&#123;i_&#123;first&#125;&#125;\)，\(\vec&#123;i_&#123;first&#125;&#125;\)的影响，由此得出矩阵相乘公式为 \[\left(\begin&#123;array&#125;&#123;llll&#125; \vec&#123;i_&#123;second&#125;&#125; &amp; \vec&#123;j_&#123;second&#125;&#125; \end&#123;array&#125;\right) \left(\begin&#123;array&#125;&#123;llll&#125; \vec&#123;i_&#123;first&#125;&#125; &amp; \vec&#123;j_&#123;first&#125;&#125; \end&#123;array&#125;\right) = \left[\begin&#123;array&#125;&#123;llll&#125; \left(\begin&#123;array&#125;&#123;llll&#125; \vec&#123;i_&#123;second&#125;&#125; &amp; \vec&#123;j_&#123;second&#125;&#125; \end&#123;array&#125;\right)\vec&#123;i_&#123;first&#125;&#125; &amp; \left(\begin&#123;array&#125;&#123;llll&#125; \vec&#123;i_&#123;second&#125;&#125; &amp; \vec&#123;j_&#123;second&#125;&#125; \end&#123;array&#125;\right)\vec&#123;j_&#123;first&#125;&#125; \end&#123;array&#125;\right]\] 通用写法即为 \[\left[\begin&#123;array&#125;&#123;llll&#125; a &amp; b\\ c &amp; d \end&#123;array&#125;\right] \left[\begin&#123;array&#125;&#123;llll&#125; e &amp; f\\ g &amp; h \end&#123;array&#125;\right] = \left[\begin&#123;array&#125;&#123;llll&#125; ae+bg &amp; af+bf\\ ce+dg &amp; cf+df \end&#123;array&#125;\right]\] Note \(AB \neq BA\\ A(BC)=(AB)C\)]]></content>
      <categories>
        <category>备忘</category>
        <category>数学</category>
      </categories>
      <tags>
        <tag>线性代数</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Upsource 服务器搭建和集成 idea 插件]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181229%20Upsource%20%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E5%92%8C%E9%9B%86%E6%88%90%20idea%20%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[【客户端安装、配置篇】 安装 idea 插件 upsource 重启 idea 右下角有新增的 up 图标，点击之 进行此步一定要记得先关闭 idea 的代理。填写 upsource 服务器地址，这个http://100.107.166.116:8080 是我自己搭的测试服务器，没有配 https（当前使用场景没什么必要），后面要是正式用，就换个服务器。 点击 ok 在弹出的浏览器页面，输入账户和密码，第一次登陆会让你修改密码。测试账号（test01/Huawei@123）。账户找管理员申请（那个搭服务器的人） 后期可以对接到w3账号。 点击 login 后。idea 右下角 up 图标变量，说明插件可以使用了。 点击图标 up，选择 rescan 如果你的账号权限配置正确，那么你会搜索到你当前代码的工程。否则，你会看到如下报错提示： 由于这个服务器目前只有mysql和rhm的代码，所以现在只可以进行它俩的cr。这个添加其他代码也很简单，是管理员要做的事情。 【使用】网页篇不作赘述。只说插件。 选择一个revision（提交），然后右键 选择 review changes，选择 create review。如果这个提交还没有 review，直接点击 ok，会创建一个新的 review（你需要管理员帮你赋权，否则只能查看不能创建 review） 填写相关信息后，大家都可以看到你发起的 cr。效果如下： 功能很多，可以发起疑问，可以讨论，可以接受和关闭 review。 【服务器篇】【管理员篇】TODO搭建这个看官网就行了，一般 code reviewer 看客户端就行。 管理仓库添加TODO 账号管理 环境信息管理地址http://100.107.166.116:8080管理员账号（创建账号和角色，添加仓库） admin/Km717070 注意免费版只支持10个用户，虽然upsource支持配置多个代码库，但是建议一个工程配置一个upsource服务器，切记。 创建账号、赋权TODO]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>code review</tag>
        <tag>Intellij Idea</tag>
        <tag>Upsource</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL loaddata 数据膨胀（mysql 后台文件大小分析）]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181229%20mysql_loaddata%E6%95%B0%E6%8D%AE%E8%86%A8%E8%83%80%2F</url>
    <content type="text"><![CDATA[1. 发现问题100w 100字段数据 后台膨胀系数较大。用膨胀系数表示load data后mysql后台 表名.ibd 文件的大小与所 load 的 data.xdr 文件的比值。膨胀系数(50f100w)代表使用了50个字段100w行的数据进行测试。 2. 分解问题2.1 是否是数据量较大，导致膨胀系数较大？构造 10f10w 和 10f100w 进行对比，排除单纯因数据量导致膨胀的推测。 数据模型（字段数） 数据模型（行数） 数据文件大小（MB） load 时长(s) 表文件大小(MB) 单次导入增加 字段类型 10 10w 58.9 3.02 76 76 “3 int, 3 double(20,2), 4 VARCHAR(256) “ 10 100w 592 33.96 688 688 “3 int, 3 double(20,2), 4 VARCHAR(256) “ 2.2 是否是因字段数不同，导致膨胀系数较大？数据模型12345678910111213create table loadtest10f( record_001 VARCHAR(256), record_002 VARCHAR(256), record_003 VARCHAR(256), record_004 VARCHAR(256), record_005 VARCHAR(256), record_006 VARCHAR(256), record_007 VARCHAR(256), record_008 VARCHAR(256), record_009 VARCHAR(256), record_010 VARCHAR(256), ....) 因构造数据工具内存限制，100字段最多构造出2w行数据，为了方便对比，以下所有数据都构造2w行；因mysql 默认row size为65535，构造的数据模型为varchar(256)，且服务器采用utf8(每个字符3个字节)，所以最多构造到65535/256/3个字段； 构造同样是2w行数据的 10f,20f,50f,60f,70f,80f,85f 等数据进行测试，结果如下： 数据模型（字段数） 数据模型（行数） 数据文件大小（MB） load 时长(s) 表文件大小(MB) 字段类型 最大行大小 B+树高度 膨胀系数 10 20000 15 0.63 26 varchar(256) 7680 1 1.733333333 20 20000 29 1.04 42 varchar(256) 15360 1 1.448275862 30 20000 44 1.63 63 varchar(256) 23040 1 1.431818182 50 20000 72 3.07 110 varchar(256) 38400 1 1.527777778 60 20000 87 12.88 680 varchar(256) 46080 3 7.816091954 70 20000 101 35.61 1921 varchar(256) 53760 3 19.01980198 80 20000 115 61.87 3280 varchar(256) 61440 3 28.52173913 85 20000 123 70.04 3985 varchar(256) 65280 3 32.39837398 100 20000 144 varchar(256) 说明数据显示，字段在50f左右开始，膨胀系数曲线较之前更为陡峭，该变化记为 d1；在50f之后曲线再次平缓，增长速度小于 d1. 分析几点说明： innodb 默认 page size 为 16834. 1234567mysql&gt; show variables like 'innodb_page_size';+------------------+-------+| Variable_name | Value |+------------------+-------+| innodb_page_size | 16384 |+------------------+-------+1 row in set (0.00 sec) innodb 采用B+Tree数据结构，查询这几个构造的数据表，其根节点页起始页码为3： 12345678910111213141516171819202122232425mysql&gt; SELECT -&gt; b.name, a.name, index_id, type, a.space, a.PAGE_NO -&gt; FROM -&gt; information_schema.INNODB_SYS_INDEXES a, -&gt; information_schema.INNODB_SYS_TABLES b -&gt; WHERE -&gt; a.table_id = b.table_id AND a.space &lt;&gt; 0 AND b.name like '%loadtest%';+-----------------------+-----------------+----------+------+-------+---------+| name | name | index_id | type | space | PAGE_NO |+-----------------------+-----------------+----------+------+-------+---------+| test/loadtest100f100w | GEN_CLUST_INDEX | 30333 | 1 | 16650 | 3 || test/loadtest10f | GEN_CLUST_INDEX | 30334 | 1 | 16651 | 3 || test/loadtest10f100w | GEN_CLUST_INDEX | 30329 | 1 | 16646 | 3 || test/loadtest10f10w | GEN_CLUST_INDEX | 30328 | 1 | 16645 | 3 || test/loadtest20f | GEN_CLUST_INDEX | 30335 | 1 | 16652 | 3 || test/loadtest20f100w | GEN_CLUST_INDEX | 30330 | 1 | 16647 | 3 || test/loadtest30f | GEN_CLUST_INDEX | 30336 | 1 | 16653 | 3 || test/loadtest50f | GEN_CLUST_INDEX | 30337 | 1 | 16654 | 3 || test/loadtest50f100w | GEN_CLUST_INDEX | 30331 | 1 | 16648 | 3 || test/loadtest60f | GEN_CLUST_INDEX | 30340 | 1 | 16657 | 3 || test/loadtest70f | GEN_CLUST_INDEX | 30341 | 1 | 16658 | 3 || test/loadtest80f | GEN_CLUST_INDEX | 30338 | 1 | 16655 | 3 || test/loadtest85f | GEN_CLUST_INDEX | 30342 | 1 | 16659 | 3 |+-----------------------+-----------------+----------+------+-------+---------+13 rows in set (0.00 sec) 查询其 pagelevel （根页偏移64字节的前2位，即16834*3+64=49216） 123456789101112131415161718192021222324SHA1000130993:/usr/local/mysql/data/test # hexdump -s 49216 -n 10 loadtest10f.ibd000c040 0000 0000 0000 0000 7e76000c04aSHA1000130993:/usr/local/mysql/data/test # hexdump -s 49216 -n 10 loadtest20f.ibd000c040 0000 0000 0000 0000 7f76000c04aSHA1000130993:/usr/local/mysql/data/test # hexdump -s 49216 -n 10 loadtest30f.ibd000c040 0000 0000 0000 0000 8076000c04aSHA1000130993:/usr/local/mysql/data/test # hexdump -s 49216 -n 10 loadtest50f.ibd000c040 0000 0000 0000 0000 8176000c04aSHA1000130993:/usr/local/mysql/data/test # hexdump -s 49216 -n 10 loadtest60f.ibd000c040 0200 0000 0000 0000 8476000c04aSHA1000130993:/usr/local/mysql/data/test # hexdump -s 49216 -n 10 loadtest70f.ibd000c040 0200 0000 0000 0000 8576000c04aSHA1000130993:/usr/local/mysql/data/test # hexdump -s 49216 -n 10 loadtest80f.ibd000c040 0200 0000 0000 0000 8276000c04aSHA1000130993:/usr/local/mysql/data/test # hexdump -s 49216 -n 10 loadtest85f.ibd000c040 0200 0000 0000 0000 8676000c04a 获取 page level 和 B+Tree 高度由于本人测试机器字节序为小端，所以000c040 0200十六进制字节实际值为000c040 0002，即2.从上一步骤得出50f以后的表pagelevel为2,50f之前pagelevel为0.所以50f以后的表B+Tree高度为page level+1=3.B+Tree高度一般为1-3，很少有4。3 属于较高的高度，怀疑数据全为索引所占。 获取index所占page的粗略信息。由于本文测试数据未建索引，所以默认索引为GEN_CLUST_INDEX。主键、聚簇索引，本身即是数据，可以看到磁盘基本都是索引占据。 123456789101112131415161718192021222324252627282930mysql&gt; SELECT -&gt; table_name, -&gt; sum(stat_value) pages, -&gt; index_name, -&gt; sum(stat_value) * @@innodb_page_size size -&gt; FROM -&gt; mysql.innodb_index_stats -&gt; WHERE -&gt; table_name like '%load%' -&gt; AND database_name = 'test' -&gt; AND stat_description = 'Number of pages in the index' -&gt; GROUP BY -&gt; table_name,index_name;+------------------+--------+-----------------+-------------+| table_name | pages | index_name | size |+------------------+--------+-----------------+-------------+| loadtest100f100w | 785472 | GEN_CLUST_INDEX | 12869173248 || loadtest10f | 1059 | GEN_CLUST_INDEX | 17350656 || loadtest10f100w | 42112 | GEN_CLUST_INDEX | 689963008 || loadtest10f10w | 4327 | GEN_CLUST_INDEX | 70893568 || loadtest20f | 2084 | GEN_CLUST_INDEX | 34144256 || loadtest20f100w | 85568 | GEN_CLUST_INDEX | 1401946112 || loadtest30f | 3366 | GEN_CLUST_INDEX | 55148544 || loadtest50f | 6121 | GEN_CLUST_INDEX | 100286464 || loadtest50f100w | 99456 | GEN_CLUST_INDEX | 1629487104 || loadtest60f | 40425 | GEN_CLUST_INDEX | 662323200 || loadtest70f | 115114 | GEN_CLUST_INDEX | 1886027776 || loadtest80f | 196778 | GEN_CLUST_INDEX | 3224010752 || loadtest85f | 239466 | GEN_CLUST_INDEX | 3923410944 |+------------------+--------+-----------------+-------------+]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[右键添加在此处打开cygwin]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181230%20%E5%8F%B3%E9%94%AE%E6%B7%BB%E5%8A%A0%E5%9C%A8%E6%AD%A4%E5%A4%84%E6%89%93%E5%BC%80cygwin%2F</url>
    <content type="text"><![CDATA[系统：windows 10目标：在空白处点击右键菜单，显示如图菜单项，点击后可以打开 cygwin 并切换到当前所在目录 方法一：步骤： 开始菜单运行 regedit 打开注册表 定位到 1计算机\HKEY_CLASSES_ROOT\Directory\Background\shell\Cygwin\command 新建项和字符串到如下图所示 默认值填写 1C:\cygwin64\bin\mintty.exe -e /bin/bash --login -i -c "cd '%V';exec bash 或使用下面的注册表文件（注意更改注册表文件中的路径）1234567891011121314151617Windows Registry Editor Version 5.00[HKEY_CLASSES_ROOT\Directory\shell\Cygwin]@=&quot;在此处打开 Cygwin&quot;&quot;Icon&quot;=&quot;C:\\cygwin64\\Cygwin.ico&quot;[HKEY_CLASSES_ROOT\Directory\shell\Cygwin\command]@=&quot;C:\\cygwin64\\bin\\mintty.exe -e /bin/bash --login -i -c \&quot;cd &apos;%V&apos;;exec bash&quot;[HKEY_CLASSES_ROOT\Directory\Background\shell\Cygwin]@=&quot;在此处打开 Cygwin&quot;&quot;Icon&quot;=&quot;C:\\cygwin64\\Cygwin.ico&quot;[HKEY_CLASSES_ROOT\Directory\Background\shell\Cygwin\command]@=&quot;C:\\cygwin64\\bin\\mintty.exe -e /bin/bash --login -i -c \&quot;cd &apos;%V&apos;;exec bash&quot; 方法二：重新运行 cygwin 安装程序，勾选 chere 安装包。安装完成后，使用管理员身份运行 cygwin。 1chere -i -t mintty -s bash 此时右键菜单应该有 “Bash Prompt Here” 菜单选项。Win10 系统中，更改此处注册表，计算机\HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Directory\background\shell\cygwin64_bash增加 Icon 字符串，并更改中文描述，达到上图菜单效果。]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Cygwin</tag>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived 原理]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190105%20keepalived%20%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[vrrp 参考：[vrrp rfc3768](https://tools.ietf.org/html/rfc3768) The Virtual Router Redundancy Protocol (VRRP) is designed to eliminate the single point of failure inherent in the static default routed environment. VRRP specifies an election protocol that dynamically assigns responsibility for a virtual router to one of the VRRP routers on a LAN. The VRRP router controlling the IP address(es) associated with a virtual router is called the Master, and forwards packets sent to these IP addresses. The election process provides dynamic fail-over in the forwarding responsibility should the Master become unavailable. Any of the virtual router&#8217;s IP addresses on a LAN can then be used as the default first hop router by end-hosts. The advantage gained from using VRRP is a higher availability default path without requiring configuration of dynamic routing or router discovery protocols on every end-host. 定义： VRRP Router A router running the Virtual Router Redundancy Protocol. It may participate in one or more virtual routers. Virtual Router An abstract object managed by VRRP that acts as a default router for hosts on a shared LAN. It consists of a Virtual Router Identifier and a set of associated IP address(es) across a common LAN. A VRRP Router may backup one or more virtual routers. IP Address Owner The VRRP router that has the virtual router&#8217;s IP address(es) as real interface address(es). This is the router that, when up, will respond to packets addressed to one of these IP addresses for ICMP pings, TCP connections, etc. Primary IP Address An IP address selected from the set of real interface addresses. One possible selection algorithm is to always select the first address. VRRP advertisements are always sent using the primary IP address as the source of the IP packet. Virtual Router Master The VRRP router that is assuming the responsibility of forwarding packets sent to the IP address(es) associated with the virtual router, and answering ARP requests for these IP addresses. Note that if the IP address owner is available, then it will always become the Master. Virtual Router Backup The set of VRRP routers available to assume forwarding responsibility for a virtual router should the current Master fail.]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
        <tag>vrrp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ip_network.adoc]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190112%20ip_address%2F</url>
    <content type="text"><![CDATA[terminology multicast ip multicast multicast address subnetwork subnetword mask CIDR notation The IP address is expressed according to the standards of IPv4 or IPv6. The address may denote a single, distinct interface address or the beginning address of an entire network. The aggregation of these bits is often called the host identifier. &#8212; wikipedia https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing#CIDR_notation 192.168.100.14/24 represents the IPv4 address 192.168.100.14. Its subnet mask is 255.255.255.0, which has 24 lead-ing 1-bits, and its associated routing prefix, 192.168.100.0 derived by applying the mask to the address. the IPv4 block 192.168.100.0/22 represents the 1024 IPv4 addresses from 192.168.100.0 to 192.168.103.255. routing prefix or network number The routing prefix may be expressed in Classless Inter-Domain Routing (CIDR) notation written as the first address of a network, followed by a slash character (/), and ending with the bit-length of the prefix. For example, 198.51.100.0/24 is the prefix of the Internet Protocol version 4 network starting at the given address, having 24 bits allocated for the network prefix, and the remaining 8 bits reserved for host addressing. &#8212; wikipedia https://en.wikipedia.org/wiki/Subnetwork rest field or host identifier subnetting The practice of dividing a network into two or more networks is called subnetting. 如何划分子网及确定子网掩码 https://blog.csdn.net/jason314/article/details/5447743 &#8212; wikipedia https://en.wikipedia.org/wiki/Subnetwork https://www.pluralsight.com/blog/it-ops/simplify-routing-how-to-organize-your-network-into-smaller-subnets https://www.pluralsight.com/blog/it-ops/ip-addressing-routing-ip-address-architecture ip address class Class A 0 00000000-01111111( 0-127) Class B 10 10000000-10111111(128-191) Class C 110 11000000-11011111(192-223) Class D 1110 11100000-11101111(224-239) Class E 1111 11110000-11111111(240-255) special use:https://tools.ietf.org/html/rfc3330 subnetwork mask computation 172.16.0.0 - 172.31.255.255 (172.16/12 prefix) 12=8+4 11111111 11110000 00000000 00000000 255.255-15.0.0 255.240.0.0 172.32.0.0 - 172.47.255.255 (172.32/12 prefix) &#8230;&#8203; 172.16.0.0 - 172.16.3.255 (172.16.0/22 prefix) 22=8+8+6 11111111 11111111 11111100 00000000 255.255.255-3.0 255.255.252.0 00 01 10 11 255.255.254.0 11111111 11111111 11111110 00000000 inet addr:172.18.7.158 Bcast:172.18.7.255 Mask:255.255.248.0 11111111 11111111 11111000 00000000 172.18. 00000111 .158 172.18.0.0/21 == reference 2. Subnetwork 3. Subnetwork 4. ip address classes 5. telnet tcpdump]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>ip address</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tcpdump 原理]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190112%20tcpdump%2F</url>
    <content type="text"><![CDATA[man tcpdump https://en.wikipedia.org/wiki/Multicast_address https://en.wikipedia.org/wiki/Subnetwork [ip address classes] (http://www.vlsm-calc.net/ipclasses.php) + http://vod.sjtu.edu.cn/help/Article_Print.asp?ArticleID=631 tcpdump usage &lt;!--￼0-&#8594;]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
        <tag>tcpdump</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用service启动mysql最大连接数始终在480多左右]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190120%20%E4%BD%BF%E7%94%A8service%E5%90%AF%E5%8A%A8mysql%E6%9C%80%E5%A4%A7%E8%BF%9E%E6%8E%A5%E6%95%B0%E5%A7%8B%E7%BB%88%E5%9C%A8480%E5%A4%9A%E5%B7%A6%E5%8F%B3%2F</url>
    <content type="text"><![CDATA[背景： mysql 最大连接数在设置为2000的情况下，并发始终只能达到480多； 其它遇到过类似情况的项目组更改ulimit -s（stack size）到1024可以解决问题，但是我们经过测试无效； 据说前期定位人员咨询过mysql原厂的人，没发现有什么配置问题。 使用service启动mysql最大连接数始终在480多左右 测试工具 mysqlslap -h127.0.0.1 -uroot -p123456789 --concurrency=5000 --iterations=1 --auto-generate-sql --auto-generate-sql-load-type=mixed --auto-generate-sql-add-autoincrement --engine=innodb --number-of-queries=1000000 show status like "%Thread%""; 排查过程 ulimit cat /proc/pidof mysqld/limits /etc/systemd/system.conf /etc/systemd/user.conf systemctl edit mysql.service /usr/lib/systemd/system/mysql.service 直接使用mysqld启动，不用service，发现正常。最终在参照不使用service启动的mysql pid limits更改mysql.service所有ulimit到最大值也没用。 systemctl show mysql.service 发现TasksMax字段值为512，与480比较相近。 文档： https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html 尝试在/usr/lib/systemd/system/mysql.service加入以下配置 TasksMax=infinity 问题解决。 后续/深入 The mappings of systemd limits to ulimit Directive ulimit equivalent Unit LimitCPU= ulimit -t Seconds LimitFSIZE= ulimit -f Bytes LimitDATA= ulimit -d Bytes LimitSTACK= ulimit -s Bytes LimitCORE= ulimit -c Bytes LimitRSS= ulimit -m Bytes LimitNOFILE= ulimit -n Number of File Descriptors LimitAS= ulimit -v Bytes LimitNPROC= ulimit -u Number of Processes LimitMEMLOCK= ulimit -l Bytes LimitLOCKS= ulimit -x Number of Locks LimitSIGPENDING= ulimit -i Number of Queued Signals LimitMSGQUEUE= ulimit -q Bytes LimitNICE= ulimit -e Nice Level LimitRTPRIO= ulimit -r Realtime Priority LimitRTTIME= No equivalent 来自 https://unix.stackexchange.com/questions/345595/how-to-set-ulimits-on-service-with-systemd]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>systemd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Ambari 安装 HDP 集群]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181013%20%E4%BD%BF%E7%94%A8%20Ambari%20%E5%AE%89%E8%A3%85%20HDP%20%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[请先参考 CentOs 7 安装 apache-ambari 获得一台 ambari 服务器。 HDP 并不是 hadoop 的辅音简称，而是 Hortonworks 的产品 Hortonworks Data Platform 的简称，是包含 Hadoop 在内的一揽子解决方案。 前置要求：3-4台 CentOS 7 机器，其中一台机器必须安装 Ambari 服务。教程参考centos 7 安装 apache-ambari。安装 master 和 slave 的节点机器，内存最好不要小于 5G。 安装部件：如前所述，此次安装包含如下服务（请按需安装）： 服务 版本 说明 HDFS 2.7.3 Apache Hadoop 分布式文件系统 YARN + MapReduce2 2.7.3 Apache Hadoop 下一代 MapReduce(YARN) Tez 0.7.0 Tez 是运行在 YARN 之上的下一代 Hadoop 查询处理框架 Hive 1.2.1000 支持即席查询与大数据量分析和存储管理服务的数据仓库系统 HBase 1.1.2 非关系型分布式数据库，包括 Phoenix，一个为低延迟应用开发的高性能 sql 扩展 Pig 0.16.0 分析大数据量的脚本平台 Sqoop 1.4.6 在 Apache Hadoop 和 其它结构化的数据存储位置例如关系数据库 之间批量传递数据的工具 Oozie 4.2.0 Apache Hadoop 的工作引擎之一，另一个是 Azkaban。负责工作流的协调和执行。会按照一个可选的 Oozie Web 客户端，依赖此也会安装 ExtJS 库 Zookeeper 3.4.6 高可用的分布式协调服务 Falcon 0.10.0 数据管理和处理平台 Storm 1.1.0 Apache Hadoop 流处理框架Storm 介绍 Flume 1.5.2 收集，聚合和移动大量流式数据到 HDFS 的分布式服务 Accumulo 1.7.0 高可靠，性能和伸缩性的 Key/Value 存储[各种KV工具对比]https://kkovacs.eu/cassandra-vs-mongodb-vs-couchdb-vs-redis) Ambari Infra 0.1.0 Ambari 管理的部件所使用的核心共享服务 Ambari Metrics 0.1.0 Ambari 集群性能监控工具 Atlas 0.8.0 元数据管理平台 Kafka 1.0.0 高吞吐量的分布式消息系统 Knox 0.12.0 一个 rest 类型的认证系统，可提供单点登录认证 Log Search(未安装) 0.5.0 日志聚合，分析，可视化 SmartSense 1.4.5.2.6.2.2-1 一款不得不装的 Hortonworks 增值服务，集群诊断功能 Spark 1.6.3 快速的大规模数据处理引擎 Spark2 2.3.0 spark spark2 对比 Zeppelin NoteBook 0.7.3 Web 界面的数据分析系统，可以使用 sql 和 scala 等 Druid 0.10.1 快速的列存储分布式系统 Mahout 0.9.0 Apache 开源机器学习算法库，提供协作筛选（CF，推荐算法），聚类（clustering），分类(classification)实现 Slider 0.92.0 部署，管理与监控 YARN 上的应用程序 Superset 0.15.0 Airbnb 的开源可视化的数据平台 安装注意事项在 确认主机 Confirm Hosts 阶段，即使你的 openssl 是最新的，还是可能会报如下错误：123NetUtil.py:96 EOF occured in violation of protocol (_ssl.c:579)和SSLError: Failed to connect.Please check openssl library version. 此时需要在每一台节点上加入以下配置： 1234vi /etc/ambari-agent/conf/ambari-agent.ini[security] ## 在此部分加入以下一行force_https_protocol=PROTOCOL_TLSv1_2 在公司，不方便上图，回家继续更新。]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>ambari</tag>
        <tag>BigData</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 远程连接无法访问的问题（密码与connection_control插件）]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190201%20mysql%20%E8%BF%9C%E7%A8%8B%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[某业务通过Hibernate访问mysql，后台报错 Access denied for user 'matexxx'@'xxxx' (using password: YES); 一般搞过开发的人都知道，这种问题不是密码错了，就是远程连接未打开，这两者其实都属于一个问题，就是用户的grant权限问题，但是此业务情况稍特殊。定位过程如下。 查看用户 SELECT USER,HOST FROM MYSQL.USER; 发现用户matexxx对应的host为 %，说明远程连接已经打开；询问业务是否更改过密码，引出问题背景： 业务曾重装过mysql，使用mysqldump将旧库数据备份，并且只在新库的master上执行了一次恢复操作。 查看主从复制的状态 SHOW SLAVE STATUS\G 发现互为主备的mysql机器，其中一台的slave io状态为connecting，Last_IO_Error 显示复制用户 replicator 禁止登录。既然复制用户和业务用户都无法登录，怀疑点聚焦在用户的grant语句方面，原因可能是其备份恢复过程中出现错误操作，其要求紧急恢复，原因就暂不深挖。 【解决】 主从复制的问题要先解决。错误产生的原因很可能是其使用mysqldump --all-databases备份，然后在配置好主从的机器上直接恢复，导致两边的机器replicator主从复制用户的ip并不正确（实际应该配置对方ip）。恢复方法： 请将下面语句中的变量替换为实际的值 GRANT REPLICATION SLAVE ON *.* TO '$&#123;repl_user_name&#125;'@'$&#123;IP&#125;' IDENTIFIED BY '$&#123;repl_user_pwd&#125;'; FLUSH PRIVILEGES; SHOW MASTER LOGS; --在master(互为主备的机器，master就是你要复制的机器，请自行理解)上执行 -- 记录上面执行语句的结果，例如 -- Log_name：mysql-bin.000002 -- File_size：483 STOP SLAVE; --在出错的机器上，执行 CHANGE MASTER TO MASTER_HOST='$&#123;master_ip&#125;',MASTER_PORT='3306',MASTER_LOG_FILE='mysql-bin.000002',MASTER_LOG_POS=483; START SLAVE; 回到主要问题 重启业务应用（反正已经坏了）发现仍然无法登录，查看进程列表，发现大量连接状态都为 Waiting in connection_control plugin ，而且在另一台机器C上面使用matexxx登录一直卡住，而使用root却没有问题，证明此用户登录失败，被拒绝后触发了 connection_control 的机制。 show processlist; +----+------+-----------+------+---------+------+--------------------------------------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +----+------+-----------+------+---------+------+--------------------------------------+------------------+ | 3 | mmmm | x.x.x.x | NULL | Query | 0 | init | show processlist | | 32 | mmmm | x.x.x.x | NULL | Connect | NULL | Waiting in connection_control plugin | NULL | | 33 | mmmm | x.x.x.x | NULL | Connect | NULL | Waiting in connection_control plugin | NULL | | 34 | mmmm | x.x.x.x | NULL | Connect | NULL | Waiting in connection_control plugin | NULL | | 35 | mmmm | x.x.x.x | NULL | Connect | NULL | Waiting in connection_control plugin | NULL | | 36 | mmmm | x.x.x.x | NULL | Connect | NULL | Waiting in connection_control plugin | NULL | | 37 | mmmm | x.x.x.x | NULL | Connect | NULL | Waiting in connection_control plugin | NULL | | 38 | mmmm | x.x.x.x | NULL | Connect | NULL | Waiting in connection_control plugin | NULL | | 39 | mmmm | x.x.x.x | NULL | Connect | NULL | Waiting in connection_control plugin | NULL | | 40 | mmmm | x.x.x.x | NULL | Connect | NULL | Waiting in connection_control plugin | NULL | | 41 | mmmm | x.x.x.x | NULL | Connect | NULL | Waiting in connection_control plugin | NULL | | 42 | mmmm | x.x.x.x | NULL | Connect | NULL | Waiting in connection_control plugin | NULL | | 43 | mmmm | x.x.x.x | NULL | Connect | NULL | Waiting in connection_control plugin | NULL | | 44 | mmmm | x.x.x.x | NULL | Connect | NULL | Waiting in connection_control plugin | NULL | | 45 | mmmm | x.x.x.x | NULL | Connect | NULL | Waiting in connection_control plugin | NULL | | 46 | mmmm | x.x.x.x | NULL | Connect | NULL | Waiting in connection_control plugin | NULL | 此处解释一下 connection_control 的作用 一句话，防暴力破解。 官网曾有人对此插件发表过疑问，官方表示不应该在开放远程连接的外网机器上配置此插件，而且在生产环境上也不应存在host为%的用户。 https://bugs.mysql.com/bug.php?id=89155 此插件的作用是，多次登录失败，服务器增加对客户端的响应延迟，以增加暴力破解的时间；少量的失败登录对用户的正常登录没有影响，如果存在大量的失败登录（被暴力破解时）则用户正常登录时耗时会增加。 查看插件是否启用 show plugins; select plugin_name,plugin_library,load_option from information_schema.plugins; show variables like "%connection_control%"; connection_control_failed_connections_threshold: 3 (1) connection_control_max_connection_dely: 214xxxxxxxx (2) connection_control_min_connection_dely: 1000 (3) 在机制生效前允许的失败次数 允许延长到的最大时间 最小时间，单位ms 暂时规避插件的作用，简化问题 注释掉/etc/my.cnf的connection_control相关的行，重新启动两台机器。使用机器C重新登录两台机器，发现其中一台远程可以登录了， 但是另一台开始很快反馈报错信息。怀疑在有问题的机器上，用户密码被错误的修改过。 【解决】在无法登陆的机器上，重新运行grant语句并指定密码 GRANT ALL PRIVILEGES ON *.* TO "matexxx"@"%" IDENTIFIED BY "$&#123;userPWD&#125;"; FLUSH PRIVILEGES； 重启应用后问题消失。打开插件。 正确的恢复方法 由于前期人员备份脚本使用的 --all-databases，会一起导出用户信息。所以正确的恢复方法，大体是： 在旧的主机和备机上各自执行备份命令。 在安装好的新的机器上，各自登录并执行 STOP SLAVE; 各自导入备份的文件，查看show master logs并在两台机器上重新配置指定binlog文件： CHANGE MASTER TO MASTER_LOG_FILE='XXXX.bin0000001', MASTER_LOG_POS=123; START SLAVE;]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql knowledge]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190210%20mysql%20%E5%85%B4%E8%B6%A3%E5%B0%8F%E7%BB%84%E4%B8%BB%E9%A2%98%2F</url>
    <content type="text"><![CDATA[第一部分 MySQL篇 1 MySQL源代码入门MySQL源代码的组织结构Linux下的编译安装MySQL库MySQL 5.7权限处理 2 MySQL启动过程3 连接的生命与使命用户连接线程创建MySQL处理请求总结 4 MySQL表对象缓存表结构的实现原理涉及的参数变量优缺点总结存在的问题5 InnoDB初探 InnoDB的源代码目录结构InnoDB存储引擎文件组织InnoDB体系结构InnoDB存储引擎启动与关闭InnoDB 存储引擎的启动InnoDB存储引擎的关闭 6 InnoDB数据字典背景系统表结构字典表加载Rowid管理总结 7 InnoDB数据存储结构表空间文件组成结构段簇页面段、簇、页面组织结构 8 InnoDB索引实现原理背景B 树及B树的区别索引的设计聚簇索引和二级索引二级索引指针神奇的B 树网络InnoDB索引的插入过程一个页面至少要存储几条记录页面结构管理文件管理头信息页面头信息最小记录和最大记录页面数据空间管理经典的槽管理页面尾部页面重组索引页面的回收 9 InnoDB记录格式背景从源码入手了解行格式总结 10 揭秘独特的两次写单一页面刷盘批量页面刷盘两次写组织结构批量刷盘两次写实现原理两次写的作用发散思维总结 11 InnoDB日志管理机制InnoDB Buffer PoolREDO LOG日志文件管理的用途MTR InnoDB物理事务日志的意义日志记录格式日志刷盘时机REDO日志恢复数据库回滚数据库UNDO段管理数据库UNDO日志记录格式回滚时刻总结 12 MySQL 5.7中崭新的MySQL sys SchemaPerformance Schema的改进sys Schema介绍sys Schema视图摘要sys Schema重点视图与应用场景使用风险总结 13 方便的MySQL GTIDGTID 相关概念什么是GTIDGTID集合GTID生命周期GTID的维护gtid_executed表gtid_executed表压缩GTID搭建主从搭建主从时，需要注意的MySQL参数开启GTID搭建主从使用GTID案例总结如何跳过一个GTID利用GTID模式快速改变主从复制关系在线将传统模式复制改为GTID模式复制在线将GTID模式复制改为传统模式复制GTID的限制 14 MySQL半同步复制半同步特性半同步主库端半同步从库端半同步实现插件安装半同步自动开关 15 MySQL 5.7多线程复制原理背景行之有效的延迟优化方法MySQL 5.6的多线程复制MySQL 5.7的多线程复制ordered commit多线程复制分发原理异常故障恢复 16 大量MySQL表导致服务变慢的问题背景问题分析案例解决总结 17 MySQL快速删除大表背景问题分析案例解决发散思维总结 18 两条不同的插入语句导致的死锁背景问题分析发散思维总结 19 MySQL在并发删除同一行数据时导致死锁的分析背景问题分析发散思维总结 20 参数SQL_SLAVE_SKIP_COUNTER的奥秘21 Binlog中的时间戳背景问题分析发散思维事务中的事件顺序问题延伸show processlist中的Time总结 22 InnoDB中Rowid对Binlog的影响背景问题分析总结 23 MySQL备份：Percona XtraBackup的原理与实践备份背景及类型认识Percona XtraBackupXtraBackup的工作流程XtraBackup的备份原理XtraBackup 需要的权限innobackupex常用的备份选项说明XtraBackup备份实践全量备份增量备份并行备份其他备份案例实践与心得建议与提醒 24 MySQL分库分表分库分表的种类分库分表的原则分库分表实现数据库层的实现业务层的实现 25 MySQL数据安全单机安全集群安全备份安全MySQL实例安全保证Double WriteREDO LOGMySQL集群安全保证传统的主从模式如何保证数据库安全Semi_Sync Replication方式的复制MySQL集群化如何保证数据库安全总结 26 MySQL 性能拾遗适当的数据文件大小碎片空洞问题设计问题合理设计表结构冗余存储拆分存储重复存储特别提醒正确使用索引MySQL系统参数内存和CPU磁盘的革命云中漫步总结 27 MySQL Group ReplicationGroup Replication概述组的概念多主复制单独的通信机制Group Replication服务模式单主模式多主模式服务模式的配置Binlog Event的多线程执行group_replication_applier通道基于主键的并行执行搭建Group Replication复制环境MySQL的参数设置Group Replication插件的使用Group Replication插件的基本参数设置Group Replication的数据库用户Group Replication组初始化新成员加入组Group Replication的高可用性组内成员数量的变化强制移除故障成员Group Replication的监控Group Replication的基本原理状态机复制分布式的状态机复制分布式的高可用数据库深入理解Group Replication中事务的执行过程本地事务控制模块成员间的通信模块全局事务认证模块异地事务执行模块事务流程的总结深入理解成员加入组的过程组视图加入组时视图的切换View_change_log_event恢复 28 MySQL Document Store面面观新的JSON数据类型和JSON函数JSON数据类型JSON函数详解JSON函数的运用MySQL X Plugin 和 X Protocol支持NoSQL所做的努力安装MySQL X PluginMySQL Shell安装MySQL Shell运行MySQL Shell在MySQL Shell中操作JSON文档用脚本执行MySQL ShellX DevAPI总结参考资料第二部分 Galera篇 29 Galera Cluster的设计与实现Galera Cluster的优点Galera的引入Galera接口总结 30 Galera 参数解析状态参数变量参数 31 Galera的验证方法Binlog与Galera的关系验证方法 32 Galera的消息传送33 GCache实现原理配置参数实现原理发散思维 34 大话SST/IST细节初始化节点环境连接到集群并且做SST/IST如何提供增量数据总结 35 Donor/Desynced详解实现方式意义何在问答环节 36 Galera的并发控制机制数据复制写集验证写集APPLY事务Commit 37 Galera的流量控制流量控制的定义流量控制的实现原理及影响两个问题 38 Galera Cluster影响单节点执行效率的因素单点验证并发控制等待GTID总结 39 grastate.dat文件揭秘引子分析研究总结 40 Galera Cluster从库的转移没有开启Server级GTID的情况开启了GTID（server级）的情况总结 41 Galera Cluster节点与其从库的随意转换背景从节点向PXC节点的转换PXC节点向异步从节点的转换 42 业务更新慢，不是由Galera引起的43 在线改表引发的Galera Cluster集群死锁背景用Binlog来代替触发器表名交换Galera Cluster中的问题一个有趣的实验解决方案总结第三部分 Inception篇 44 Inception诞生记关于SQL审核半自动化方法人肉法不满现状的追求何谓Inception 45 Inception安装与使用下载和编译启动配置线上配置需求需要额外注意的点使用方法举例说明环境变量的设置 46 支持选项选项说明DDL与DML语句分离小技巧 47 Inception的备份回滚备份存储架构备份所需条件 48 审核规范支持的语句类型公共检查项插入语句检查项更新、删除语句检查项表属性检查项列属性检查项索引属性检查项修改表语句检查项总结 49 参数变量语法和变量注意事]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[测试 asciidoc 的支持]]></title>
    <url>%2F2019%2F09%2F22%2F2018%2F20181011%20asciidoc%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[列表1 列表项2]]></content>
      <categories>
        <category>测试</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>asciidoc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 5.7 replication]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190210%20mysql_5.7_replication%2F</url>
    <content type="text"><![CDATA[大纲 本文参考或翻译自： https://dev.mysql.com/doc/refman/5.7/en/replication.html mysql 5.7 支持多种主从复制的方法 传统方法：依赖binlog文件和文件的position保持同步 （https://dev.mysql.com/doc/refman/5.7/en/replication-configuration.html） 新方法： 依赖全局事务id即global transaction identifer（GTIDs） （https://dev.mysql.com/doc/refman/5.7/en/replication-gtids.html） replication 支持不同类型的同步 异步复制（asynchronous，默认） 同步复制（只有 NDB 集群才有的一种特性） 半同步复制（semisynchronous，是对异步复制的一种补充） With semisynchronous replication, a commit performed on the master blocks before returning to the session that performed the transaction until at least one slave acknowledges that it has received and logged the events for the transaction; see Semisynchronous Replication(https://dev.mysql.com/doc/refman/5.7/en/replication-semisync.html). MySQL 5.7 also supports delayed replication such that a slave server deliberately lags behind the master by at least a specified amount of time; see Section 16.3.10, Delayed Replication(https://dev.mysql.com/doc/refman/5.7/en/replication-delayed.html). HOW-TO There are a number of solutions available for setting up replication between servers, and the best method to use depends on the presence of data and the engine types you are using. For more information on the available options, see Section 16.1.2, “Setting Up Binary Log File Position Based Replication”(https://dev.mysql.com/doc/refman/5.7/en/replication-howto.html). 复制格式 基于语句的(Statement Based Replication (SBR)) 基于行的(Row Based Replication (RBR)) 混合的，也就是结合以上两种(Mixed Based Replication (MBR)) https://dev.mysql.com/doc/refman/5.7/en/replication-formats.html. 选项与变量 Replication is controlled through a number of different options and variables. For more information, see Section 16.1.6, “Replication and Binary Logging Options and Variables”(https://dev.mysql.com/doc/refman/5.7/en/replication-options.html). replication 的其它用途 https://dev.mysql.com/doc/refman/5.7/en/replication-solutions.html 原理 https://dev.mysql.com/doc/refman/5.7/en/replication-implementation.html 研究路线 配置 replication 基于日志位置的复制配置 基于GTIDs的复制 MySQL multi-Source replication 在上线机器上更改复制模式 复制与日志记录选项和变量 常用复制管理任务 replication 实现 replication 用途 .. 半同步 replication notes and tips 配置 replication 基于 BinLog 日志文件位置 的复制 master 作为数据库改变的源头，将事件（变化、更新等操作）写入到二进制日志，事件信息存储的格式根据变化的不同而不同；slave 从主机读取并执行日志。 每台 slave 都会获取到一份二进制日志（以下简称 binlog）的完整内容的副本。slave 会决定执行这个 binlog 的哪一部分。除非特别指定，否则全部执行。如果需要，你也可以配置只执行特定 database 或者 table 的相关语句。 不能配置只执行某一次特定的事件。 每台 slave 都会记录一个 binlog 的坐标：文件名称和这个文件中已经处理到什么位置。这就意味着多个 slave 可以正在执行同一个 binlog 的不同部分。因为是 slave 在控制这个过程， slave 可以随意连接、断开 master 而不影响 master 操作。而且这意味着 slave 可以断开、重连、恢复处理。 master 和每一个 slave 都必须有一个唯一的 server-id(https://dev.mysql.com/doc/refman/5.7/en/replication-options.html#option_mysqld_server-id)，并且需要通过 CHANGE MASTER TO 语句提供 master 主机地址、日志文件名称、日志文件位置等信息(https://dev.mysql.com/doc/refman/5.7/en/change-master-to.html)。这部分细节存储在 slave 的 master info repository， 可以是一个文件，也可能存储在一个表中(https://dev.mysql.com/doc/refman/5.7/en/slave-logs.html)。 首先，掌握一些基础命令，有助于后面的配置 控制 master 的语句 (SQL Statements for Controlling Master Servers) （https://dev.mysql.com/doc/refman/5.7/en/replication-master-sql.html） SHOW BINARY LOGS(1) SHOW BINLOG EVENTS(2) SHOW MASTER STATUS SHOW SLAVE HOSTS SHOW BINARY LOGS 等同于 SHOW MASTER LOGS. 需要权限. 支持指定文件名、位置等，见 https://dev.mysql.com/doc/refman/5.7/en/show-binlog-events.html； 大数据量耗费较多时间，可用 mysqlbinlog 工具代替，见 https://dev.mysql.com/doc/refman/5.7/en/mysqlbinlog.html. 控制 slave 的语句 (SQL Statements for Controlling Slave Servers) （https://dev.mysql.com/doc/refman/5.7/en/replication-slave-sql.html） CHANGE MASTER TO(1) CHANGE REPLICATION FILTER MASTER_POS_WAIT() RESET SLAVE SET GLOBAL sql_slave_skip_counter START SLAVE STOP SLAVE SHOW SLAVE STATUS and SHOW RELAYLOG EVENTS 内容参考 https://dev.mysql.com/doc/refman/5.7/en/change-master-to.html，关注点： 是否需要先 stop slave 多线程的 slave 下可能出现的间隙问题（gaps）以及 START SLAVE UNTIL SQL_AFTER_MTS_GAPS CHANGE MASTER TO .. FOR CHANNEL channel 的用法, 更多 Replication Channel 参考 https://dev.mysql.com/doc/refman/5.7/en/replication-channels.html 未指定的选项保留旧的值。 【重要】如果指定了 MASTER_HOST 或者 MASTER_PORT，即使值没有变化，mysql 也认为 master 主机也跟以前不一样了。这种情况下，binlog的文件名和位置就失效了，所以如果不指定 MASTER_LOG_FILE 和 MASTER_LOG_POS，mysql默认添加上 MASTER_LOG_FILE='' 且 MASTER_LOG_POS = 4。 ssl 相关的配置，MASTER_SSL_XXX 和 --ssl-XXX (https://dev.mysql.com/doc/refman/5.7/en/encrypted-connection-options.html) 功能一样。 心跳检测相关的选项（比如 MASTER_HEARTBEAT_PERIOD 不指定，默认是系统变量 slave_net_timeout 的一半；更改 slave_net_timeout 也要适当更改其它关联选项否则不起作用等） 更改默认值并检查当前连接心跳次数： STOP SLAVE; CHANGE MASTER TO MASTER_HOST='X.X.X.X', MASTER_LOG_POS=XX, MASTER_HEARTBEAT_PERIOD=10; START SLAVE; -- 一些常用的健康表 mysql&gt; USE performance_schema; mysql&gt; SHOW TABLES LIKE "replication%"; +---------------------------------------------+ | Tables_in_performance_schema (replication%) | +---------------------------------------------+ | replication_applier_configuration | | replication_applier_status | | replication_applier_status_by_coordinator | | replication_applier_status_by_worker | | replication_connection_configuration | | replication_connection_status | | replication_group_member_stats | | replication_group_members | +---------------------------------------------+ 8 rows in set (0.00 sec) -- 检查当前配置 SELECT * FROM performance_schema.replication_connection_configuration\G -- 检查当前连接心跳次数、连接状态 SELECT * FROM performance_schema.replication_connection_status\G MASTER_DELAY 与 延迟复制 https://dev.mysql.com/doc/refman/5.7/en/replication-delayed.html MASTER_BIND 与多网卡平面有关（可用 SHOW SLAVE STATUS 查看） 一些不可同时指定的值： MASTER_LOG_FILE or MASTER_LOG_POS 与 RELAY_LOG_FILE or RELAY_LOG_POS 不可同时指定。 MASTER_LOG_FILE or MASTER_LOG_POS 与 MASTER_AUTO_POSITION = 1 不可同时指定。 MASTER_LOG_FILE or MASTER_LOG_POS 如果不指定，使用之前的旧值。 【重要】relaylog 的删除 In MySQL 5.7.4 and later, relay logs are preserved if at least one of the slave SQL thread and the slave I/O thread is running; if both threads are stopped, all relay log files are deleted unless at least one of RELAY_LOG_FILE or RELAY_LOG_POS is specified. MASTER_AUTO_POSITION = 1 When MASTER_AUTO_POSITION = 1 is used with CHANGE MASTER TO, the slave attempts to connect to the master using the GTID-based replication protocol. From MySQL 5.7, this option can be employed by CHANGE MASTER TO only if both the slave SQL and slave I/O threads are stopped. Both the slave and the master must have GTIDs enabled (GTID_MODE=ON, ON_PERMISSIVE, or OFF_PERMISSIVE on the slave, and GTID_MODE=ON on the master). Auto-positioning is used for the connection, so the coordinates represented by MASTER_LOG_FILE and MASTER_LOG_POS are not used, and the use of either or both of these options together with MASTER_AUTO_POSITION = 1 causes an error. If multi-source replication is enabled on the slave, you need to set the MASTER_AUTO_POSITION = 1 option for each applicable replication channel.（https://dev.mysql.com/doc/refman/5.7/en/replication-gtids-auto-positioning.html） Replication 与 binlog 的选项、变量(Replication and Binary Logging Options and Variables) （https://dev.mysql.com/doc/refman/5.7/en/replication-options.html） 基于GTIDs的复制 MySQL multi-Source replication 在上线机器上更改复制模式 复制与日志记录选项和变量 常用复制管理任务 replication 实现 replication 用途 半同步复制 https://dev.mysql.com/doc/refman/5.7/en/replication-semisync.html mysql 默认是异步同步，master 把操作写到 binlog 里，但是不关心 slave 是否（或者何时）收到（或者处理）这些事件。这种方式下，master 如果崩溃，可能来不及把其已经提交的事务传输给任何一个 slave。 Consequently, failover from master to slave in this case may result in failover to a server that is missing transactions relative to the master. 半同步可以作为异步的一种替代： 1. 当 slave 连接到主机的时候，它会提示 master，自己是否支持半同步 2. 当 master 开启了半同步，并且有至少一台开启了半同步的 slave 连接到了 master，那么任何一个执行事务的线程，就会一直等待，至少一个开启了半同步的 slave 反馈其收到了这个事务相关的全部日志（或者达到一个超时时间），然后才会 commit； 3. slave 只有在收到事件、把事件写入到 relaylog 并刷到磁盘后，才会向 master 发出这个反馈； 4. 当超时时间已经达到，master 还没有收到任何反馈，其会转成异步模式；一旦任何一个 slave 赶上（步骤3完成？），master 还会继续转回半同步模式。 5. 半同步必须在 master 和 slave 同时开启，任何一方没有开启，都是异步的模式。 管理界面 安装配置 监控 实战 如何在主从不同步的情况下，重新同步主从? 在我的测试机器上面，我在多次运行测试语句后，发现主机上有从机不存在的表。现在我想重新让两者同步，怎么办？ -- master RESET MASTER; FLUSH TABLES WITH READ LOCK; SHOW MASTER STATUS; mysqldump -u root -p --all-databases &gt; /a/path/mysqldump.sql scp /a/path/mysqldump.sql TO SLAVE /b/path/mysqldump.sql UNLOCK TABLES; -- slave mysql -uroot -p &lt; mysqldump.sql RESET SLAVE; CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000001', MASTER_LOG_POS=154; START SLAVE; SHOW SLAVE STATUS; https://stackoverflow.com/questions/2366018/how-to-re-sync-the-mysql-db-if-master-and-slave-have-different-database-incase-o https://dev.mysql.com/doc/refman/5.7/en/reset-master.html]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[测试驱动开发的一个示例代码——求质因数]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190210%20prime_number%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637package test;import java.util.ArrayList;import java.util.Arrays;import java.util.List;public class TestMain &#123; public static int[] getPrimeFactor(int input) &#123; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); switch (input) &#123; case 0 | 1: result.add(input); break; default: result = doSth(input); &#125; return Arrays.stream(result.toArray(new Integer[result.size()])) .mapToInt(Integer::intValue) .toArray(); &#125; private static List&lt;Integer&gt; doSth(int input) &#123; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); for (int i = 2; i &lt;= input; i++) &#123; while (input % i == 0) &#123; result.add(i); input /= i; &#125; &#125; return result; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package test;import org.junit.Assert;import org.junit.Test;public class TestTest &#123; @Test public void shouldReturn0Given0()&#123; int[] expect = &#123;0&#125;; Assert.assertArrayEquals(TestMain.getPrimeFactor(0), expect); &#125; @Test public void shouldReturn1Given1()&#123; int[] expect = &#123;1&#125;; Assert.assertArrayEquals(TestMain.getPrimeFactor(1), expect); &#125; @Test public void shouldReturn2Given2()&#123; int[] expect = &#123;2&#125;; Assert.assertArrayEquals(TestMain.getPrimeFactor(2), expect); &#125; @Test public void shouldReturn3Given3()&#123; int[] expect = &#123;3&#125;; Assert.assertArrayEquals(TestMain.getPrimeFactor(3), expect); &#125; @Test public void shouldReturn2_2Given4()&#123; int[] expect = &#123;2,2&#125;; Assert.assertArrayEquals(TestMain.getPrimeFactor(4), expect); &#125; @Test public void shouldReturn5Given5()&#123; int[] expect = &#123;5&#125;; Assert.assertArrayEquals(TestMain.getPrimeFactor(5), expect); &#125; @Test public void shouldReturn2_3Given6()&#123; int[] expect = &#123;2,3&#125;; Assert.assertArrayEquals(TestMain.getPrimeFactor(6), expect); &#125; @Test public void shouldReturn2_2_2Given8()&#123; int[] expect = &#123;2,2,2&#125;; Assert.assertArrayEquals(TestMain.getPrimeFactor(8), expect); &#125; @Test public void shouldReturn3_3Given9()&#123; int[] expect = &#123;3,3&#125;; Assert.assertArrayEquals(TestMain.getPrimeFactor(9), expect); &#125; @Test public void shouldReturn2_5Given10()&#123; int[] expect = &#123;2,5&#125;; Assert.assertArrayEquals(TestMain.getPrimeFactor(10), expect); &#125; @Test public void shouldReturn3_5Given15()&#123; int[] expect = &#123;3,5&#125;; Assert.assertArrayEquals(TestMain.getPrimeFactor(15), expect); &#125; @Test public void shouldReturn2_2_5_5Given100()&#123; int[] expect = &#123;2,2,5,5&#125;; Assert.assertArrayEquals(TestMain.getPrimeFactor(100), expect); &#125; @Test public void shouldReturn13_13Given169()&#123; int[] expect = &#123;13,13&#125;; Assert.assertArrayEquals(TestMain.getPrimeFactor(169), expect); &#125;&#125;]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysqldump_迁移数据]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190210%20mysql_dump%2F</url>
    <content type="text"><![CDATA[.strike&#123; text-decoration:line-through &#125; mysqldump 迁移数据 背景 客户N在使用H部门提供的mysql遇到部分性能问题后，未得到H部门的及时支撑。机缘巧合，我们的服务化mysql刚刚发布第一版，客户N有意切换我们的mysql。由于部门策略调整，我们准备由原来的社区mysql切换为部门R的商业版mysql，其间对接问题不提，客户提出的首要问题是前期尝试通过mysqldump备份数据，发现有报错并且很慢，我们的策略是 为拓展业务先把锅接下来吧 答应先提供数据迁移方案供客户评估。 机器、数据、应用情况 源机器cpu核心数16，内存32G； 两台机器，一个是master，一个是slave；未配置互为主备； 开启了基于GTID的主从复制； 从镜像库来看，数据量3800W左右，实际生产环境每天还会增加约不到100w； 0-1w 1w-10w 10w-50w 50w-100w 100w-1000w &gt;1000w 表数量约 2105 83 28 5 6 1 mysql为社区版5.7.23，所有表均为INNODB引擎； 据客户N的业务人员反馈，他们尝试使用mysqldump可能会报错。 一些准备工作 为了能够顺滑的开展后期工作，我习惯先整理一些常用的命令，以备随时复制粘贴&#8230;&#8203; -- 查询所有业务数据库的表名，数据库，存储引擎信息 select table_name,table_schema,engine from information_schema.tables where engine='innodb' and table_schema not in('mysql','information_schema','performance_schema','sys'); -- 查询所有业务数据库的表的数量 select count(*) from information_schema.tables where engine='innodb' and table_schema not in('mysql','information_schema','performance_schema','sys'); -- 查询所有表的数据量 SELECT CONCAT(TABLE_SCHEMA,'.',TABLE_NAME) AS table_name, IFNULL(TABLE_ROWS,0) as table_rows FROM information_schema.tables WHERE TABLE_SCHEMA NOT IN ('mysql','information_schema','performance_schema','sys') ORDER BY 2; -- 查询所有业务数据库的视图数量 select table_name,table_schema from information_schema.views where table_schema not in ('mysql','information_schema','performance_schema','sys'); select count(*) from information_schema.views where table_schema not in ('mysql','information_schema','performance_schema','sys'); -- 查询所有routines(存储过程和函数)的数量 select * from mysql.proc where db not in ('mysql','information_schema','performance_schema','sys')\G -- 查询所有触发器的数量 SELECT * FROM information_schema.triggers where TRIGGER_SCHEMA not in ('mysql','information_schema','performance_schema','sys')\G -- 查询所有事件的数量 SELECT * FROM information_schema.EVENTS where EVENT_SCHEMA not in ('mysql','information_schema','performance_schema','sys')\G -- 查询所有用户数量 select user,host from mysql.user; -- 查看磁盘IO信息 iostat -x -p /dev/mapper/vg02-lv02 1 10 -m iostat -x -p 1 10 -m 首先尝试使用原生mysqldump 业务诚不欺我，果然有坑，报错如下(安全需要，隐藏关键信息)。 Warning mysqldump: Couldn&#8217;t execute 'SHOW FIELDS FROM `XX&#8217;: View 'XX.XX' references invalid table(s) or column(s) or function(s) or definer/invoker of view lack rights to use them (1356) 报错信息很明显了，本次实践中，主要是视图引用创建语句中子查询的列不存在，select 都会报错，这个我们只能让业务自己去审视，决策是否删除或者修复。 由于通过mysqldump来发现那些视图有问题非常不效率，所有写了一个简单的脚本： 搜集所有有问题的视图 #!/usr/bin/env bash function usage &#123; echo "Usage: $0 [-u USER_NAME] [-p PASSWORD] [-d WORKDIR] [-D:DROP ERROR VIEWS]" echo "Do not support -uroot, using -u root please." # too 2 exit 2 &#125; function set_variable &#123; local varname=$1 shift if [[ -z "$&#123;!varname&#125;" ]]; then eval "$varname=\"$@\"" else echo "Error: $varname already set" usage fi &#125; function execMysqlCommand &#123; mysql -u$&#123;USER_NAME&#125; -p$&#123;PASSWORD&#125; --skip-column-names -e "$1" &#125; function checkView &#123; viewName="$1" # too slow # mysql -u$&#123;USER_NAME&#125; -p$&#123;PASSWORD&#125; -e "select 1 from $&#123;viewName&#125; limit 1" &gt;/dev/null 2&gt;&gt;/home/mysql/temp/view_error # not good either # mysql -u$&#123;USER_NAME&#125; -p$&#123;PASSWORD&#125; -e "update $&#123;viewName&#125; set thisIsANotExistCol=123;" &gt;/dev/null 2&gt;&gt;/home/mysql/temp/view_error # execMysqlCommand "show fields from $&#123;viewName&#125;;" &gt;/dev/null 2&gt;&gt;/home/mysql/temp/view_error return $? &#125; function checkAllViewsAndGetErrorViews &#123; echo ""&gt;/home/mysql/temp/view_error i=1 for view in $&#123;views[@]&#125;;do echo -n "checking $view ...$i/$&#123;#views[@]&#125;" "..." checkView $&#123;view&#125; result=$? [[ $&#123;result&#125; -ne 0 ]] &amp;&amp; echo "bad" [[ $&#123;result&#125; -ne 0 ]] &amp;&amp; echo "pass" ((i++)) done; cat /home/mysql/temp/view_error|grep "1356"|awk -F"'" '&#123;print $2&#125;'&gt;/home/mysql/temp/error_list rm /home/mysql/temp/view_error -rf error_views=(`cat /home/mysql/temp/error_list`) &#125; function printIgnoreMsg &#123; [[ $&#123;#error_views[@]&#125; -gt 0 ]] &amp;&amp; echo "You can add these statements to mysqldump to ignore those error views:" for view in $&#123;error_views[@]&#125;;do echo -n " --ignore-table=$&#123;view&#125;" done echo "" &#125; function backupErrorViewsSql &#123; echo "Backing up create statement of error views to $&#123;WORKDIR&#125;..." echo "" &gt; /home/mysql/temp/backup_create_view_sql -rf for view in $&#123;error_views[@]&#125;;do execMysqlCommand "show create view $view;" &gt;&gt;/home/mysql/temp/backup_create_view_sql 2&gt;/dev/null done cat /home/mysql/temp/backup_create_view_sql|awk -F'\t' '&#123;print $2";"&#125;'|grep -v 'Create View;'&gt;&gt;/home/mysql/temp/backup_create_view rm -rf /home/mysql/temp/backup_create_view_sql echo "Done backing up create statement of error views." &#125; function deleteErrorViews &#123; echo "Dropping error views..." for view in $&#123;error_views[@]&#125;;do while [[ "X" == "X$&#123;confirm&#125;" ]];do read -p "please confirm to delete $&#123;view&#125;:(y/n)" confirm done if [[ "Xy" == "X$&#123;confirm&#125;" ]];then execMysqlCommand "drop view $view;" 2&gt;/dev/null fi done echo "Done dropping error views." &#125; init() &#123; unset DELETE_VIEWS USER_NAME PASSWORD WORKDIR while getopts 'u:p:d:D?h' option do case $&#123;option&#125; in d) set_variable WORKDIR $OPTARG ;; D) set_variable DELETE_VIEWS true ;; u) set_variable USER_NAME $OPTARG ;; p) set_variable PASSWORD $OPTARG ;; h|?) usage ;; esac done [[ -z "$&#123;USER_NAME&#125;" ]] &amp;&amp; usage [[ -z "$&#123;PASSWORD&#125;" ]] &amp;&amp; usage [[ -z "$&#123;WORKDIR&#125;" ]] &amp;&amp; set_variable WORKDIR "/home/mysql/temp" &amp;&amp; mkdir -p $&#123;WORKDIR&#125; echo "Using directory $&#123;WORKDIR&#125; as temp dir." &#125; getAllViews() &#123; echo "Getting all views from schema..." views=(`execMysqlCommand "select concat(table_schema,'.',table_name) from information_schema.views where table_schema not in ('mysql','information_schema','performance_schema','sys');" 2&gt;/dev/null`) &#125; init $@ getAllViews checkAllViewsAndGetErrorViews printIgnoreMsg [[ X"true" == X"$&#123;DELETE_VIEWS&#125;" &amp;&amp; $&#123;#error_views[@]&#125; -gt 0 ]] &amp;&amp; backupErrorViewsSql &amp;&amp; deleteErrorViews 命令优化x 具体方案之前，先加上一些基本的备份对象 --hex-blob --single-transaction --quick --routines --triggers 方案一 160分钟 单线程直接执行mysqldump，大概160分钟 &gt; /data01/chroot/usr/local/mysql5.7.23/bin/mysqldump -udbXXXX -pXXXX --all-databases --hex-blob --ignore-table=netcxx.xxxxx --ignore-table=netxxx.rxxx(此处很多忽略的视图) | gzip &gt; /temp/back0129.sql.gz 方案二 90分钟 考虑一个表一个文件，10个线程，大概90分钟；TODO 测试增加线程 multidump.sh[lines=25..55] multidump() &#123; rm -rf $&#123;WORKDIR&#125;/backup mkdir -p $&#123;WORKDIR&#125;/backup COMMIT_COUNT=0 COMMIT_LIMIT=10 error_views_file="$&#123;WORKDIR&#125;/error_list" DBTBS=(`cat $&#123;WORKDIR&#125;/listOfTables`) i=1 for DBTB in $&#123;DBTBS[@]&#125;;do echo "processing $i/$&#123;#DBTBS[@]&#125;" ((i++)) DB=`echo $&#123;DBTB&#125; | sed 's/\./ /g' | awk '&#123;print $1&#125;'` TB=`echo $&#123;DBTB&#125; | sed 's/\./ /g' | awk '&#123;print $2&#125;'` if [[ "X"`grep -w $&#123;DBTB&#125; $&#123;error_views_file&#125;` != X"" ]];then echo skip "$&#123;DBTB&#125;" continue fi dumpIt $&#123;DB&#125; $&#123;TB&#125; (( COMMIT_COUNT++ )) if [[ $&#123;COMMIT_COUNT&#125; -eq $&#123;COMMIT_LIMIT&#125; ]] then COMMIT_COUNT=0 wait fi done if [[ $&#123;COMMIT_COUNT&#125; -gt 0 ]] then wait fi &#125; 方案三 15-22分钟 mysqlpump 是 mysql 提供的工具，文档和网上教程一大堆，这里只谈使用。 可以很直观的看到执行到哪个表，剩余多少行；注意：mysqlpump遇到错误会停止继续，比如命令不正确、数据结构有问题。而且这个数据库开启GTID，所以如果你的数据库没有此选项，要把命令中的&#8212;&#8203;set-gtid-purged=ON去掉。 两种压缩格式的时间差距还是很明显： Example 1. zlib格式 可用 zlib_decompress 解压；100个线程的mysqlpump，时间大概22分钟 mysqlpump -uusername -ppassword --compress-output=ZLIB --default-parallelism=100 --set-gtid-purged=ON --hex-blob --add-drop-database --add-drop-table --add-drop-user --users |gzip &gt; /temp/test.sql.gz Dump progress: 0/xx tables, xx/xxxxxxxxx rows Dump completed in xxxxxx milliseconds Example 2. lz4 15分钟 可用 lz4_decompress 解压 mysqlpump -uusername -ppassword --compress-output=LZ4 --default-parallelism=100 --set-gtid-purged=ON --hex-blob --add-drop-database --add-drop-table --add-drop-user --users &gt; /temp/testlz4.lz4 方案四 mysqlpump 可以针对database进行多线程导出，但是有时候数据分布不均匀，90%的数据可能都在一个表内，这种情况下mysqlpump显得无能为力。有没有可以对单个大表继续进行分拆的工具呢？ mydumper 可以做这件事。 首先统计表的分布 totalSql="SELECT IFNULL(SUM(TABLE_ROWS),0) as t_rows_sum FROM information_schema.tables WHERE TABLE_SCHEMA NOT IN ('mysql','information_schema','performance_schema','sys');" eachTableSql="SELECT CONCAT(TABLE_SCHEMA,'.',TABLE_NAME) AS table_name, IFNULL(TABLE_ROWS,0) as table_rows FROM information_schema.tables WHERE TABLE_SCHEMA NOT IN ('mysql','information_schema','performance_schema','sys') ORDER BY 2;" 验证mydumper导出database的效率 只导出netcare，17分钟-20分钟左右 mydumper -u username -p password -v 3 -B databaseName --triggers --events --routines --rows=500000 --compress-protocol -c -t threadNum.ie.100 --trx-consistency-only --outputdir /temp/mydumper 验证mydumper导出某一个大表的效率 方案五(最终方案) https://dev.mysql.com/doc/mysql-enterprise-backup/8.0/en/ 方案五 优化前：21分钟 unset tempdir tempdir=/data03/backup_`date '+%y%m%d%H%M%S'` mkdir $&#123;tempdir&#125; ~/mysqlbackup -udbAdmin -pabcd1234 --backup-dir=$&#123;tempdir&#125; --compress backup echo "Successfully backing up data to $&#123;tempdir&#125;" # 有待优化 https://dev.mysql.com/doc/mysql-enterprise-backup/4.1/en/backup-capacity-options.html --limit-memory=MB （default 100） --read-threads=num_threads （default 1） --process-threads=num_threads （default 6） --write-threads=num_threads （default 1） ~/mysqlbackup -udbAdmin -pabcd1234 --backup-dir=$&#123;tempdir&#125; --compress backup #优化后： 15分钟 # 整库备份到单个文件 ~/mysqlbackup -udbAdmin -pabcd1234 --compress --compress-level=5 --limit-memory=1024 --read-threads=10 --process-threads=15 --write-threads=10 --backup-dir=$&#123;tempdir&#125; --backup-image=/data03/`basename $&#123;tempdir&#125;`.bin backup-to-image #直接备份到目标机器： ~/mysqlbackup -udbAdmin -pabcd1234 --compress --compress-level=5 --limit-memory=1024 --read-threads=10 --process-threads=15 --write-threads=10 --backup-dir=$&#123;tempdir&#125; --backup-image=- backup-to-image | ssh root@10.15.32.73 'cat &gt; /opt/temp_for_restore/my_backup.bin' 具体备份恢复使用见另一篇文章 mysql gtid 主从复制数据迁移(物理备份)]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysqldump</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vmware+centos7 双网卡平面设置]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190210%20vmware%2Bcentos7%20%E5%8F%8C%E7%BD%91%E5%8D%A1%E5%B9%B3%E9%9D%A2%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[[root@host1 ~]# ip a 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:7d:ba:48 brd ff:ff:ff:ff:ff:ff inet 192.168.17.101/24 brd 192.168.17.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 fe80::64ee:1323:6aaa:61da/64 scope link noprefixroute valid_lft forever preferred_lft forever 3: ens37: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:7d:ba:52 brd ff:ff:ff:ff:ff:ff inet 192.168.44.129/24 brd 192.168.44.255 scope global noprefixroute dynamic ens37 valid_lft 1083sec preferred_lft 1083sec inet6 fe80::6ccf:c498:99ff:1910/64 scope link noprefixroute valid_lft forever preferred_lft forever [root@host1 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens33 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=static IPADDR=192.168.17.101 GATEWAY=192.168.17.1 NETMASK=255.255.255.0 DNS1=8.8.8.8 DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=ens33 UUID=fe4b3f1d-a5da-47e6-bacf-a4341d936b2f DEVICE=ens33 ONBOOT=yes [root@host1 ~]# ---]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>vmware</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次 mysql 死锁问题解决]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190210%20%E4%B8%80%E6%AC%A1%20mysql%20%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[一个业务反应，环境多次出现大量服务不可使用，如app导入不响应，用户更新超时，bpm创单超时等等。查看数据库的processlist，发现有大量的处于Waiting for table metadata lock状态的查询，其中包含T_APP_INFO、TBL_UM_USER、T_TICKET_BASICINFO等表，跟故障服务一致，确定故障原因是数据库锁表引起； 业务自行导出所有的阻塞task，并按照阻塞时间排序，发现第一条引起阻塞的是一条来来自于localhost的 由root用户发起的批量锁表语句，疑似是问题根因。 上面这段是业务说的，已经排查的比较深入了，给个赞。 我之前通过直接kill掉这个query线程，他们的业务就正常走下去了，因为忙其他事情，所以就没有再关注。后面他们又出现了这个问题，这次必须要解决了。所以记录一下定位过程。 定位思路 [WHAT] root@localhost 的进程在做什么？ mysql 所有“卡住”问题，先看进程列表： show processlist; +---------+------+-----------+------+---------+------+----------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +---------+------+-----------+------+---------+------+----------+------------------+ | 3467133 | root | localhost | NULL | Query | 320400 | Waiting for table metadata lock | LOCK TABLES `....| +---------+------+-----------+------+---------+------+----------+------------------+ 看到 root@localhost 的用户，有一条状态为 Waiting for table metadata lock 的查询。查询语句为“LOCK TABLES&#8230;&#8203;&#8230;&#8203;”。 Note 猜测：是后台备份进程在锁表，由于也有可能业务自己登陆后台锁表，所以需要证明这个确实是备份工具发起的语句。 证明：当前时间是2月12日下午，Time 时间显示此语句已经等待320400s（约89小时），往前推算约为2月9日凌晨0点。后台备份文件夹有一个0点的文件夹，里面备份文件为0字节。 [QUESTION] 为什么会导致这个问题出现 在 https://dev.mysql.com/doc/refman/5.7/en/mysqldump.html#option_mysqldump_databases 第一句就有，mysqldump 如果不加 --single-transaction，执行mysqldump的用户就必须有LOCK TABLES的权限，由此推出，这种情况（不加 --single-transaction，当前gts mysql方案）下，就会锁表。那么这种锁表行为分不分存储引擎呢？答案是myisam都会锁表，而innodb会在&#8212;&#8203;single-transaction的时候不锁表，详见官网。 由于业务在show processlist;的时候，还看到了有另外一条语句B select * from activemq_lock for update; 那么即使有这条语句在执行，如果其正常提交了事务，也不会阻塞备份工具锁表。业务由于直接用的开源activemq，所以也说不清楚这个表的作用，那么问题出在哪里？ [控制变量] 和正常的环境来对比 顶着业务的各种不满（业务：我也学会kill进程了，你要解决根本问题啊，不能再kill了），直接再次kill掉这个进程，查看正常环境的状态。发现语句B始终存在，并且show processlist发现该语句的Time一直在变化。说明其一直在频繁执行。 Note 猜测：语句B一直在执行获取锁，mysqldump在备份前先 LOCK TABLES 所有表，其它表都正常锁住，唯有这个表获取不到锁，就一直等待。而其它被锁住的表，此时是无法更新的。 证明：当前环境再次手工执行一把备份，发现备份脚本卡住，查看processlist，发现与问题描述表现一致。此时业务果然发生了上面的问题。 解决方法 疑问点 早有耳闻mysqldump有&#8212;&#8203;skip-lock-tables、--single-transation、--ignore-table的选项，但是由于不熟悉，所以还要自己验证一番，看看各个参数是不是如自己所想： --skip-lock-tables 是跳过获取不到锁的表，还是备份前不加锁，还是备份的语句里面不加锁（曾被误导，以为是备份后的语句） --single-transaction 看起来和锁没什么关系，能不能达到我们的目的呢？ --ignore-table 是忽略表和视图的意思，如果忽略这个表，那还会不会锁住这个表呢？ 验证 带着上面的疑问去自己的测试数据库验证，首先了解本例涉及到的几种锁以及如何构造它们： 我们常使用的锁，语句一般就几种： flush tables with read lock; lock tables tablename read; select * from table name for update; -- 其它 share mode 等暂不谈，也不在此老生常谈排他锁、互斥锁、只读锁等的概念。 研究如下： 说明 影响 如何定位这种锁 如何释放 进阶 flush tables with read lock; 全部的表都刷上read lock 执行此语句的session，在修改数据会收到报错：ERROR1223 cant execute query because you hanve a conflicting lock. 其它session，在修改数据会卡住。 1. 无法通过show open tables查看 2. 无法通过information_schema.innodb_locks等表查看 3. 无法通过show engine innodb status\G查看 4. 其它被锁住的session，可以通过show processlist;查看到状态:Waiting for global read lock session结束或者unlock tables; 在手工备份的时候很好用 lock tables t_test read; 只对某一个表刷上read lock 1. 执行此语句的session，在修改数据会收到报错：ERROR1099 table … was locked with read lock and cant be updated. 2. 只能查询锁住的表，如果查询其它的表，也会失败 其它session，在修改数据会卡住。 1. show open tables 可以看到表的 in_use + 1 2. 无法无法通过information_schema.innodb_locks等表查看 3. show engine innodb status\G其中的 transactions 一列显示 mysql tables in use 1,locked 1 4. 其它被锁住的session，可以通过show processlist;查看到状态: Wating for table metadata lock session结束或者unlock tables;还有其它一些场景会释放锁，比如alter table，详见官网文档； 释放锁会默认提交事务，具体详见官网文档 select * from t_test for update; 对某一个表刷上排他锁。 只能在一个事务中使用，不在事务中无效 ， 使用见附录 执行此语句的session，就是为了更改数据。 其它session，在修改数据会卡住。 1. show open tables 可以看到表的 in_use + 1 2. 无法无法通过information_schema.innodb_locks等表查看 3. show engine innodb status\G其中的 transactions 一列显示 2 lock stucts, 2 row lock(表数据行+1数量的锁) 4. 其它被锁住的session，可以通过show processlist;查看到状态: Wating for table metadata lock commit; 其它未commit的异常状态，锁也会随着session关闭释放掉，具体见官网文档" 行锁需要有主键或者索引 。本例无，所以是表锁的效果。 经过组合 select * from t_test for update 和 lock tables t_test read; 重现了业务的问题。后续经过验证，上面提到的 mysqldump 的三个参数，都可以达到目的： 方案 说明 缺点 1. mysqldump –skip-lock-tables 备份前，不加锁 无法保证数据一致性 2. mysqldump –single-transaction 备份在一个事务中进行 备份期间表定义变化等可能导致备份失败（重新执行一次备份即可） 3. mysqldump –ignore-table=activemq_lock 略过该表，不会获取锁 不备份该表 附录 select&#8230;&#8203;for update 的使用方法 begin; select * from t_test for update; commit; begin; select * from t_test where id=1111 for update; commit; https://dev.mysql.com/doc/refman/5.7/en/select.html lock tables 的使用方法 lock tables t_test read; 参考： https://dev.mysql.com/doc/refman/5.7/en/select.html https://dev.mysql.com/doc/refman/5.7/en/lock-tables.html https://dev.mysql.com/doc/refman/5.7/en/mysqldump.html#option_mysqldump_databases]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[suse 新增磁盘]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190210%20suse%20%E6%96%B0%E5%A2%9E%E7%A3%81%E7%9B%98%2F</url>
    <content type="text"><![CDATA[fdisk -l DISK=vdb disk_list=(`cat /proc/partitions | sort | grep -v "name" |grep -v "loop" |awk '&#123;print $4&#125;'| sed /^[[:space:]]*$/d | grep -v "[[:digit:]]" | uniq`) parted -s /dev/$&#123;DISK&#125; mklabel gpt parted -s /dev/$&#123;DISK&#125; print |grep softhome |wc -l DISKSIZE=`parted -s /dev/$&#123;DISK&#125; unit GB print | grep '^Disk' |grep GB | awk '&#123;print $3&#125;'` DISK1=`echo $&#123;DISK&#125;1` # parted -s /dev/$&#123;DISK&#125; mkpart softhome 0G $DISKSIZE parted -s /dev/$&#123;DISK&#125; set 1 lvm vgname=`echo "/opt" | awk -F'/' '&#123;print $NF&#125;'` vgname="$&#123;vgname&#125;vg" # optvg lvname=`echo "/opt" | awk -F'/' '&#123;print $NF&#125;'` lvname="$&#123;lvname&#125;lv" # optlv echo y | pvcreate /dev/$&#123;DISK1&#125; vgcreate "$vgname" /dev/$&#123;DISK1&#125; free=`vgdisplay "$vgname" |grep "Total PE" |awk '&#123;print $3&#125;'` echo y | lvcreate -l "$free" -n "$lvname" "$vgname" lvPath=`lvdisplay "$vgname" | grep "LV Path" | awk '&#123;print $3&#125;'` #格式化 mkfs.ext4 "$&#123;lvPath&#125;" #挂载 mount -t ext4 $&#123;lvPath&#125; /opt cat /etc/fstab | grep -w $lvPath #永久 echo "$lvPath $&#123;PATHS&#125; ext4 defaults 1 0" &gt;&gt; /etc/fstab]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql gtid 主从复制数据迁移(物理备份)]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190212%20mysql_gtid_%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB%2F</url>
    <content type="text"><![CDATA[方案整体概览 安装好商业版本的mysql 使用mysqlbackup备份旧库主机的数据 停掉新库两台mysql，清空后台文件，恢复数据 新库相互配置主从复制 新库主机作为从机对接到旧库主机，同步数据 切断新库主机和旧库主机的主从复制 除第6步外，全innodb的库（netcare满足）不需要锁表 解决问题记录： mysqldump报错 mysqldump过慢，修复报错后备份也需要2个半小时 开发多线程mysqldump，最终90分钟，太慢，弃用 mysqlpump 多线程 优化到22分钟 mysqlpump 多线程 lz4 压缩 17分钟 mysqlpump 等逻辑备份导入过慢且表现不稳定（每次备份数据不一致），弃用逻辑备份方案 mysqlbackup 文件夹备份 20分钟 压缩过慢 一个小时未结束 mysqlbackup 单文件本地备份 lz4 压缩 15分钟 mysqlbackup 无法恢复数据 恢复数据后无法启动的几种错误 mysqlbackup 恢复数据4分钟 GITD 主从复制恢复 主从复制新主-旧主恢复 主从复制新主-新从恢复 前提 安装好软件平台 mysql。 步骤 0 检查环境 版本 旧库5.7.23 community， 新库5.7.24 commercial (netcare specified) 表和视图等，自检 业务自行检查库是否正常，可以使用我们开发的小工具checkViews.sh（请索要）检查部分视图（此工具只检查视图，不排除还有其它非视图问题引起的问题）。 本例中netcare视图有问题，已做删除处理。 旧库复制状态 比如组网，和当前状态。 netcare为单向主备。在备机SHOW SLAVE STATUS\G查看复制状态正常。 表的存储引擎 select table_name,table_schema,engine from information_schema.tables where engine='innodb' and table_schema not in('mysql','information_schema','performance_schema','sys'); 本例业务表全是innodb，不需要考虑锁表问题，也好选择备份工具，方便很多。 是否开启GTID的主从复制 查看/opt/mysql/.my.cnf里gtid_mode=ON还是OFF。未开GTID模式的库不适用此文。 当前机器有mysqlbackup工具吗 检查磁盘和数据的大小 检查当前mysql的状态 检查端口 检查mysql的端口，本例是3306，是否开启了防火墙策略，如果没有开启（在新机器上telnet ip 3306看一下），需要走电子流。 检查22端口（高危，不好开）是否互通，如果不互通，需要花费时间下载文件到中转机，再上传到新库；如果互通，可以使用mysqlbackup直接备份到远端，可以节省大量时间（本例3个小时）。 步骤 1 导出备份数据 准备 安装 mysqlbackup 工具 如果旧库没有mysqlbackup，需要从新库中拷贝一个mysqlbackup到旧库任意位置，比如/root；然后赋予其可执行权限。 准备好各种用户名和密码 备份 此过程花费约20分钟 登录旧库主机，例如 10.1.9.195，拷贝以下命令执行 unset tempdir tempdir=/data03/backup_`date '+%y%m%d%H%M%S'` mkdir $&#123;tempdir&#125; ~/mysqlbackup -uusername -pxxxxxx --compress --compress-level=5 --limit-memory=1024 --read-threads=10 --process-threads=15 --write-threads=10 --backup-dir=$&#123;tempdir&#125; --backup-image=/data03/`basename $&#123;tempdir&#125;`.bin backup-to-image ~/mysqlbackup -uusername -pxxxxxx --backup-dir=$&#123;tempdir&#125; --compress backup 老机器22端口被限制，通过跳板机下载上传一把就要5个小时。如果可以打开的话，可以通过类似下面这种命令直接备份到新机器，可以节省大量时间 ~/mysqlbackup -uusername -pxxxxxx --compress --compress-level=5 --limit-memory=1024 --read-threads=10 --process-threads=15 --write-threads=10 --backup-dir=$&#123;tempdir&#125; --backup-image=- backup-to-image | ssh root@10.15.32.73 'cat &gt; /opt/temp_for_restore/my_backup.bin' 步骤 2 验证备份数据 拷贝 如果22端口不开，出于上面已经描述过的原因，建议先将备份文件拷贝到新库主机，再从主机scp到备机。 验证 出于性能考虑，建议在新库验证。本例中，先将备份的文件 my_backup.bin 上传到了新机器的备机 /opt/temp_for_restore/ 验证。此过程花费数分钟。 mysqlbackup --backup-image=/opt/temp_for_restore/my_backup.bin validate 步骤 3 准备数据到可恢复的状态（可省略） 受制于物理备份的限制，备份过程中，正在备份的数据可能有修改，因此正常流程需要执行以下两个命令，先进行apply-log（把日志变化应用到数据中，使数据达到一致状态），再进行copy-back（恢复数据文件）。 如下： mysqlbackup .... apply-log mysqlbackup .... copy-back 但是本例在步骤5用一句命令代替，所以此步可省略。 mysqlbackup .... copy-back-and-apply-log 步骤 4 新库准备 备份配置文件 在新主和新从都要执行 mkdir /opt/backup cp /opt/mysql/.my.cnf /opt/backup/my.cnf.bak 冻结hacs集群管理 后续步骤会将mysql停止，为了防止hacs切换、拉起mysql造成干扰，需要先停止hacs集群管理功能。 在新主上执行 # 冻结和解冻集群 crm configure property maintenance-mode=true # 冻结，不会发生切换 crm configure property maintenance-mode=false # 解冻 停止mysql 在新主和新从都要执行 su - mysql mysql.server stop 清理文件 按照规范，两台机器 /opt/mysql/app/mysql-files/my.cnf 中的datadir、innodb_undo_directory、innodb_log_group_home_dir、log-bin、relay-log 的参数配置的路径下要为空。 ## 本例中，所有文件都在data下面，所以直接 mv /opt/mysql/data /opt/backup/data.bak 步骤 5 恢复数据 准备一些配置 由于新旧库几个关键配置不同，所以直接执行下面的语句会失败。 # ~/mysqlbackup --defaults-file=/opt/mysql/.my.cnf --backup-dir=/opt/temp_for_restore/ –datadir=/opt/mysql/data --uncompress copy-back-and-apply-log 在旧库主机上，找到你指定的backup-dir路径，比如/data03/backupxxxxx，找到backup-my.cnf，执行以下命令： cat /data03/&lt;backup-dir&gt;/backup-my.cnf|grep innodb 手动整理输出的结果，填入命令，最终使命令如下所示： /opt/mysql/app/product/bin/mysqlbackup --defaults-file=/opt/mysql/.my.cnf -unew_name -pnew_password --backup-image=/opt/temp_for_restore/backup_190212153601.bin --backup-dir=/opt/temp_for_restore/ --datadir=/opt/mysql/data/workdbs --innodb_data_file_path=ibdata1:12M:autoextend --innodb_log_file_size=1073741824 --innodb_log_files_in_group=4 --innodb_page_size=16384 --innodb_checksum_algorithm=crc32 --innodb_buffer_pool_filename=ib_buffer_pool --innodb_undo_tablespaces=4 --innodb_undo_logs=128 --innodb_buffer_pool_filename=ib_buffer_pool --uncompress copy-back-and-apply-log 开始恢复数据 在新主新备两台机器上，拷贝以下命令执行 # 创建data文件夹 mkdir /opt/mysql/data/workdbs # 执行数据准备和恢复 /opt/mysql/app/product/bin/mysqlbackup --defaults-file=/opt/mysql/.my.cnf -u__new_name__ -p__new_password__ --backup-image=/opt/temp_for_restore/backup_190212153601.bin --backup-dir=/opt/temp_for_restore/ --datadir=/opt/mysql/data/workdbs `--innodb_data_file_path=ibdata1:12M:autoextend --innodb_log_file_size=1073741824 --innodb_log_files_in_group=4 --innodb_page_size=16384 --innodb_checksum_algorithm=crc32 --innodb_buffer_pool_filename=ib_buffer_pool --innodb_undo_tablespaces=4 --innodb_undo_logs=128 --innodb_buffer_pool_filename=ib_buffer_pool` --uncompress copy-back-and-apply-log ## 恢复一些目录，防止启动失败 cp -r /opt/backup/data.bak/log /opt/mysql/data/ cp -r /opt/backup/data.bak/backup /opt/mysql/data/ mkdir -p /opt/mysql/data/binlog/binlog mkdir -p /opt/mysql/data/binlog/relay mkdir -p /opt/mysql/data/tmp ## 修改 /opt/mysql/.my.cnf 的配置，将此处配置修改为与旧主一样，防止启动失败 vi /opt/mysql/.my.cnf innodb_data_file_path=ibdata1:12M:autoextend ## 最后更改权限 chown -R mysql: /opt/mysql/data/ 参考 https://dev.mysql.com/doc/mysql-enterprise-backup/4.1/en/restore.compressed-backup.html 步骤 6 启动后清理 启动 su - mysql mysql.server start 清理 暂未发现要清理项。 步骤 7 重新配置主从复制 配置新主到旧主的复制 注意以下填写的 ip，基本都是对方的 ip，如果不清楚可以先查询官方文档。 在旧主执行 SET sql_log_bin=0; create user 'rpl_user'@'10.15.32.73' identified by 'rplMql_179itiADb'; grant replication slave on *.* to 'rpl_user'@'10.15.32.73'; flush privileges; SET sql_log_bin=1; 在新主执行 vi /path-to-backup_gtid_executed.sql/backup_gtid_executed.sql source /path-to-backup_gtid_executed.sql/backup_gtid_executed.sql&#8201;&#8212;&#8201;如果这里报错，show globale variables like "GTID_EXECUTED"; 与文件中是否一致，如果一致，直接执行下一步即可。 在新主执行 change master to master_host='10.1.9.195',master_port=3306, master_user='rpl_user',master_password='rplMql_179itiADb', master_auto_position=1 for channel 'rpl_temp'; UPDATE mysql.event SET status = 'SLAVESIDE_DISABLED'; 恢复新主和新从之间的主从复制 在新主执行 SET sql_log_bin=0; create user 'rpl_user'@'10.15.36.5' identified by 'rplMql_179itiADb'; grant replication slave on *.* to 'rpl_user'@'10.15.36.5'; flush privileges; SET sql_log_bin=1; 在新从执行 change master to master_host='10.15.32.73',master_port=3310, master_user='rpl_user',master_password='rplMql_179itiADb', master_auto_position=1 for channel 'rpl1'; UPDATE mysql.event SET status = 'SLAVESIDE_DISABLED'; start slave user='rpl_user' password='rplMql_179itiADb' for channel 'rpl1'; 在新从执行 SET sql_log_bin=0; create user 'rpl_user'@'10.15.32.73' identified by 'rplMql_179itiADb'; grant replication slave on *.* to 'rpl_user'@'10.15.32.73'; flush privileges; SET sql_log_bin=1; 在新主执行 change master to master_host='10.15.36.5',master_port=3310, master_user='rpl_user',master_password='rplMql_179itiADb', master_auto_position=1 for channel 'rpl1'; UPDATE mysql.event SET status = 'SLAVESIDE_DISABLED'; // 此处不要执行，留给hacs 管理 start slave user='rpl_user' password='rplMql_179itiADb' for channel 'rpl1'; 开启新主对旧主的复制 在新主执行 # 开启级联复制，旧主-&gt;新主-&gt;新从 vi /opt/mysql/.my.cnf log-slave-updates=1 mysql.server restart start slave user='rpl_user' password='rplMql_179itiADb' for channel 'rpl_temp'; 参考 https://dev.mysql.com/doc/mysql-enterprise-backup/4.1/en/advanced.slave.html 步骤 8 观察同步状态 状态查看 在新主和新从执行 show slave status\G 测试 在旧主执行 create database test; 在新主和新从执行 show database; 状态应如下图所示 更多测试请自行测试 步骤 9 恢复hacs状态 hacs 有对mysql的很多操作，肯定用到了mysql的原来的密码。因本次只为测试用途，所以未更改此处。后续需要软件人员支撑如何修改。 步骤 10 切断与切换数据库 停止新主和旧主之间的复制 在新主执行 STOP SLAVE FOR CHANNEL "rpl_temp"; # 要不要还reset，有必要清除信息吗？可以暂时保留，只停线程就行 # 但是这样hacs会不会又拉起？软件的hacs检查脚本会检查这个slave的状态吗？ 浮动 ip 绑定 这里需要业务管理员在hic上自行操作。 改回级联复制 在新主执行 vi /opt/mysql/.my.cnf log-slave-updates=0 错误 FAQ 恢复时，新库旧库关键参数配置不同，导致mysqlbackup执行失败 【解决办法】 参照步骤5 准备一些配置 一节。 恢复后，启动失败1 【解决办法】 所有启动失败的问题，思路都是看当前启动命令执行后的控制台信息，或者/opt/mysql/data/log/&#8230;&#8203;/mysqld.log。 此例解决方法为：参考步骤5 开始恢复数据 一节中的创建文件夹步骤。 恢复后，启动失败2 【解决办法】 参照步骤5 开始恢复数据 中修改my.cnf的配置项 innodb_data_file_path=ibdata1:12M:autoextend 其它重要事项记录 部分数据表设计不合理 物理备份时发现只有6万多数据的表，表文件有9.4个G大。还有其他数据量也不大的表，物理文件要比最大数据量的表还要大。 describe 看表发现有大量varchar(4000) varchar(256) longtext 等类型的字段，导致索引文件巨大。 会导致物理备份： 耗时长 占用空间大 旧库性能差，目前尚未定位原因，是否会将引起性能差的因素原样拷贝过来? 但是如果采用逻辑备份，新库是否需要重建索引的时间？ 软件的方案优化 软件平台目前采用mysqlbackup到文件夹，然后tar压缩的方式，实测tar极慢（由于上面大文件的原因）。所以本案例采用直接压缩成一个镜像的方式（压缩默认是lz4算法，极快），时间与只备份不压缩差不了多少。 修改了软件的配置 innodb_data_file_path 软件是1024M，老库是12M。不改成12无法启动。是否有其它影响？需要维护人员关注。 镜像库 本例使用镜像库测试，不知道在备份过程中数据有无刷新，此项需要业务关注测试。]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysqlbackup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 应用案例-开发环境搭建]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190217%20docker%20%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[proxy export http_proxy=http://192.168.31.159:2080 export https_proxy=https://192.168.31.159:2080]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>[object Object]</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7 docker 入门]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190217%20centos7%20docker%20%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[快速上手 install(offline) # 在有网络的机器上，执行以下命令，获取安装所需的包 $ yum install --downloadonly --downloaddir=/opt/utils yum-utils device-mapper-persistent-data lvm2 $ yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo $ yum install --downloadonly --downloaddir=/opt/all_packages docker-ce docker-ce-cli containerd.io root@192.168.31.201:/opt/all_packages #0$ l audit-libs-python-2.8.4-4.el7.x86_64.rpm libcgroup-0.41-20.el7.x86_64.rpm checkpolicy-2.5-8.el7.x86_64.rpm libsemanage-python-2.5-14.el7.x86_64.rpm containerd.io-1.2.2-3.3.el7.x86_64.rpm policycoreutils-2.5-29.el7_6.1.x86_64.rpm container-selinux-2.74-1.el7.noarch.rpm policycoreutils-python-2.5-29.el7_6.1.x86_64.rpm docker-ce-18.09.2-3.el7.x86_64.rpm python-IPy-0.75-6.el7.noarch.rpm docker-ce-cli-18.09.2-3.el7.x86_64.rpm setools-libs-3.3.8-4.el7.x86_64.rpm root@192.168.31.201:/opt/all_packages #0$ l ../utils/ device-mapper-1.02.149-10.el7_6.3.x86_64.rpm lvm2-2.02.180-10.el7_6.3.x86_64.rpm device-mapper-event-1.02.149-10.el7_6.3.x86_64.rpm lvm2-libs-2.02.180-10.el7_6.3.x86_64.rpm device-mapper-event-libs-1.02.149-10.el7_6.3.x86_64.rpm python-chardet-2.2.1-1.el7_1.noarch.rpm device-mapper-libs-1.02.149-10.el7_6.3.x86_64.rpm python-kitchen-1.1.1-5.el7.noarch.rpm libxml2-python-2.9.1-6.el7_2.3.x86_64.rpm yum-utils-1.1.31-50.el7.noarch.rpm # 在离线机器上， 执行以下命令以安装 $ yum localinstall /opt/utils/*.rpm $ yum localinstall /opt/all_packages/*.rpm install docker-compose $ curl -L "https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)" \ -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose $ docker-compose --version install docker-machine $ base=https://github.com/docker/machine/releases/download/v0.16.1 &amp;&amp; curl -L $base/docker-machine-$(uname -s)-$(uname -m) &gt;/tmp/docker-machine &amp;&amp; install /tmp/docker-machine /usr/local/bin/docker-machine 基本命令 $ service docker start或者systemctl start docker $ docker run helloworld $ docker version $ docker info $ docker image ls $ docker container ls $ docker container ls -a $ docker container ls -aq 镜像制作、分发 $ docker build --tag=zhaoyu/helloworld:0.0.1 . $ docker save zhaoyu/helloworld -o zhaoyu_helloworld_0.0.1.tar $ docker load &lt; zhaoyu_helloworld_0.0.1.tar $ docker tag zhaoyu/helloworld:0.0.1 zhaoyu/helloworld:0.0.2 $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE zhaoyu/helloworld 0.0.1 8a2ec1b2d523 14 hours ago 131MB zhaoyu/helloworld 0.0.2 8a2ec1b2d523 14 hours ago 131MB python 2.7-slim 99079b24ed51 4 days ago 120MB 运行，查看，停止，删除 $ docker run -p 4000:80 zhaoyu/helloworld $ docker run -p -d 4000:80 zhaoyu/helloworld $ docker run -it --name=zhaoyu zhaoyu/helloworld:0.0.1 /bin/bash $ docker attach zhaoyu $ docker container ls $ docker container top &lt;container_id&gt; $ docker container stop &lt;container_id&gt; $ docker rm &lt;container_id&gt; $ docker rmi &lt;image_id&gt; $ docker container stop $(docker ps -a -q) $ docker rm $(docker ps -a -q) swarm/stack $ docker swarm init $ docker node ls $ docker stack deploy -c docker-compose.yml helloworld_swarm $ docker stack ls $ docker stack ps helloworld_swarm ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS l8c3a4haeccd helloworld_swarm_web.1 zhaoyu/helloworld:0.0.1 host1 Running Running 8 seconds ago z8pz8s0zh6b1 helloworld_swarm_web.2 zhaoyu/helloworld:0.0.1 host1 Running Preparing 17 seconds ago yd5qyb7q146x helloworld_swarm_web.3 zhaoyu/helloworld:0.0.1 host1 Running Running 1 second ago 82o2in6wudci helloworld_swarm_web.4 zhaoyu/helloworld:0.0.1 host1 Running Preparing 17 seconds ago lidmd9n70wnz helloworld_swarm_web.5 zhaoyu/helloworld:0.0.1 host1 Running Running 2 seconds ago $ docker service ps helloworld_swarm $ docker stack rm helloworld_swarm $ docker swarm leave --force 概览 docker daemon docker client docker registries docker objects images containers services underlying technology namespaces control group union file systems container format 开始入门]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>centos7</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 问题与源码]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190413%20mysql%20%E9%97%AE%E9%A2%98%E4%B8%8E%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[问题1: 连接数为214， 登录经常报错 too many connections 在公司mysql企业版服务化开发的初期，我们曾经遇到一个问题，即在连接mysql的时候报错 too many connections, 即使是新安装的mysql。在以前的社区版mysql也曾经遇到过类似的问题（参考 使用service启动mysql最 大连接数始终在480多左右 ），当时mysql是用rpm安装并使用systemd启动的方式。此次企业版的mysql启动并未托管到 systemd，因此解决办法不能照搬。 定位过程 为了能够登录，首先只能重启mysql，执行 show variables like "max_conne%"; 发现连接数并非配置文件中定义的 2000，而是一个奇怪的数字 214； 执行 ulimit -a 或者 cat /proc/`pidof mysqld`/limits 发现 open files 为一个较低的默认值 1024；（代码中有改动该值的逻辑，但是最终并未生效，最终发现是公司系统镜 像/etc/security/limits.d/&#8230;&#8203;的默认值有问题，此处不延伸） core file size (blocks, -c) 0 data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 23883 max locked memory (kbytes, -l) 64 max memory size (kbytes, -m) unlimited open files (-n) 1024 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) 8192 cpu time (seconds, -t) unlimited max user processes (-u) 23883 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited 为什么是214？ 查看mysqld.cc:adjust_max_connections发现原委: void adjust_max_connections(ulong requested_open_files) &#123; ulong limit; // TABLE_OPEN_CACHE_MIN = 400 // requested_open_files = 1024 limit= requested_open_files - 10 - TABLE_OPEN_CACHE_MIN * 2; if (limit &lt; max_connections) &#123; sql_print_warning("Changed limits: max_connections: %lu (requested %lu)", limit, max_connections); // This can be done unprotected since it is only called on startup. max_connections= limit; &#125; &#125; 计算很简单，看一下此处，应该会打印出一行警告日志，可以试试看，日志中是否可以找到这样的信息。 sql_print_warning("Changed limits: max_connections: %lu (requested %lu)", limit, max_connections); 值得关注的点是，这个requested_open_files有一个比较复杂的计算过程。 mysqld.cc:adjust_related_options void adjust_related_options(ulong *requested_open_files) &#123; /* In bootstrap, disable grant tables (we are about to create them) */ if (opt_bootstrap) opt_noacl= 1; /* The order is critical here, because of dependencies. */ adjust_open_files_limit(requested_open_files); adjust_max_connections(*requested_open_files); adjust_table_cache_size(*requested_open_files); adjust_table_def_size(); &#125; mysqld.cc:adjust_open_files_limit /** Adjust @c open_files_limit. Computation is based on: - @c max_connections, - @c table_cache_size, - the platform max open file limit. */ void adjust_open_files_limit(ulong *requested_open_files) &#123; ulong limit_1; ulong limit_2; ulong limit_3; ulong request_open_files; ulong effective_open_files; /*这里会有三种计算方案*/ /* MyISAM requires two file handles per table. */ limit_1= 10 + max_connections + table_cache_size * 2; /* We are trying to allocate no less than max_connections*5 file handles (i.e. we are trying to set the limit so that they will be available). */ limit_2= max_connections * 5; /* Try to allocate no less than 5000 by default. */ //这里可以解释了，为什么很多的系统安装后， /proc/`pidof mysqld`/limits中的值为5000 //但是这里的代码，是否应该改为 open_files_limit&gt; 5000 ? open_files_limit : 5000; limit_3= open_files_limit ? open_files_limit : 5000; // 取三种方案的最大值 request_open_files= max&lt;ulong&gt;(max&lt;ulong&gt;(limit_1, limit_2), limit_3); /* Notice: my_set_max_open_files() may return more than requested. */ effective_open_files= my_set_max_open_files(request_open_files); if (effective_open_files &lt; request_open_files) &#123; if (open_files_limit == 0) &#123; sql_print_warning("Changed limits: max_open_files: %lu (requested %lu)", effective_open_files, request_open_files); &#125; else &#123; sql_print_warning("Could not increase number of max_open_files to " "more than %lu (request: %lu)", effective_open_files, request_open_files); &#125; &#125; open_files_limit= effective_open_files; if (requested_open_files) *requested_open_files= min&lt;ulong&gt;(effective_open_files, request_open_files); &#125; my_file.c:my_set_max_open_files uint my_set_max_open_files(uint files) &#123; struct st_my_file_info *tmp; DBUG_ENTER("my_set_max_open_files"); DBUG_PRINT("enter",("files: %u my_file_limit: %u", files, my_file_limit)); files+= MY_FILE_MIN; files= set_max_open_files(MY_MIN(files, OS_FILE_LIMIT)); if (files &lt;= MY_NFILE) DBUG_RETURN(files); if (!(tmp= (struct st_my_file_info*) my_malloc(key_memory_my_file_info, sizeof(*tmp) * files, MYF(MY_WME)))) DBUG_RETURN(MY_NFILE); /* Copy any initialized files */ memcpy((char*) tmp, (char*) my_file_info, sizeof(*tmp) * MY_MIN(my_file_limit, files)); memset((tmp + my_file_limit), 0, MY_MAX((int) (files - my_file_limit), 0) * sizeof(*tmp)); my_free_open_file_info(); /* Free if already allocated */ my_file_info= tmp; my_file_limit= files; DBUG_PRINT("exit",("files: %u", files)); DBUG_RETURN(files); &#125; 按照设置值max_connections=2000来计算，requested_open_files不能小于\(2000+10+400 \times 2=2810\).]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 检查清单]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190416%20mysql%20%E5%8E%9F%E5%8E%82%E6%A3%80%E6%9F%A5%E6%B8%85%E5%8D%95%2F</url>
    <content type="text"><![CDATA[oracle检查清单 根据电话沟通情况，请收集上传以下数据进行进一步分析： 1) MySQL配置文件 （my.cnf 或 my.ini） 2) MySQL完整的错误日志文件 （error log file）.（如果文件太大，可以压缩后上传） 3) MySQL的 slow query log 文件 （如果已经配置收集的话）. 4) 生成下面的mysql_output.txt文本文件（请在查询性能低、响应慢时运行）： （请使用具有SUPER权限的MySQL用户（如root）登录MySQL命令行客户端并运行） TEE mysql_output0416.txt; select now(),@@version,@@version_comment,@@hostname,@@port,@@basedir,@@datadir,@@tmpdir,@@log_error, @@slow_query_log_file,user(),current_user(),/*!50600 @@server_uuid,*/@@server_id\G SHOW GLOBAL VARIABLES; SHOW GLOBAL STATUS; SHOW ENGINES\G SHOW PLUGINS\G select benchmark(50000000,(1234*5678/37485-1298+8596^2)); #should take less than 20 seconds SELECT ENGINE, COUNT(*), SUM(DATA_LENGTH), SUM(INDEX_LENGTH) FROM information_schema.TABLES GROUP BY ENGINE; SHOW ENGINE INNODB STATUS; /*!50503 SHOW ENGINE performance_schema STATUS */; /*!50503 SELECT * FROM performance_schema.setup_instruments WHERE name LIKE 'wait/sync%' AND (enabled='yes' OR timed='yes')*/; -- Info on transactions and locks SELECT r.trx_id waiting_trx_id, r.trx_mysql_thread_id waiting_thread, r.trx_query waiting_query, b.trx_id blocking_trx_id, b.trx_mysql_thread_id blocking_thread, b.trx_query blocking_query, bl.lock_id blocking_lock_id, bl.lock_mode blocking_lock_mode, bl.lock_type blocking_lock_type, bl.lock_table blocking_lock_table, bl.lock_index blocking_lock_index, rl.lock_id waiting_lock_id, rl.lock_mode waiting_lock_mode, rl.lock_type waiting_lock_type, rl.lock_table waiting_lock_table, rl.lock_index waiting_lock_index FROM information_schema.INNODB_LOCK_WAITS w INNER JOIN information_schema.INNODB_TRX b ON b.trx_id = w.blocking_trx_id INNER JOIN information_schema.INNODB_TRX r ON r.trx_id = w.requesting_trx_id INNER JOIN information_schema.INNODB_LOCKS bl ON bl.lock_id = w.blocking_lock_id INNER JOIN information_schema.INNODB_LOCKS rl ON rl.lock_id = w.requested_lock_id\G SHOW FULL PROCESSLIST; /*!50503 SELECT * FROM information_schema.innodb_trx */; /*!50503 SELECT * FROM performance_schema.threads */; /*!50708 SELECT * FROM sys.session */; SHOW OPEN TABLES; SHOW MASTER STATUS\G SHOW SLAVE STATUS\G /*!50602 SELECT * FROM MYSQL.SLAVE_MASTER_INFO */; /*!50602 SELECT * FROM MYSQL.SLAVE_RELAY_LOG_INFO */; /*!50602 SELECT * FROM MYSQL.SLAVE_WORKER_INFO */; SHOW MASTER LOGS; SELECT SLEEP(300); SHOW GLOBAL STATUS; SHOW ENGINE INNODB STATUS; /*!50503 SHOW ENGINE performance_schema STATUS */; /*!50503 SELECT * FROM performance_schema.setup_instruments WHERE name LIKE 'wait/sync%' AND (enabled='yes' OR timed='yes')*/; -- Info on transactions and locks SELECT r.trx_id waiting_trx_id, r.trx_mysql_thread_id waiting_thread, r.trx_query waiting_query, b.trx_id blocking_trx_id, b.trx_mysql_thread_id blocking_thread, b.trx_query blocking_query, bl.lock_id blocking_lock_id, bl.lock_mode blocking_lock_mode, bl.lock_type blocking_lock_type, bl.lock_table blocking_lock_table, bl.lock_index blocking_lock_index, rl.lock_id waiting_lock_id, rl.lock_mode waiting_lock_mode, rl.lock_type waiting_lock_type, rl.lock_table waiting_lock_table, rl.lock_index waiting_lock_index FROM information_schema.INNODB_LOCK_WAITS w INNER JOIN information_schema.INNODB_TRX b ON b.trx_id = w.blocking_trx_id INNER JOIN information_schema.INNODB_TRX r ON r.trx_id = w.requesting_trx_id INNER JOIN information_schema.INNODB_LOCKS bl ON bl.lock_id = w.blocking_lock_id INNER JOIN information_schema.INNODB_LOCKS rl ON rl.lock_id = w.requested_lock_id\G SHOW FULL PROCESSLIST; /*!50503 SELECT * FROM information_schema.innodb_trx */; /*!50503 SELECT * FROM performance_schema.threads */; /*!50708 SELECT * FROM sys.session */; SHOW OPEN TABLES; SHOW MASTER STATUS\G SHOW SLAVE STATUS\G /*!50602 SELECT * FROM MYSQL.SLAVE_MASTER_INFO */; /*!50602 SELECT * FROM MYSQL.SLAVE_RELAY_LOG_INFO */; /*!50602 SELECT * FROM MYSQL.SLAVE_WORKER_INFO */; select * from information_schema.innodb_trx; select * from information_schema.innodb_locks; select * from information_schema.innodb_lock_waits; select * from performance_schema.events_waits_history; SHOW MASTER LOGS; SELECT t.TABLE_SCHEMA, t.TABLE_NAME, s.TABLE_NAME FROM information_schema.tables t LEFT OUTER JOIN information_schema.statistics s ON t.TABLE_SCHEMA = s.TABLE_SCHEMA AND t.TABLE_NAME = s.TABLE_NAME AND s.INDEX_NAME = 'PRIMARY' WHERE s.TABLE_NAME IS NULL AND t.TABLE_SCHEMA not in ('information_schema','mysql','performance_schema') AND t.TABLE_TYPE = 'BASE TABLE'; \s NOTEE; （注意：SELECT SLEEP(300)会休眠300秒，请勿中断运行！） 5) 生成下面的query.txt文本文件（请在查询性能低、响应慢时运行）： TEE query.txt; EXPLAIN EXTENDED select count(1) from t_intg_dm_0863; SHOW WARNINGS; SHOW CREATE TABLE t_intg_dm_0863\G SHOW INDEXES FROM t_intg_dm_0863; SHOW TABLE STATUS LIKE 't_intg_dm_0863'\G SET PROFILING=1; SHOW SESSION STATUS; select count(1) from t_intg_dm_0863; select sleep(1); select count(1) from t_intg_dm_0863; SHOW SESSION STATUS; SHOW PROFILE ALL FOR QUERY 2; SHOW PROFILE ALL FOR QUERY 4; SELECT * FROM INFORMATION_SCHEMA.PROFILING WHERE QUERY_ID = 2 OR QUERY_ID = 4 ORDER BY SEQ; SET PROFILING=0; SET optimizer_trace="enabled=on"; select count(1) from t_intg_dm_0863; SELECT * FROM INFORMATION_SCHEMA.OPTIMIZER_TRACE; SET optimizer_trace="enabled=off"; NOTEE; 6) OS的状态信息，生成文件linuxdiags.txt（使用root用户运行，请在查询性能低、响应慢时运行）： (注意：先单独运行 "script"命令，然后再运行其他命令） script /tmp/linuxdiags.txt set -x id uptime uname -a free -m cat /proc/cpuinfo cat /proc/mounts mount ls -lrt /dev/mapper pvdisplay vgdisplay lvdisplay df -h df -i top -b -d 10 -n 6 iostat -x 10 6 vmstat 10 6 numactl -H numastat -m numastat -n ps -ef | grep -i mysql ls -al /etc/init.d/ | grep -i mysql for PID in `ps -ef | awk '/mysqld[^_[]/&#123;print $2&#125;'`; do echo "PID=$PID"; cat /proc/$PID/limits; done ps auxfww | grep mysql dmesg egrep -i "err|fault|mysql|oom|kill|warn|fail" /var/log/* exit]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>[object Object]</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让git在windows上使用LF换行符]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190322%20%E8%AE%A9git%E5%9C%A8windows%E4%B8%8A%E4%BD%BF%E7%94%A8LF%E6%8D%A2%E8%A1%8C%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[= 让git在windows上使用LF换行符:stem: latexmath:icons: font 12git config --global core.eol lfgit config --global core.autocrlf input For repos that were checked out after those global settings were set, everything will be checked out as whatever it is in the repo – hopefully LF (\n). Any CRLF will be converted to just LF on checkin. With an existing repo that you have already checked out – that has the correct line endings in the repo but not your working copy – you can run the following commands to fix it: 12git rm -rf --cached .git reset --hard HEAD This will delete (rm) recursively (r) without prompt (-f), all files except those that you have edited (–cached), from the current directory (.). The reset then returns all of those files to a state where they have their true line endings (matching what’s in the repo). If you need to fix the line endings of files in a repo, I recommend grabbing an editor that will let you do that in bulk like IntelliJ or Sublime Text, but I’m sure any good one will likely support this.]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>[object Object]</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker phpmyadmin]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190419%20docker%20phpmyadmin%2F</url>
    <content type="text"><![CDATA[docker phpmyadmin 路线1 公司suse12容器导出包作为基础镜像，使用xampp作为服务器 探索镜像内容 docker run -v /root/temp:/root/temp -it test/suse12sp2:20190418 bash docker run -d -p 4000:80 -v /root/temp:/root/temp test/suse12sp2:20190418 /bin/sh -c "while true; do ping 127.0.0.1; done" 制作安装xampp的镜像 FROM test/suse12sp2:20190418 COPY xampp-linux-x64-7.3.4-0-installer.run configure.sh /tmp/ RUN chmod +x /tmp/xampp-linux-x64-7.3.4-0-installer.run \ &amp;&amp; /tmp/xampp-linux-x64-7.3.4-0-installer.run --mode unattended --disable-components xampp_developer_files \ &amp;&amp; chmod 755 /opt/lampp -R \ &amp;&amp; mkdir -p /opt/lampp/phpmyadmin/tmp \ &amp;&amp; chmod 777 /opt/lampp/phpmyadmin/tmp -R \ &amp;&amp; rm /opt/lampp/mysql -rf \ &amp;&amp; sed 's/function startMySQL() &#123;/function startMySQL() &#123;\nreturn 0/g' -i /opt/lampp/xampp \ &amp;&amp; sh /tmp/configure.sh 运行查看 docker build -t test/testmysqlconsole:latest . Successfully tagged test/testmysqlconsole:latest [root@node1 build]# docker run -d -p 4000:80 -v /root/temp:/root/temp test/testmysqlconsole /bin/sh -c "while true; do ping 127.0.0.1; done" 3a5c223bcad7727ff0bdd72e030f825317959cc82809b612ccb3f0f8cfdbe09e [root@node1 build]# docker exec -it 3a5c223bcad7727ff0bdd72e030f825317959cc82809b612ccb3f0f8cfdbe09e /bin/bash 3a5c223bcad7:/ # ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 04:11 ? 00:00:00 /bin/sh -c while true; do ping 127.0.0.1; done root 6 1 0 04:11 ? 00:00:00 ping 127.0.0.1 root 7 0 3 04:12 pts/0 00:00:00 /bin/bash root 25 7 0 04:12 pts/0 00:00:00 ps -ef 3a5c223bcad7:/ # cd /opt/lampp/ 3a5c223bcad7:/opt/lampp # ./lampp start Starting XAMPP for Linux 7.3.4-0... XAMPP: Starting Apache...ok. XAMPP: Starting ProFTPD...ok. Example 1. 访问链接 http://10.90.182.122:4000/phpmyadmin/ 路线2 官方phpmyadmin/phpmyadmin作为基础镜像 FROM phpmyadmin/phpmyadmin:latest ENV HTML_DIR /usr/src/phpmyadmin/ COPY configure.sh /tmp/ RUN sh /tmp/configure.sh docker build -t test/phpmyadmin:latest . docker run --name zhaoyu -d -p 5001:80 test/phpmyadmin:latest 路线3 官方phpmyadmin/phpmyadmin的容器导出作为基础镜像 # docker export ea681f9b151c -o phpmyadmin_export.tar # docker import phpmyadmin_export.tar test/phpmyadmin_export:latest FROM test/phpmyadmin_export:latest ENV HTML_DIR /var/www/html/ COPY configure.sh /tmp/ RUN sh /tmp/configure.sh ENTRYPOINT ["/run.sh"] CMD ["supervisord","-n","-j","/supervisord.pid"]]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>[object Object]</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[suse12 安装 nginx rpm]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190418%20suse12%20%E5%AE%89%E8%A3%85%20nginx%20rpm%2F</url>
    <content type="text"><![CDATA[http://nginx.org/packages/mainline/ http://nginx.org/packages/mainline/sles/12/x86_64/ http://nginx.org/packages/mainline/sles/12/x86_64/RPMS/nginx-1.15.12-1.sles12.ngx.x86_64.rpm rpm -ivh nginx-1.15.12-1.sles12.ngx.x86_64.rpm autoindex vi /etc/nginx/conf.d/default.conf location / &#123; root /var/www/html; index index.html index.htm; autoindex on; autoindex_exact_size off; autoindex_localtime on; &#125; chmod -R 777 /var/www /usr/sbin/nginx -c /etc/nginx/nginx.conf]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>[object Object]</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 主从复制异常恢复]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190425%20mysql%20%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%BC%82%E5%B8%B8%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[mysql 主从复制异常恢复 检查版本 如果版本较老，基于binlog而不是gtid的版本， 数据量较小，可以参考 基于binlog的老版本。 基于binlog的老版本 1. 登录主机数据库， mysql --login-path=local 执行 mysql&gt; stop slave; mysql&gt; show master status; 记录以上master status的 log_file 和 log_pos 信息 mysql&gt; exit; 2. 进入备份脚本目录（根据版本不同，可能在以下位置） cd /opt/backup/mysql/backup_script 或者 cd /opt/backup/mysql/backup_script 执行 ./backupandDelete.sh 3. 找到最新备份的文件，如 cd /opt/backup/mysql/backup_data/xxxxx 或者 cd /opt/backup/mysql/backup_data/xxxxx 找到备份文件 xxxxx.sql.gz 将其拷贝到另外一台机器 scp .. .. 4. 在另外一台机器，解压 gunzip -d xxxx.sql.gz 得到如 /root/xxxx.sql 的文件 5. 登录mysql mysql --login-path=local 执行(注意替换路径，和ip，端口，密码等信息) mysql&gt; set sql_log_bin=0; mysql&gt; source /root/xxxx.sql mysql&gt; select user,host from mysql.user; mysql&gt; update mysql.user set host="另外一台机器ip" where user="replicator"; mysql&gt; flush privileges; mysql&gt; set sql_log_bin=1; mysql&gt; change master to master_host="另外一台机器ip", master_port=13307, master_log_file="上面记录的log_file", master_log_pos='上面记录的log_pos'; mysql&gt; start slave; 6. 查看主从状态是否正常 show slave status\G 基于gtid的版本 1. 登录主机数据库， mysql --login-path=local 执行 mysql&gt; stop slave; mysql&gt; exit; 2. 进入备份脚本目录（根据版本不同，可能在以下位置） cd /opt/backup/mysql/backup_script 或者 cd /opt/backup/mysql/backup_script 执行 ./backupandDelete.sh 3. 找到最新备份的文件，如 cd /opt/backup/mysql/backup_data/xxxxx 或者 cd /opt/backup/mysql/backup_data/xxxxx 找到备份文件 xxxxx.sql.bin（如果不是bin格式的文件，说明版本不对，此时不是商业版，或者没有做使用mysqlbackup备份恢复的需求，后者直接拷贝最新版backupandDelete.sh使用即可，或者使用binlog的方案） 将其拷贝到另外一台机器 scp .. .. 在另一台机器上，将备份文件的权限更改为mysql的属组 chown mysql: xxxx.sql.bin 4. 在要恢复的机器上，执行以下检查： 4.1 检查是否有mysqlbackup程序 mysqlbackup --version 4.2 检查/opt/mysql/.bashrc 是否有ip_cluster_a的字样，其中ip_cluster_a或者ip_cluster_b中，一个是本机ip，一个是对端ip 如果以上条件满足，进行第5_a步，否则执行5_b步骤。 5_a. 进行恢复 以下命令中的false或者true代表是否备份机器的/opt/mysql/data/目录，请根据机器磁盘剩余空间选择 /opt/mysql/dataRecover.sh xxxx.sql.bin false 或者 /opt/mysql/dataRecover.sh xxxx.sql.bin 5_b. 如果在第4步检查通过，此步可以跳过。否则，如果bashrc里没有ip_cluster_a或者ip_cluster_b，说明版本较老。 方法一：可以取该版本对应的资料，按照资料进行操作（四个步骤： 1.关闭sql_log_bin，更改mysql.user表的用户ip为对端ip 2 清空binlog和relaylog信息 stop slave; reset slave; reset master; 3. 设置主从 STOP SLAVE;CHANGE MASTER TO MASTER_HOST='$&#123;another_ip&#125;', MASTER_AUTO_POSITION=1 FOR CHANNEL 'rpl1';START SLAVE 方法二：也可以将两个ip手动写入该文件，并且拷贝最新版本的dataRecover.sh，然后执行步骤5_a 注意替换值为实际ip ip_cluster_a=$&#123;master_ip&#125; ip_cluster_b=$&#123;slave_ip&#125; 6. 恢复完成后，登录两台机器查看主从复制状态。]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>[object Object]</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql双主自增主键配置及测试]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190425%20mysql%E5%8F%8C%E4%B8%BB%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E9%85%8D%E7%BD%AE%E5%8F%8A%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[mysql双主自增主键配置及主从复制影响测试 术语 binlog_format=ROW sbr rbr autoinc_lock_mode=2 Mysql_Server_auto_increment_offset=1 Mysql_Server_auto_increment_increment=2 模型 DROP DATABASE IF EXISTS TEST2; CREATE DATABASE TEST2; CREATE TABLE TEST2.TEST_INCREMENT(ID INT(10) PRIMARY KEY AUTO_INCREMENT NOT NULL, NAME VARCHAR(10)); INSERT INTO TEST2.TEST_INCREMENT VALUES (NULL, 'master111'), (NULL,'master222'); INSERT INTO TEST2.TEST_INCREMENT VALUES (NULL, 'slave111'), (NULL,'slave222'); INSERT INTO TEST2.TEST_INCREMENT VALUES (NULL), (NULL), (NULL), (NULL), (NULL), (NULL), (NULL), (NULL), (NULL), (NULL), (NULL), (NULL), (NULL), (NULL); SELECT * FROM TEST2.TEST_INCREMENT; 问题 === SELECT trx.trx_id, trx.trx_started, trx.trx_mysql_thread_id FROM INFORMATION_SCHEMA.INNODB_TRX trx; https://dev.mysql.com/doc/refman/8.0/en/innodb-auto-increment-handling.html https://dev.mysql.com/doc/refman/8.0/en/replication-sbr-rbr.html https://dev.mysql.com/doc/refman/8.0/en/innodb-auto-increment-handling.html]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql order by 对同一值的varchar列排序问题]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190524%20mysql%20order%20by%20%E5%AF%B9%E5%90%8C%E4%B8%80%E5%80%BC%E7%9A%84varchar%E5%88%97%E6%8E%92%E5%BA%8F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[mysql order by 对同一值的varchar列排序问题 背景 TODO 数据 DROP TABLE IF EXISTS `tbl_rn_log`; /*!40101 SET @saved_cs_client = @@character_set_client */; /*!40101 SET character_set_client = utf8 */; CREATE TABLE `tbl_rn_log` ( `SN` bigint(20) NOT NULL AUTO_INCREMENT, `STATUS` varchar(20) COLLATE utf8_bin NOT NULL, `SENDER` varchar(128) COLLATE utf8_bin DEFAULT NULL, `SENDTIME` bigint(20) NOT NULL, `SENDIP` varchar(128) COLLATE utf8_bin DEFAULT NULL, `OPERATIONUSER` varchar(128) COLLATE utf8_bin DEFAULT NULL, `ADDRESSES` varchar(1024) COLLATE utf8_bin NOT NULL, `BRIEFINFO` varchar(1024) COLLATE utf8_bin DEFAULT NULL, `TENANTID` varchar(50) COLLATE utf8_bin DEFAULT NULL, `PROJECT` varchar(32) COLLATE utf8_bin DEFAULT 'global', PRIMARY KEY (`SN`), KEY `TBL_RN_LOG_SENDTIME_INDEX` (`SENDTIME`) ) ENGINE=InnoDB AUTO_INCREMENT=53 DEFAULT CHARSET=utf8 COLLATE=utf8_bin; /*!40101 SET character_set_client = @saved_cs_client */; -- -- Dumping data for table `tbl_rn_log` -- LOCK TABLES `tbl_rn_log` WRITE; /*!40000 ALTER TABLE `tbl_rn_log` DISABLE KEYS */; INSERT INTO `tbl_rn_log` VALUES (1,'0','192.168.1.15',1558594684463,'192.168.1.15','192.168.1.15','ec6f7c03cd022582834ac62520c9d3227d7463db7fc17d5e55f8c40ff1dace273a346bd97f3e8391dd16fd','1',NULL,'global'),(3,'1','192.168.1.15',1558594730408,'192.168.1.15','192.168.1.15','693260ebda5b546df637a2fa3c530172046b78171f7162f052c7eb622d47119c67cd0ef52e8bd7248ee600','2',NULL,'global'),(5,'0','192.168.1.15',1558594942150,'192.168.1.15','192.168.1.15','c926a89d226d718f345d2c3203c4a29b5deeccefcb41737a89b20ae9ae24d4813c7d03e8427f30ff53a78f','3',NULL,'global'),(7,'1','192.168.1.15',1558594987780,'192.168.1.15','192.168.1.15','0633facbe13f11ecceef383fc395b7a51e920cf8b026aa2c490e454afab1c4baca7782745951349235a75d','4',NULL,'global'),(9,'0','192.168.1.15',1558594988831,'192.168.1.15','192.168.1.15','2f8249628d533cafebd6a415fbbbd8e49ec9932512d5c1aa0f5545a534a4dd595397403796444978ccb99b','5',NULL,'global'),(11,'1','192.168.1.15',1558595037764,'192.168.1.15','192.168.1.15','02efda91e896dc1870a2fceff0a628f7b4428d9d604729021afc2056b5730ff7c69ec288ce7d5d2519657d','6',NULL,'global'),(13,'0','192.168.1.15',1558595038906,'192.168.1.15','192.168.1.15','28e465192ce7a2cd699d19433c1c0a20a1ec6a53c09c94cd7966650fdbfb5b12a37bdf568d623a4d69a4eb','8',NULL,'global'),(15,'1','192.168.1.15',1558595083635,'192.168.1.15','192.168.1.15','06c75a25b0c18fcdaa33b9881ccc716741ccabaed29b2f06f29953173c91c6ea447ef2cb2811efe9cf39e0','9',NULL,'global'),(17,'0','192.168.1.15',1558595084745,'192.168.1.15','192.168.1.15','5b93b7204b6bc0ec86dbac231801f71df9c31af627804f256e1ccbdeb4740279af24b2cdd46b3bc92c97fb','10',NULL,'global'),(19,'0','192.168.1.15',1558595092067,'192.168.1.15','192.168.1.15','5380bcb85c5aecf5b9e80e0135a1d0ff581d2e338f01689c2454f624289fb365c25ad61039c4f211cc155e','11',NULL,'global'),(21,'0','192.168.1.15',1558595099882,'192.168.1.15','192.168.1.15','852ed381e70079d870de71af1cd9e100612e016e9e9af0dc59a6606c9c6cd87e65fc0d0def19d766838878','12',NULL,'global'),(23,'1','192.168.1.15',1558595139935,'192.168.1.15','192.168.1.15','cabdf9654c717f6401369f8452c5f6c08ac582957ddfe9d2be27e3e232e75621f462269461a2c67bbc17a1','13',NULL,'global'),(25,'0','192.168.1.15',1558595140880,'192.168.1.15','192.168.1.15','83a7d94446b5e688d769f8f55c96f2cc8fab1413636f708085e19bc32f9661b31981421800d33fd08f5f93','14',NULL,'global'),(27,'1','192.168.1.15',1558595363264,'192.168.1.15','192.168.1.15','e319f341101409b91983227cc802513959b525610071f9d9fcf79849aa8398f02c978a7ca21fd86bf9369b','15',NULL,'global'),(29,'0','192.168.1.15',1558595376583,'192.168.1.15','192.168.1.15','4b6cee3ca5c0b94b5cdc6c4ad60e09b95fc8d37dea60e4f391ee082f959cbf2e7f3b4a8bddee2c0fc4047e','16',NULL,'global'),(31,'1','192.168.1.15',1558596095126,'192.168.1.15','192.168.1.15','d31ce8f013b756e293dd09b2f82f6bccb3cf419b415f76c7d7b1c796187901e080e6914d3fb020c2d0bafb','17',NULL,'global'),(33,'0','192.168.1.15',1558596189223,'192.168.1.15','192.168.1.15','5ffda5ccdb49bc24e9fe4e215a70d85178f9c7ae632326a023092567d35964af710b5438991f44aa28a1ef','18',NULL,'global'),(35,'0','192.168.1.15',1558596196462,'192.168.1.15','192.168.1.15','a75e0eecf22b91596219c53a32dba974044958137ee53a8782a8febd2251716c478b4ac3af5b895b0bd8e6','19',NULL,'global'),(37,'0','192.168.1.15',1558598393426,'192.168.1.15','192.168.1.15','9a9c96301e1eae6a8154cc08b12236d51ad0a2d27c323fd2e2d88538bedbcc25dfefb0f83b3ba21486f007','123456789',NULL,'global'),(39,'0','192.168.1.15',1558662516038,'192.168.1.15','192.168.1.15','2de09ba57207982875481ff43654b7090fa18d7d53403984b9ca265b39a142b127272a46767621cde5cb2e','9:47',NULL,'global'),(41,'1','192.168.1.15',1558662963495,'192.168.1.15','192.168.1.15','42943d728fda7a250241a16d533be9b652607cbe6b335fc1543f4d1b1085b07db570c4a1834a4116764fee','两个用户，容量限制为2条，人数限制为1',NULL,'global'),(43,'1','192.168.1.15',1558662964178,'192.168.1.15','192.168.1.15','c9d5d8d82a777711ce45f26584e92bf103f2eb0f257c49c618ca0dd1bfea4fe317db0a89389c1c79e4e336','两个用户，容量限制为2条，人数限制为1',NULL,'global'),(45,'0','192.168.1.15',1558663043324,'192.168.1.15','192.168.1.15','3314ff4a91274ad8227dded9af58dabb3b9ae792a509c3ee8b98337ff4eb7fc886820047b73e73b9b12d0b','两个用户，关闭流控',NULL,'global'),(47,'0','192.168.1.15',1558663043324,'192.168.1.15','192.168.1.15','00416309bd1a431bd204d39f6f23b8708d0d11f9d93deb23db0c01da2cb4d360ca3b2f4b5f6196d9d224bb','两个用户，关闭流控',NULL,'global'),(49,'0','192.168.1.15',1558663129242,'192.168.1.15','192.168.1.15','e828a302fc57203917a9d75017859943d98f46415f7727d216f2c3dce8f8dec606ea8ef9eb6014bf48d45b','两个用户，容量限制为2条，人数限制为2',NULL,'global'),(51,'0','192.168.1.15',1558663129243,'192.168.1.15','192.168.1.15','7398449a801afb27e841fe68e9219e5c9c8040ce3e204b5f88252c8a4034e22d3a579b1cd5f8034ca91759','两个用户，容量限制为2条，人数限制为2',NULL,'global'); /*!40000 ALTER TABLE `tbl_rn_log` ENABLE KEYS */; UNLOCK TABLES; INSERT INTO tbl_rn_log VALUES (1,'0','192.168.1.16',1558594684463,'192.168.1.16','192.168.1.16','ec6f7c03cd022582834ac62520c9d3227d7463db7fc17d5e55f8c40ff1dace273a346bd97f3e8391dd16fd','1',NULL,'global'); limit 顺序 mysql&gt; select sn,sender,sendtime from tbl_rn_log order by sender limit 15; +----+--------------+---------------+ | sn | sender | sendtime | +----+--------------+---------------+ | 1 | 192.168.1.15 | 1558594684463 | | 3 | 192.168.1.15 | 1558594730408 | | 5 | 192.168.1.15 | 1558594942150 | | 7 | 192.168.1.15 | 1558594987780 | | 9 | 192.168.1.15 | 1558594988831 | | 11 | 192.168.1.15 | 1558595037764 | | 13 | 192.168.1.15 | 1558595038906 | | 15 | 192.168.1.15 | 1558595083635 | | 17 | 192.168.1.15 | 1558595084745 | | 19 | 192.168.1.15 | 1558595092067 | | 21 | 192.168.1.15 | 1558595099882 | | 23 | 192.168.1.15 | 1558595139935 | | 25 | 192.168.1.15 | 1558595140880 | | 27 | 192.168.1.15 | 1558595363264 | | 29 | 192.168.1.15 | 1558595376583 | +----+--------------+---------------+ 15 rows in set (0.00 sec) 反序 mysql&gt; select sn,sender,sendtime from tbl_rn_log order by sender limit 16; +----+--------------+---------------+ | sn | sender | sendtime | +----+--------------+---------------+ | 31 | 192.168.1.15 | 1558596095126 | | 29 | 192.168.1.15 | 1558595376583 | | 27 | 192.168.1.15 | 1558595363264 | | 25 | 192.168.1.15 | 1558595140880 | | 23 | 192.168.1.15 | 1558595139935 | | 21 | 192.168.1.15 | 1558595099882 | | 19 | 192.168.1.15 | 1558595092067 | | 17 | 192.168.1.15 | 1558595084745 | | 15 | 192.168.1.15 | 1558595083635 | | 13 | 192.168.1.15 | 1558595038906 | | 11 | 192.168.1.15 | 1558595037764 | | 9 | 192.168.1.15 | 1558594988831 | | 7 | 192.168.1.15 | 1558594987780 | | 5 | 192.168.1.15 | 1558594942150 | | 3 | 192.168.1.15 | 1558594730408 | | 1 | 192.168.1.15 | 1558594684463 | +----+--------------+---------------+ 无limit 顺序 mysql&gt; select sn,sender,sendtime,operationuser from tbl_rn_log order by sender; +----+--------------+---------------+---------------+ | sn | sender | sendtime | operationuser | +----+--------------+---------------+---------------+ | 1 | 192.168.1.15 | 1558594684463 | 192.168.1.15 | | 3 | 192.168.1.15 | 1558594730408 | 192.168.1.15 | | 5 | 192.168.1.15 | 1558594942150 | 192.168.1.15 | | 7 | 192.168.1.15 | 1558594987780 | 192.168.1.15 | | 9 | 192.168.1.15 | 1558594988831 | 192.168.1.15 | | 11 | 192.168.1.15 | 1558595037764 | 192.168.1.15 | | 13 | 192.168.1.15 | 1558595038906 | 192.168.1.15 | | 15 | 192.168.1.15 | 1558595083635 | 192.168.1.15 | | 17 | 192.168.1.15 | 1558595084745 | 192.168.1.15 | | 19 | 192.168.1.15 | 1558595092067 | 192.168.1.15 | | 21 | 192.168.1.15 | 1558595099882 | 192.168.1.15 | | 23 | 192.168.1.15 | 1558595139935 | 192.168.1.15 | | 25 | 192.168.1.15 | 1558595140880 | 192.168.1.15 | | 27 | 192.168.1.15 | 1558595363264 | 192.168.1.15 | | 29 | 192.168.1.15 | 1558595376583 | 192.168.1.15 | | 31 | 192.168.1.15 | 1558596095126 | 192.168.1.15 | | 33 | 192.168.1.15 | 1558596189223 | 192.168.1.15 | | 35 | 192.168.1.15 | 1558596196462 | 192.168.1.15 | | 37 | 192.168.1.15 | 1558598393426 | 192.168.1.15 | | 39 | 192.168.1.15 | 1558662516038 | 192.168.1.15 | | 41 | 192.168.1.15 | 1558662963495 | 192.168.1.15 | | 43 | 192.168.1.15 | 1558662964178 | 192.168.1.15 | | 45 | 192.168.1.15 | 1558663043324 | 192.168.1.15 | | 47 | 192.168.1.15 | 1558663043324 | 192.168.1.15 | | 49 | 192.168.1.15 | 1558663129242 | 192.168.1.15 | | 51 | 192.168.1.15 | 1558663129243 | 192.168.1.15 | | 53 | 192.168.1.16 | 1558594684463 | 192.168.1.16 | +----+--------------+---------------+---------------+ 27 rows in set (0.00 sec) 反序 mysql&gt; select sn,sender,sendtime from tbl_rn_log order by sender; +----+--------------+---------------+ | sn | sender | sendtime | +----+--------------+---------------+ | 51 | 192.168.1.15 | 1558663129243 | | 49 | 192.168.1.15 | 1558663129242 | | 47 | 192.168.1.15 | 1558663043324 | | 45 | 192.168.1.15 | 1558663043324 | | 43 | 192.168.1.15 | 1558662964178 | | 41 | 192.168.1.15 | 1558662963495 | | 39 | 192.168.1.15 | 1558662516038 | | 37 | 192.168.1.15 | 1558598393426 | | 35 | 192.168.1.15 | 1558596196462 | | 33 | 192.168.1.15 | 1558596189223 | | 31 | 192.168.1.15 | 1558596095126 | | 29 | 192.168.1.15 | 1558595376583 | | 27 | 192.168.1.15 | 1558595363264 | | 25 | 192.168.1.15 | 1558595140880 | | 23 | 192.168.1.15 | 1558595139935 | | 21 | 192.168.1.15 | 1558595099882 | | 19 | 192.168.1.15 | 1558595092067 | | 17 | 192.168.1.15 | 1558595084745 | | 15 | 192.168.1.15 | 1558595083635 | | 13 | 192.168.1.15 | 1558595038906 | | 11 | 192.168.1.15 | 1558595037764 | | 9 | 192.168.1.15 | 1558594988831 | | 7 | 192.168.1.15 | 1558594987780 | | 5 | 192.168.1.15 | 1558594942150 | | 3 | 192.168.1.15 | 1558594730408 | | 1 | 192.168.1.15 | 1558594684463 | | 53 | 192.168.1.16 | 1558594684463 | +----+--------------+---------------+ 27 rows in set (0.00 sec) max_length_for_sort_data 默认值1024 改为10240，就所有的都是反序。 https://www.cnblogs.com/cchust/p/5304594.html]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql jdbc 报错 operation not allowed after statement closed]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190601%20mysql%20jdbc%20%E6%8A%A5%E9%94%99%20operation%20not%20allowed%20after%20statement%20closed%2F</url>
    <content type="text"><![CDATA[mysql jdbc 报错 No operations allowed after statement closed 背景 业务上来说，连你们的mysql连不上，连别人的（其它部门的mysql）都能连上。查看其日志，报了一行错误"No operations allowed after statement closed"。 这句话的意思，说的很清楚，不应该用关闭后的statement执行查询。但是因为我们是服务化的mysql，公司在遇到问题甩锅给其它部门的习惯由来已久，所以还是要帮业务解决。 大致代码 class Main &#123; private static connection; private static statement; static &#123; connection = getConnection(); statement = connection.createStatement(); &#125; public static query()&#123; statement.executeUpdate("xxxx"); statement.close(); &#125; &#125; 定位 首先，业务反馈的是“连接不上”，但是报错位置其实是在executeUpdate一行，在此鄙视这些人，日志都不看清楚就开始推脱责任。在其代码中加入debug日志 public static query()&#123; log(statement.isClosed()); statement.executeUpdate("xxxx"); statement.close(); &#125; 发现日志打了两次，第一次为false，第二次为true并报错。 查看该类引用位置，发现为一个定义了init-method的bean，类似于 &lt;bean id="xxxx" class="xxxx" init-method="query" /&gt; 最终建议： 将bean的scope更改为singleton 重构Main类类似如下 class Main &#123; private static connection; private static statement; private static void getConnection &#123; DriverManager.xxxx statement = connection.createStatement(); &#125; public static query()&#123; getConnection(); statement.executeUpdate("xxxx"); statement.close(); &#125; &#125; 其实有更好的写法，但是每个人的时间都很宝贵，没有义务和必要为你解决你自己的问题。而且从结果来看，其所谓的别人的数据库都能连上其实是不可能的。在帮其定位过程中，看git发现这些有问题的代码都是新增代码，所以，做数据库真的累。]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 性能测试报告惨不忍睹的一次原因]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190601%20mysql%20%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A%E6%83%A8%E4%B8%8D%E5%BF%8D%E7%9D%B9%E7%9A%84%E4%B8%80%E6%AC%A1%E5%8E%9F%E5%9B%A0%2F</url>
    <content type="text"><![CDATA[mysql 性能测试报告惨不忍睹的一次原因 背景 新版本发布在即，新增与kafka，zk，redis等其它服务合设的场景，因此需要性能测试探个底。但是性能测试人员反馈，分设与合设性能差距数万倍，一句话甩过来：定位吧。 定位 其实干这行这么久，处理的疑难问题也不少，总结一个规律：解决别人问题，大部分精力会浪费在理清问题甚至是帮助他问问题的过程中，尤其这个人是一些强势部门或者菜鸟（菜鸟也有会思考的，但是现在很少遇到了）的情况下，例如测试。虽然提出问题的人不会提问题，但是解决问题是有科学方法遵循的。 首先，明确问题----到底是什么问题 替他总结一下问题： 安装两套某某版本的mysql，分别是与redis等服务合设的一套（32U64G），和mysql单独安装的一套（8U16G）。 使用jmeter并且采用同样的测试模型，对服务进行长稳测试，其中合设的一套资源，其它服务也会跑长稳。 观察jmeter报告，发现合设的mysql中，平均时间average为20s以上，throughput在10个/秒以下。而独立的mysql，average为ms级别，throughput为数万个。 此时应该随报告提供环境cpu，磁盘，内存，网络带宽，测试模型等情况 当然，这不是我司人员的工作方法，自始至终，我们得到的情况都是误导人的。比如 独立和合设的mysql，其实使用的是不同的版本。 比如合设场景，没有人员进行管理，测自己组件的时候，不知道别人是不是在测试。 当我们要求以管理手段对整体测试方案进行管控，对方以现网难道没有这种情况为由，拒绝同意。 比如在我们咨询是否有停掉其它服务，单独在合设节点测试mysql以便控制变量，对比分设合设机器差异，我们得到的回答是很忙，哪有空给你单独测mysql。 这些都是通过辩证思维很容易得出的结论，却被人高举着“现网”的旗号强势拒绝，而其理由根本站不住脚，他要你做什么可以，你要他做什么，不行。习惯就好。 其次，明确测试模型和环境----你是怎么测的，测试的时候资源情况怎么样 抛开分歧，找出原因。 该测试模型很简单，使用一个1个int主键，20个varchar（256）字段共100w的数据（sql不提供），主键还建了索引。使用select * from xxx where id in random(1, 100w);（伪代码）进行1000并发测试。 因为测试人员拒绝停止其它服务，并且无法提供独立安装的mysql环境信息，不知道如何以及收集哪些环境资源信息，不知道其它服务是否在测试，不知道mysql有没有其它人在连接。因此，我们要提早介入，主要收集以下几种信息。 cpu及内存（top） iostat -x 1 以及其它 /dev/mysqllv(mysql 数据挂载磁盘) 查看jmeter并发服务器的jmap histro 查看mysql show processlist，show status like "%Thread%"等 定位 正常开发会在这个阶段介入，根据信息情况，进一步定位，比如开启慢查询或者调试参数。根据以上收集的信息，发现 cpu，内存等资源占用不高。 iostat 磁盘读写速度不高，但是%util占比居高不下 单独执行一条sql语句，偶尔很快，偶尔很慢 show processlist反馈，大量连接停留在freeing items的状态，说明连接在等候io操作，与上述iostat结论不谋而合 hdparm -Tt 合设机器只有60m/s的磁盘速度（未停服务，不准确） 查询审计日志，发现审计日志大量积压，5M/2分钟的速度在持续增加 走管理手段，要求测试人员提供独立mysql机器信息，其反馈非其本人测试并且已卸载。我们强烈要求重新安装独立mysql 独立mysql表现也慢，与合设无异（测试人员严重失误） 最终发现，其独立mysql测试版本为较老版本 对比版本差异，发现问题 结论 新版本mysql开启audit日志，并且安全部门参照公司《mysql 安全加固规范》中的必须修改项——审计日志的策略 audit_log_strategy 必须为 SYNCHRONOUS , 利用自动化工具扫描并发现我们的mysql没有开启此项，提了单。修改人员在修改时因为经验不足，未多想，便直接修改。 该项的另一个可选值为ASYNCHRONOUS，即异步。与主从复制的同步，半同步及异步类似，作用不言自明。改为该值后，问题消失。]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何炫酷地计算网段]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190610%20%E5%A6%82%E4%BD%95%E7%82%AB%E9%85%B7%E5%9C%B0%E8%AE%A1%E7%AE%97%E7%BD%91%E6%AE%B5%2F</url>
    <content type="text"><![CDATA[如何炫酷地计算网段 背景 我们有很多服务，使用了keepalived作为浮动ip切换的工具。在实际操作中，由于机器网络平面不止一个，因此keepalived的浮动ip，需要 保持跟业务（比如mysql）的ip在同一个网段。以往，我们是通过用户自己控制，在安装的堆栈参数中，自行确保所填入的业务ip和浮动ip在 同一个网段，但是这样不太友好。 于是，可以做点小优化，算出浮动ip所在的网段，并与各个网卡的网段比较，如果相同，则取该网卡作为keepalived.conf中的interface值。 如果两个网卡都在一个网段，这样keepalived会取第一个匹配到的网卡，也不会有问题。 脚本 在我们的部分机器上（自研操作系统）等，可能没有ipcalc软件可用，且携带而机制软件发布，本身是比较麻烦的一件事情。因此，考虑自行 实现一个ipcalc.sh。 自行实现的ipcalc.sh #!/bin/bash net="$1" ip=($&#123;net%/*&#125;) cdr=($&#123;net##*/&#125;) cdr2mask()&#123; #set -- $((5-("$1"/8))) 255 255 255 255 $((2**8-2**(8-"$1"%8))) 0 0 0 set -- $(( 5-("$1"/8) )) 255 255 255 255 $(( (255 &lt;&lt; (8-("$1"%8))) &amp; 255 )) 0 0 0 [[ $1 -gt 1 ]] &amp;&amp; shift $1 || shift #echo $#:$@ #255 255 255 255 253 0 0 0 shift #^_____________^ 255.255.255.255 shift # ^_____________^ 255.255.255.253 shift 2 # ^___________^ 255.255.253.0 shift 3 #default 0, just in case echo $&#123;1-0&#125;.$&#123;2-0&#125;.$&#123;3-0&#125;.$&#123;4-0&#125; &#125; msk=$(cdr2mask $cdr) IFS=. read -r i1 i2 i3 i4 &lt;&lt;&lt; "$&#123;ip&#125;" IFS=. read -r m1 m2 m3 m4 &lt;&lt;&lt; "$&#123;msk&#125;" printf "%d.%d.%d.%d" "$((i1 &amp; m1))" "$((i2 &amp; m2))" "$((i3 &amp; m3))" "$((i4 &amp; m5))" ## usage # route=$(sh ipcalc.sh 192.168.31.123/24) # echo $route 基于上述脚本实现的小程序(伪代码) get_matched_interface()&#123; xxxx for eth in eths;do ip=get_ip_eth $eth if ipcalc.sh $ip == ipcalc.sh $float_ip;then return eth.name fi done &#125; 如何炫酷 这个小例子的最大意义，在于学习了ipcalc.sh中set的用法，以及令人目眩的shift和位运算。]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20190626 问题定位记录]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190626%20%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[20190626 问题定位记录 序号 提出人 所属服务 提出时间 问题描述 问题根因 解决时间(h) 1 20190524 mysql使用mysqldump无法恢复，报错无权限；使用apaas恢复报错gtid相关错误； 解决：使用新版mysqlbackup的相关脚本，参照文档操作即可；或者mysqldump过程中指定–gtid-purged 0.1h 2 20190524 mysql 备份恢复始终卡住； 查看备份脚本打印出的备份路径中的日志，发现mysql进程已经停止，经咨询其在测试可靠性，备份过程中杀掉了mysql，所以备份当然失败，该用例已删除 0.1h 3 notice 20190524 select * from tbl_rn_log order by sender; 两条语句的 select sn, sender from tbl_rn_log order by sender; 顺序不同 mysql自身filesort排序算法问题，设置max_length_for_sort_data可以对算法选择有影响，但是最终建议是在order by中增加主键列或者其它索引列作为副排序字段 4h 4 20190524 修改一个字段类型为text、列名为blob的字段问题 blob为保留字段，需要改为blob 0.1h 5 20190527 安装失败，报错153 mysql linux的密码为Huawei!12345678r，不符合镜像要求 0.1h 6 ms 20190531 jdbc 连接 mysql 报错 operation not allowed when statement closed 给业务代码加debug日志，发现该处逻辑走了两次。第一次走正常，然后关闭了连接；第二次因为是静态方法，且connection是静态字段，使用的仍然是第一次的连接，所以报错。帮业务将其spring context定义文件中的bean限制为singleton，静态方法重构解决 1h 7 20190531 合设节点使用最新版本的mysql性能测试，jmeter测试吞吐量极低，与单独安装的mysql相差万倍 “定位了cpu，内存，硬盘，网络，合设与否，发现硬盘读写util%占用百分比非常高。最后与老版本mysql对比，排除到审计日志策略audit_log_strategy=SYNCHRONOUS影响，修改为异步问题消失； vi /opt/mysql/.my.cnf 将audit_log_strategy=SYNCHRONOUS 改为audit_log_strategy=ASYNCHRONOUS mysql.server restart” 4h 8 20190531 修改long_query_time为1，仍然有ms级别信息 该变量只影响更改后新建的连接 0.1h 9 20190610 mysql安装报错_Mysql_Server_SetPassword 系统不干净，更改了系统目录/run权限 0.1h 10 20190610 mysql 主机启动的pid文件不对 系统不干净，残留了/etc/my.cnf 0.2h 11 20190610 mysql 启动的pid文件与配置文件不对 配置文件中pid_file改为pid-file解决 0.3h 12 20190612 gauss vip 无法访问 使用arping -I eth0 ${vip}发现vip冲突，业务自行解决 0.1h]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[postgresql_mysql_oracle]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190627_postgresql_mysql_oracle%2F</url>
    <content type="text"><![CDATA[postgresql_mysql_oracle sql standard mysql differences from standard sql oracle differences from standard sql postgresql differences from standard sql mysql and oracle postgresql and the others]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>[object Object]</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql_文件管理]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190709_mysql_%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[mysql_文件管理 reference https://dev.mysql.com/doc/refman/5.7/en/innodb-file-space.html https://docs.oracle.com/cd/B19306_01/server.102/b14220/physical.htm https://oracle-base.com/articles/misc/reclaiming-unused-space https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_page_size https://dev.mysql.com/doc/refman/5.7/en/optimizing-innodb-diskio.html]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20190803_使用cgroup限制自研数据库cpu占比]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190803_%E4%BD%BF%E7%94%A8cgroup%E9%99%90%E5%88%B6%E8%87%AA%E7%A0%94%E6%95%B0%E6%8D%AE%E5%BA%93cpu%E5%8D%A0%E6%AF%94%2F</url>
    <content type="text"><![CDATA[20190803_使用cgroup限制自研数据库cpu占比 背景 美国升级贸易战，为了A国业务连续性，全体产品数据库从mysql等切换自研数据库G数据库，该数据库近十年备胎之路，一朝转正， 之前没有暴露出来的问题，最近如雨后春笋，层出不穷。以前几个月发一个版本，现在一周一个版本。我们在美国宣布将XX列入实 体清单的前一个月，就已经着手G数据库的服务化，给公司去年150亿美元的产品线使用。且因为处理器和操作系统suse12被断货，我 们的版本，还涉及了自研处理器及自研操作系统的版本，问题就出在这个自研操作系统。 问题表现 我们使用低版本的G数据库，在x86的处理器，及2.5版本的欧拉系统上，一切正常； 使用高版本的G数据库，在hi1620的处理器（虚拟一个4U8G的节点），及与该处理器匹配的2.8系统上，并发100的情况下，cpu就占到了99%； 通过排除法，发现使用高版本的G数据库，在x86上依然有此问题。 原因及规避 在最近几个月以来，G数据库部门承受了较大的性能测试压力，因此其通过更改多种机制，榨干系统资源，满足多个业务的高性能要求； 但是我们的业务，有把数据库和其它服务，或者监控程序合设在同一个节点的场景。如果G数据库榨干了资源，其它服务均会阻塞，导致异常发生。 虽然长期来看，这个问题还是要G数据库的人员来解决，但是时间紧迫，我们目前短期的规避思路，是通过cgroup限制G数据库使用核心的时间，以及 通过提升其它关键程序的优先级，来暂时达到服务可用的目的。 cgroup cgconfig.conf cgrules.conf 我们首先通过手动创建/sys/fs/cgroup/cpu/g_database文件夹，并执行以下命令： echo 300000 &gt; /sys/fs/cgroup/cpu/g_database/cpu.quota.xxxx echo 100000 &gt; /sys/fs/cgroup/cpu/g_database/cpu.period.xxxx # 并将进程写入该目录下的cgroup.proc及tasks # 并执行以下命令，提高监控程序的优先级 ps -ef|grep ...|renice -15 来验证效果，发现问题解决。 因为服务可能频繁重启，不可能使用一个固定的进程，而在每次启动服务后获取pid并修改文件的做法，需要root权限，不符合规范。因此，我们使用cgconfig.conf和cgrules.conf来 达到目的。 网络上有大量cgroup的文章，但我们在实施过程中，遇到了一个坑。自研的欧拉系统，libcgroup-tools包中，缺失了cgred.servcie(cgsendgd二进制文件)，因此设置的cgrules.conf不生效。 无奈重新arm编译该文件，先测试，后期推动系统组件更新。 cgconfig.conf cgroup&#123; cpu&#123; g_database&#123; cpu.quota... cpu.period... &#125; &#125; &#125; cgrules.conf username:/opt/xxxx/command cpu g_database 使用sysbench测试，其它程序不再被G数据库阻塞，且cpu占用率稳定在我们想要的数值。]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>cgroup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20190810_使用systemd限制自研数据库的cpu占用率]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190810_%E4%BD%BF%E7%94%A8systemd%E9%99%90%E5%88%B6%E8%87%AA%E7%A0%94%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84cpu%E5%8D%A0%E7%94%A8%E7%8E%87%2F</url>
    <content type="text"><![CDATA[使用systemd限制自研数据库的cpu占用率 接上篇，使用cgroup的方案，参考我博客中的《20190803_使用cgroup限制自研数据库cpu占比》，在实际操作中，由于镜像（其它部门）因社区已经移除cgred，多年无人维护，因此不建议我们使用 cgred的方案。出于后续开源申请的考虑，我们决定废弃cgrou的方案，改用systemd。 如何使用systemd 我们前期没有一开始使用systemd的方案，一是因为团队中有个se发了一大段研究结果，说systemd不够精确，达不到我们的使用要求，二是我们拿自研的数据库，本身是没有service文件， 需要自己改造；现在cgroup的方案走不通，只能走这条路，我们就自己研究。 之前有过通过systemd的TasksMax提高mysql的并发连接数案例，参考这个博客中的《使用service启动mysql最大连接数始终在480多左右》，因此改造起来也很顺畅，最终，service文件大致如下： 出于公司要求，以下文件是伪代码，靠记忆写出来的 [Unit] Description=.... After=Network-Online.target（名字不一定准确，不要拷贝，请查询，一个服务如果需要在网络就绪后启动的target是什么） EnvironmentFile=.. Environment=.. ExecStart='' ExecStop='' CPUQuota=280% CPUAccounting=true TasksMax=... WantedBy=multiuser.target 其中，CPUQuota和libcgroup中的cpuquota是一个概念，但是这里仅支持百分数。我们是4核cpu，想达到使用cpu使用率的总体70%，因此结果是280%。 普通用户如何使用sudo免密 业务场景中，监控软件需要启停数据库，但是监控软件是普通用户运行，因此systemctl是没有权限的。我们采取了以下方案，让普通用户可以sudo直接启停数据库而不需要密码： /etc/sudoers (依然是伪代码) username All(All) NOPASSWD:/usr/bin/systemctl]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>systemd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次ssh免密无法登录的问题]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190810_%E4%B8%80%E6%AC%A1ssh%E5%85%8D%E5%AF%86%E6%97%A0%E6%B3%95%E7%99%BB%E5%BD%95%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[一次ssh免密无法登录的问题 自研数据库升级的过程中，需要配置一次ssh免密登录，以便在其中一台机器，很方便的升级集群所有服务器。但是在测试过程中，创建免密登录的脚本失效了。 问题定位 通过手动创建公钥，拷贝到其它机器的authrized_keys，发现仍然需要输入密码登录； 通过ssh -v user@ip，查看详细信息，发现其提示： Authentication can continue: publickey, gssapi-key&#8230;&#8203;..password try publickey .ssh/&#8230;&#8203;.. try publickey .ssh/&#8230;&#8203;.. using password: 而正常的服务器上，该行为： Servert accepted key&#8230;&#8203; 看日志，怀疑ssh客户端没有找到正确的公钥文件，但是该文件确实存在在正确的路径，且拥有正确的600权限。 尝试使用其它端口，启动服务端的sshd，发现可以免密登录 尝试在客户端新建其它用户，并使用22默认端口，一样可以免密登录 执行以下命令，对比新建用户的目录，和问题用户的目录，发现问题 ls -laZ 在问题用户的目录中，.ssh目录的label为unlabel，而正常用户的.ssh，为user_t。通过查询及测试，发现该目录为user_t或者ssh_home_t的标签，都可以测试通过，但是为ublabeled不行。 那么该目录为什么为unlabel呢？毕竟我们执行的只是ssh-keygen，目录并非我们生成。 其实这个目录的标签，会继承父目录的标签，而父目录的标签，由于未知原因，丢失了。因此，selinux的机制不允许ssh使用该目录作为公钥目录。该问题可以通过以下两种方法解决： restorecon -vv -r ~/.ssh setenforce 0等关闭selinux 至于标签为什么会丢失，目前仍在定位中。]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mount 磁盘被秒 umount 的一个问题]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190918_mount%E7%A3%81%E7%9B%98%E8%A2%AB%E7%A7%92umount%E7%9A%84%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[== mount 磁盘被秒 umount 的一个问题:stem: latexmath:icons: font === 问题描述 在 ubuntu 18.04 的机器上（家用），自己搭了一个 samba 服务器。有一天要添加一块磁盘，因为服务器上还运行了一些其他服务，不想重启，因此使用 partprobe 动态扫描了磁盘，分区，写入 /etc/fstab，一切正常。执行 mount -a，没有任何报错，不过磁盘就是没有挂载上去。 === 解决思路 使用 mount 命令，可以手动挂载 无任何报错出现，使用 umount 提示并未挂载 查看 journalctl -xe，发现是 systemd 在 umount 磁盘。最终还是搜索解决了问题，https://unix.stackexchange.com/questions/169909/systemd-keeps-unmounting-a-removable-drive 描述了这个问题。 执行 systemctl daemon-reload 解决后，重新 mount -a 解决。]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>systemd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自研数据库主备切换的一个bug记录]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190810_%E8%87%AA%E7%A0%94%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2%E7%9A%84%E4%B8%80%E4%B8%AAbug%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[自研数据库主备切换的一个bug记录 还是要给自研数据库的人点个赞，以前可能有人要问，业界有mysql，有oracle，有postgresql，大量的收费免费数据库，你们为什么要自己开发数据库？ 相信过了今年，不会再有人问这个问题了。 自研数据库虽然具体细节不能透露，但是其只有6m的安装包大小，完美支持与oracle对接并同步的特性，兼容sql标准，支持python，c，java， 支持多个主备，简单如mysql的配置，简单的容灾能力，支持方便的升级等等，还是很有竞争力。 主备同步的bug 那么bug是什么呢？ 该数据库在一主一备的情况下，有两种手段可以进行主备倒换： 1. switchover 2. failover switchover的场景是，如果主机和备机都正常，想手动触发主备倒换； failover的场景是，如果主机宕机了，备机需要容灾，提升为主机。 这个bug出现在failover的情况。在failover的场景，备机已经升为主机，但是如果主机又恢复，这个时候会出现双主的现象，就需要将其降为备（demote）。 问题是，在demote后，数据库必然出现主备不一致的情况，导致发生该数据库一个著名的异常情况needrepair，而且恢复方案需要删除数据重建，因此没人愿意写自动脚本处理，需要手工干预。 问题定位 我们首先快速排查自己触发切换代码，在排查后将问题范围指向该数据库本身； 首先，主备不一致的情况，是可以在日志中查询到的。该数据库，在主机降备成功后的十秒钟左右，会打印一行类似如下的信息： standby redo point(1/1422) is faster than primary(2/1421)，need repair&#8230;&#8203; 很清晰，说新的备机redo日志比主机要快。那么就是要找出，多出来的这个操作，到底是什么？ 路线分为两路： 1. 通过解析redo日志，查看操作内容 2. 通过其它日志手段，继续确认及排查 由于环境与我们开发环境的网络较为复杂，速度也比较慢，而该redo日志有1个G，传输要1个小时。因此在等待传输的间隙，我们走路线2. 通过类似以下命令开启audit日志以及debug日志。 alter system set audit_level=15; alter system set _log_level=255; 最终搜索通过debug日志，查到有insert语句在执行： cat debug.log|grep -i insert -C 2 通过查询数据库的job，发现开启了wsr性能收集job： select * from dba_jobs; 关闭该任务后，问题消失。自研数据库部门的人虽然确认问题，但是始终想不通，明明在停止和切换数据库的时间节点，已经停止wsr收集，为何还会导致该问题出现，该问题虽然不属于我们的范畴， 但是以往写并发以及过程控制要求比较严格的场景的经验告诉我，自研数据库这块的job，包括wsr以及用户自定义的job的逻辑，都需要再仔细审视一下。]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用nginx代理k8 cadvisor一例]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190918_%E4%BD%BF%E7%94%A8nginx%E4%BB%A3%E7%90%86k8%20cadvisor%E4%B8%80%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[== 使用nginx代理k8 cadvisor一例:stem: latexmath:icons: font k8 自带 cadvisor 监控，UI 界面监听在 4194 端口，不过 HW 的 k8s 这里监听的地址是 127.0.0.1，因此相当于是一个摆设。使用开源的 nginx 可以代理该 url 并暴露在一个可以访问的网卡上，不过出于学习的目的，使用我们自己编译的类似于 nginx 的一个 NSP 来实现这个目的。 == 着手包地址在内网，无法提供。运行此包有三个限制： 使用名称为 lb 的用户执行，否则会报错 getpwnam(“lb”)，因为他们编译写死了执行用户 LD_LIBRARY_PATH要加上包目录中的 lib, luajit/lib, lualib/ 三个目录 包最好放在 /usr/local，因为编译写死了这个路径… == 配置配置好在仍然兼容开源 nginx，关键配置如下：12345678910111213upstream my_server &#123; server 127.0.0.1:4194; keepalive 2000;&#125;server &#123; listen 4195; server_name 172.200.8.173; client_max_body_size 1024M; location / &#123; proxy_pass http://127.0.0.1:4194; index index.html; &#125;&#125; 然后使用浏览器，访问 http://172.200.8.173:4195，即可出现 cadvisor 的页面。]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查询锁状态常用命令]]></title>
    <url>%2F2019%2F09%2F22%2F2019%2F20190210%20mysql%20%E6%9F%A5%E8%AF%A2%E9%94%81%E7%8A%B6%E6%80%81%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[show status like '%lock%; select * from information_schema.processlist; select * from information_schema.processlist where state like "%Waiting%"; select * from information_schema.innodb_trx; SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS; SELECT INNODB_LOCKS.* FROM INNODB_LOCKS JOIN INNODB_LOCK_WAITS ON (INNODB_LOCKS.LOCK_TRX_ID = INNODB_LOCK_WAITS.BLOCKING_TRX_ID); SELECT * FROM INNODB_LOCKS WHERE LOCK_TABLE = db_name.table_name; SELECT TRX_ID, TRX_REQUESTED_LOCK_ID, TRX_MYSQL_THREAD_ID, TRX_QUERY FROM INNODB_TRX WHERE TRX_STATE = 'LOCK WAIT'; show engine innodb status;]]></content>
      <categories>
        <category>备忘</category>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
</search>
